%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "Gerry Murray",
%%%     version         = "1.2",
%%%     date            = "2 April 2012",
%%%     filename        = "acmsmall-sample-bibfile.bib",
%%%     address         = "ACM, NY",
%%%     email           = "murray at hq.acm.org",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "ACM Reference Format, bibliography, citation, references",
%%%     supported       = "yes",
%%%     docstring       = "This BibTeX database file contains 'bibdata' entries
%%%                        that 'match' the examples provided in the Specifications Document
%%%                        AND, also, 'legacy'-type bibs. It should assist authors in
%%%                        choosing the 'correct' at-bibtype and necessary bib-fields
%%%                        so as to obtain the appropriate ACM Reference Format output.
%%%                        It also contains many 'Standard Abbreviations'. "
%%%  }
%%% ====================================================================

% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries


@book{Aho:book:2006,
 author = {Aho, Alfred V. and Lam, Monica S. and Sethi, Ravi and Ullman, Jeffrey D.},
 title = {{Compilers: Principles, Techniques, and Tools (2\textsuperscript{nd} Edition)}},
 year = {2006},
 isbn = {0321486811},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
}

@article{Pratikakis:toplas:2011,
  author = {Pratikakis, Polyvios and Foster, Jeffrey S. and Hicks, Michael},
  title = {{LOCKSMITH: Practical Static Race Detection for C}},
  year = {2011},
  issue_date = {January 2011},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {33},
  number = {1},
  issn = {0164-0925},
  url = {https://doi.org/10.1145/1889997.1890000},
  doi = {10.1145/1889997.1890000},
  abstract = {Locksmith is a static analysis tool for automatically detecting data races in C programs. In this article, we describe each of Locksmith's component analyses precisely, and present systematic measurements that isolate interesting trade-offs between precision and efficiency in each analysis. Using a benchmark suite comprising stand-alone applications and Linux device drivers totaling more than 200,000 lines of code, we found that a simple no-worklist strategy yielded the most efficient interprocedural dataflow analysis; that our sharing analysis was able to determine that most locations are thread-local, and therefore need not be protected by locks; that modeling C structs and void pointers precisely is key to both precision and efficiency; and that context sensitivity yields a much more precise analysis, though with decreased scalability. Put together, our results illuminate some of the key engineering challenges in building Locksmith and data race detection analyses in particular, and constraint-based program analyses in general.},
  journal = {ACM Trans. Program. Lang. Syst.},
  month = jan,
  articleno = {3},
  numpages = {55},
  keywords = {data race, static analysis, sharing analysis, correlation inference, context sensitivity, race detection, Locksmith, contextual effects}
}

@inproceedings{Pratikakis:pldi:2006,
  author = {Pratikakis, Polyvios and Foster, Jeffrey S. and Hicks, Michael},
  title = {{LOCKSMITH: Context-Sensitive Correlation Analysis for Race Detection}},
  year = {2006},
  isbn = {1595933204},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1133981.1134019},
  doi = {10.1145/1133981.1134019},
  abstract = {One common technique for preventing data races in multi-threaded programs is to ensure that all accesses to shared locations are consistently protected by a lock. We present a tool called LOCKSMITH for detecting data races in C programs by looking for violations of this pattern. We call the relationship between locks and the locations they protect consistent correlation, and the core of our technique is a novel constraint-based analysis that infers consistent correlation context-sensitively, using the results to check that locations are properly guarded by locks. We present the core of our algorithm for a simple formal language λ&gt; which we have proven sound, and discuss how we scale it up to an algorithm that aims to be sound for all of C. We develop several techniques to improve the precision and performance of the analysis, including a sharing analysis for inferring thread locality; existential quantification for modeling locks in data structures; and heuristics for modeling unsafe features of C such as type casts. When applied to several benchmarks, including multi-threaded servers and Linux device drivers, LOCKSMITH found several races while producing a modest number of false alarm.},
  booktitle = {Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages = {320–331},
  numpages = {12},
  keywords = {correlation, race detection, locksmith, type inference, context-sensitivity, multi-threaded programming, data race},
  location = {Ottawa, Ontario, Canada},
  series = {PLDI '06}
}

@inproceedings{Voung:fse:2007,
  author = {Voung, Jan Wen and Jhala, Ranjit and Lerner, Sorin},
  title = {{RELAY: Static Race Detection on Millions of Lines of Code}},
  year = {2007},
  isbn = {9781595938114},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1287624.1287654},
  doi = {10.1145/1287624.1287654},
  abstract = {Data races occur when multiple threads are about to access the same piece of memory, and at least one of those accesses is a write. Such races can lead to hard-to-reproduce bugs that are time consuming to debug and fix. We present RELAY, a static and scalable race detection analysis in which unsoundness is modularized to a few sources. We describe the analysis and results from our experiments using RELAY to find data races in the Linux kernel, which includes about 4.5 million lines of code.},
  booktitle = {Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
  pages = {205--214},
  numpages = {10},
  keywords = {race detection, static analysis, verification,data race},
  location = {Dubrovnik, Croatia},
  series = {ESEC-FSE '07}
}

@inproceedings{Atzeni:ipdps:2016,
  author    = {Simone Atzeni and Ganesh Gopalakrishnan and Zvonimir Rakamari\'{c} and Dong H. Ahn and Ignacio Laguna and Martin Schulz and Gregory L. Lee and Joachim Protze and Matthias S. M{\"{u}}ller},
  title     = {{{ARCHER:} Effectively Spotting Data Races in Large OpenMP Applications}},
  abstract  = {OpenMP plays a growing role as a portable programming model to harness on-node parallelism, yet, existing data race checkers for OpenMP have high overheads and generate many false positives. In this paper, we propose the first OpenMP data race checker, ARCHER, that achieves high accuracy, low overheads on large applications, and portability. ARCHER incorporates scalable happens-before tracking, exploits structured parallelism via combined static and dynamic analysis, and modularly interfaces with OpenMP runtimes. ARCHER significantly outperforms TSan and Intel® Inspector XE, while providing the same or better precision. It has helped detect critical data races in the Hypre library that is central to many projects at Lawrence Livermore National Laboratory and elsewhere.},
  booktitle = {2016 {IEEE} International Parallel and Distributed Processing Symposium,
               {IPDPS} 2016, Chicago, IL, USA, May 23-27, 2016},
  keywords  = {data race detection,Dynamic analysis,High performance computing,OpenMP,Static analysis},
  pages     = {53--62},
  publisher = {{IEEE} Computer Society},
  year      = {2016},
  isbn      = {9781509021406},
  url       = {https://doi.org/10.1109/IPDPS.2016.68},
  doi       = {10.1109/IPDPS.2016.68},
}

@inproceedings{Atzeni:ipdps:2018,
  author    = {Simone Atzeni and Ganesh Gopalakrishnan and Zvonimir Rakamari\'{c} and Ignacio Laguna and Gregory L. Lee and Dong H. Ahn},
  title     = {{{SWORD:} {A} Bounded Memory-Overhead Detector of OpenMP Data Races in Production Runs}},
  booktitle = {2018 {IEEE} International Parallel and Distributed Processing Symposium,
               {IPDPS} 2018, Vancouver, BC, Canada, May 21-25, 2018},
  abstract  = {The detection and elimination of data races in large-scale OpenMP programs is of critical importance. Unfortunately, today's state-of-the-art OpenMP race checkers suffer from high memory overheads and/or miss races. In this paper, we present SWORD, a data race detector that significantly improves upon these limitations. SWORD limits the application slowdown and memory usage by utilizing only a bounded, user-adjustable memory buffer to collect targeted memory accesses. When the buffer fills up, the accesses are compressed and flushed to a file system for later offline analysis. SWORD builds on an opera-tional semantics that formally captures the notion of concurrent accesses within OpenMP regions. An offline race checker that is driven by these semantic rules allows SWORD to improve upon happens-before techniques that are known to mask races. To make its offline analysis highly efficient and scalable, SWORD employs effective self-balancing interval-tree-based algorithms. Our experimental results demonstrate that SWORD is capable of detecting races even within programs that use over 90% of the memory on each compute node. Further, our evaluation shows that it matches or exceeds the best available dynamic OpenMP race checker in detection capability while remaining efficient in execution time.},
  keywords  = {Concurrency Bugs,Data Races,HPC,High Performance Computing,Index Terms—Dynamic Data Race Detection,Offline Analysis,OpenMP, data race},
  pages     = {845--854},
  publisher = {{IEEE} Computer Society},
  year      = {2018},
  url       = {https://doi.org/10.1109/IPDPS.2018.00094},
  doi       = {10.1109/IPDPS.2018.00094},
  url       = {http://soarlab.org/publications/ipdps2018-agrlla.pdf}
}

@inproceedings{Serebryany:wbia:2009,
author = {Serebryany, Konstantin and Iskhodzhanov, Timur},
 title = {{ThreadSanitizer: Data Race Detection in Practice}},
 booktitle = {Proceedings of the Workshop on Binary Instrumentation and Applications},
 series = {WBIA '09},
 year = {2009},
 isbn = {978-1-60558-793-6},
 location = {New York, New York, USA},
 pages = {62--71},
 url = {http://doi.acm.org/10.1145/1791194.1791203},
 doi = {10.1145/1791194.1791203},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Valgrind, concurrency bugs, dynamic data race detection, testing},
}

@inproceedings{Serebryany:rv:2011,
  author = {Serebryany, Konstantin and Potapenko, Alexander and Iskhodzhanov, Timur and Vyukov, Dmitriy},
  title = {{Dynamic Race Detection with LLVM Compiler}},
  year = {2011},
  isbn = {9783642298592},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  url = {https://doi.org/10.1007/978-3-642-29860-8\_9},
  doi = {10.1007/978-3-642-29860-8_9},
  abstract = {Data races are among the most difficult to detect and costly bugs. Race detection has been studied widely, but none of the existing tools satisfies the requirements of high speed, detailed reports and wide availability at the same time. We describe our attempt to create a tool that works fast, has detailed and understandable reports and is available on a variety of platforms. The race detector is based on our previous work, ThreadSanitizer [1], and the instrumentation is done using the LLVM compiler. We show that applying compiler instrumentation and sampling reduces the slowdown to less than 1.5x, fast enough to use instrumented programs interactively.},
  booktitle = {Proceedings of the Second International Conference on Runtime Verification},
  keywords = {data race},
  pages = {110--114},
  numpages = {5},
  location = {San Francisco, CA},
  series = {RV'11}
}

@inproceedings{Basupalli:iwomp:2011,
  author    = {Vamshi Basupalli and
               Tomofumi Yuki and
               Sanjay Rajopadhye and
               Antoine Morvan and
               Steven Derrien and
               Patrice Quinton and
               David Wonnacott},
  editor    = {Barbara M. Chapman and
               William D. Gropp and
               Kalyan Kumaran and
               Matthias S. M{\"{u}}ller},
  title     = {{ompVerify: Polyhedral Analysis for the OpenMP Programmer}},
  booktitle = {OpenMP in the Petascale Era - 7th International Workshop on OpenMP,
               {IWOMP} 2011, Chicago, IL, USA, June 13-15, 2011. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {6665},
  pages     = {37--53},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  year      = {2011},
  url       = {https://doi.org/10.1007/978-3-642-21487-5\_4},
  doi       = {10.1007/978-3-642-21487-5\_4},
  keywords  = {data race},
}


@inproceedings{Grosser:impact:2011,
 author = {Grosser, Tobias and Zheng, Hongbin and Aloor, Raghesh and Simb{\"u}rger, Andreas  and Gr{\"o}{\ss}linger, Armin and Pouchet, Louis-No{\"e}l},
 title = {{Polly -- Polyhedral Optimization in {LLVM}}},
 booktitle = {1st International Workshop on Polyhedral Compilation Techniques (IMPACT)},
 year = {2011},
 editor = {C. Alias and C. Bastoul},
 address = {Chamonix, France},
 keywords = {polyhedral},
 abstract = {
  Various powerful polyhedral techniques exist to optimize computation intensive
programs ectively. Applying these techniques on any non-trivial program is
still surprisingly dincult and often not as ective as expected. Most polyhedral
tools are limited to a specific programming language.  Even for this language,
relevant code needs to match specific syntax that rarely appears in existing
code. It is therefore hard or even impossible to process existing programs
automatically. In addition, most tools target C or OpenCL code, which prevents
ective communication with compiler internal optimizers. As a result target
architecture specific optimizations are either little ective or not approached
at all.

In this paper we present Polly, a project to enable polyhedral optimizations in
LLVM. Polly automatically detects and transforms relevant program parts in a
language-independent and syntactically transparent way. Therefore, it supports
programs written in most common programming languages and constructs like C++
iterators, goto based loops and pointer arithmetic. Internally it provides a
state-of-the-art polyhedral library with full support for Z -polyhedra,
advanced data dependency analysis and support for external optimizers. Polly
includes integrated SIMD and OpenMP code generation. Through LLVM, machine code
for CPUs and GPU accelerators, C source code and even hardware descriptions can
be targeted.
},
 url = {http://perso.ens-lyon.fr/christophe.alias/impact2011/impact-07.pdf}
}

@phdthesis{Upadrasta:phdthesis:2013,
    author  = {Ramakrishna Upadrasta},
    title   = {{Sub-Polyhedral Compilation Using (Unit-)Two-Variable-Per-Inequality Polyhedra
        or Scalability Challenges in the Polyhedral Model:
                    An Algorithmic Approach using (Unit-)Two-variable Per Inequality Sub-Polyhedra}},
    school  = {Universit\'e Paris-Sud (11)},
    address = {Orsay, France},
    month   = {March},
    year    = {2013},
    note    = {\url{http://tel.archives-ouvertes.fr/tel-00818764}},
}

@inproceedings{Upadrasta:popl:2013,
    author = {Upadrasta, Ramakrishna and Cohen, Albert},
    title = {{Sub-Polyhedral Scheduling Using (Unit-)Two-Variable-Per-Inequality Polyhedra}},
    booktitle = {40th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    year = 2013,
    month = Jan,
    address = {Rome, Italy},
}

@inproceedings{Acharya:pldi:2018,
author = {Acharya, Aravind and Bondhugula, Uday and Cohen, Albert},
title = {{Polyhedral Auto-Transformation with No Integer Linear Programming}},
year = {2018},
isbn = {9781450356985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3192366.3192401},
doi = {10.1145/3192366.3192401},
booktitle = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {529-542},
numpages = {14},
keywords = {Pluto algorithm, Polyhedral transformation},
location = {Philadelphia, PA, USA},
series = {PLDI 2018}
}

@article{Feautrier:rairo:1988,
 title = {{Parametric Integer Programming}},
 author = {Feautrier, Paul},
 journal = {RAIRO Recherche op{\'e}rationnelle},
 volume = {22},
 number = {3},
 pages = {243--268},
 year = {1988},
 keywords = {polyhedral},
 abstract = {
  When analysising computer programs (especially numercial programs in which
arrays are used extensively), one is often confronted with integer programing
problems. These problems have three peculiarities:
  1) feasible points are ranked according to lexicographic order rathern than
the usual linear economic function;
  2) the feasible set depends on integer parameters;
  3) one is interested only in exact solutions.

The difficulty is somewhat alleviated by the fact that problems sizes are usually quite small. In this paper
we show thath:
  1) the classical simplex algorithm has no difficulty in handling lexicographic ordering;
  2) the algorithm may be executed in symbolic mode, this giving the solution of continuous parametric problems;
  3) the method may be extended to problems in integers.

We prove that the resulting algorithm always terminate and give an estimative of its complexity.
},
 url = {http://camlunity.ru/swap/Library/Conflux/Techniques%20-%20Code%20Analysis%20and%20Transformations%20%28Polyhedral%29/Integer%20Programming/parametric_integer_programming.pdf}
}

@inproceedings{Bastoul:pact:2013,
    author =	 {C\'{e}dric Bastoul},
    title =	     {{Code Generation in the Polyhedral Model Is Easier Than You Think}},
    booktitle =	 {PACT'13 IEEE International Conference on Parallel Architecture
	and Compilation Techniques},
    year =   2004,
    pages =	 {7--16},
    month =	 {September},
    address =  {Juan-les-Pins, France}
}

@inproceedings{Liao:sc:2017,
 author = {Liao, Chunhua and Lin, Pei-Hung and Asplund, Joshua and Schordan, Markus and Karlin, Ian},
 title = {{DataRaceBench: A Benchmark Suite for Systematic Evaluation of Data Race Detection Tools}},
 booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
 series = {SC '17},
 year = {2017},
 isbn = {978-1-4503-5114-0},
 pages = {11:1--11:14},
 articleno = {11},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3126908.3126958},
 doi = {10.1145/3126908.3126958},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {benchmark suite, data race detection, openMP},
}

@inproceedings{Verma:Correctness:2020,
 author = {Verma, Gaurav and Shi, Yaying and Liao, Chunhua and Chapman, Barbara and Yan, Yonghong},
 booktitle = {2020 IEEE/ACM 4th International Workshop on Software Correctness for HPC Applications (Correctness)},
 title = {{Enhancing DataRaceBench for Evaluating Data Race Detection Tools}},
 year = {2020},
 volume={},
 number={},
 pages={20-30},
 doi={10.1109/Correctness51934.2020.00008}
}

@inproceedings{Lin:correctness:2019,
author={Lin, Pei-Hung and Liao, Chunhua and Schordan, Markus and Karlin, Ian},
booktitle={IEEE/ACM 3rd Int. Workshop on Software Correctness for HPC Applications (Correctness)},
title={{Exploring Regression of Data Race Detection Tools Using DataRaceBench}},
year={2019},
volume={},
number={},
pages={11-18},
}

@techreport{Jin:unpublished:1999,
  title={{The OpenMP implementation of NAS parallel benchmarks and its performance}},
  author={Jin, Hao-Qiang and Frumkin, Michael and Yan, Jerry},
  year={1999},
  institution = {NASA Ames Research Center},
  source={https://www.nas.nasa.gov/assets/pdf/techreports/1999/nas-99-011.pdf},
}

@inproceedings{Che:iiswc:2009,
  title={{Rodinia: A benchmark suite for heterogeneous computing}},
  author={Che, Shuai and Boyer, Michael and Meng, Jiayuan and Tarjan, David and Sheaffer, Jeremy W. and Lee, Sang-Ha and Skadron, Kevin},
  booktitle={Workload Characterization, 2009. IISWC 2009. IEEE International Symposium on},
  pages={44--54},
  year={2009},
  organization={Ieee}
}

@inproceedings{Aslot:iwomp:2001,
  title={{SPEComp: A new benchmark suite for measuring parallel computer performance}},
  author={Aslot, Vishal and Domeika, Max and Eigenmann, Rudolf and Gaertner, Greg and Jones, Wesley B. and Parady, Bodo},
  booktitle={International Workshop on OpenMP Applications and Tools},
  pages={1--10},
  year={2001},
  organization={Springer}
}

@inproceedings{Yuki:lcpc:2012,
 title = {{{AlphaZ}: A System for Design Space Exploration in the Polyhedral Model}},
 author = {Yuki, Tomofumi and Gupta, Gautam and Kim, DaeGon and Pathan, Tanveer and Rajopadhye, Sanjay},
 booktitle = {Proceedings of the 25th International Workshop on Languages and Compilers for Parallel Computing},
 year = {2012},
 url = {http://people.rennes.inria.fr/Tomofumi.Yuki/papers/yuki-lcpc2012.pdf},
 doi       = {10.1007/978-3-642-37658-0\_2},
 keywords = {polyhedral},
 abstract = {
  The polyhedral model is now a well established and effective formalism for
program optimization and parallelization. However, finding optimal
transformations is a long-standing open problem. It is therefore important to
develop tools that, rather than following predefined optimization criteria,
allow practitioners to explore different choices through script-driven or
user-guided transformations. More than practitioners, such flexibility is even
more important for compiler researchers and auto-tuner developers. In addition,
tools must also raise the level of abstraction by representing and manipulating
reductions and scans explicitly. And third, the tools must also be able to
explore transformation choices that consider memory (re)-allocation.

AlphaZ is a system that allows exploration of optimizing transformations in the
polyhedral model that meets these goals. We illustrate its power through two
examples of optimizations that existing parallelization tools cannot perform,
but can be systematically applied using our system. One is time-tiling of a
code from PolyBench that resembles the Alternating Direction Implicit (ADI)
method, and the other is a transformation that brings down the algorithmic
complexity of a kernel in UNAfold, a sequence alignment software, from O(N^4)
to O(N^3).}
}

@inproceedings{Flanagan:pldi:2009,
  author = {Flanagan, Cormac and Freund, Stephen N.},
  title = {{FastTrack: Efficient and Precise Dynamic Race Detection}},
  year = {2009},
  isbn = {9781605583921},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1542476.1542490},
  doi = {10.1145/1542476.1542490},
  abstract = {Multithreaded programs are notoriously prone to race conditions. Prior work on dynamic race detectors includes fast but imprecise race detectors that report false alarms, as well as slow but precise race detectors that never report false alarms. The latter typically use expensive vector clock operations that require time linear in the number of program threads.This paper exploits the insight that the full generality of vector clocks is unnecessary in most cases. That is, we can replace heavyweight vector clocks with an adaptive lightweight representation that, for almost all operations of the target program, requires only constant space and supports constant-time operations. This representation change significantly improves time and space performance, with no loss in precision.Experimental results on Java benchmarks including the Eclipse development environment show that our FastTrack race detector is an order of magnitude faster than a traditional vector-clock race detector, and roughly twice as fast as the high-performance DJIT+ algorithm. FastTrack is even comparable in speed to Eraser on our Java benchmarks, while never reporting false alarms.},
  booktitle = {Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages = {121–133},
  numpages = {13},
  keywords = {concurrency, dynamic analysis, race conditions, data race},
  location = {Dublin, Ireland},
  series = {PLDI '09}
}

@article{Savage:tocs:1997,
  author = {Savage, Stefan and Burrows, Michael and Nelson, Greg and Sobalvarro, Patrick and Anderson, Thomas},
  title = {{Eraser: A Dynamic Data Race Detector for Multithreaded Programs}},
  year = {1997},
  issue_date = {Nov. 1997},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {15},
  number = {4},
  issn = {0734-2071},
  url = {https://doi.org/10.1145/265924.265927},
  doi = {10.1145/265924.265927},
  abstract = {Multithreaded programming is difficult and error prone. It is easy to make a mistake in synchronization that produces a data race, yet it can be extremely hard to locate this mistake during debugging. This article describes a new tool, called Eraser, for dynamically detecting data races in lock-based multithreaded programs. Eraser uses binary rewriting techniques to monitor every shared-monory reference and verify that consistent locking behavior is observed. We present several case studies, including undergraduate coursework and a multithreaded Web search engine, that demonstrate the effectiveness of this approach.},
  journal = {ACM Trans. Comput. Syst.},
  month = nov,
  pages = {391--411},
  numpages = {21},
  keywords = {multithreaded programming, binary code modification, race detection, data race}
}

@inproceedings{Chatarasi:impact:2016,
  title = {{Static data race detection for SPMD programs via an extended polyhedral representation}},
  author = {Chatarasi, Prasanth and Shirako, Jun and Sarkar, Vivek},
  booktitle = {Proceedings of the 6th International Workshop on Polyhedral Compilation Techniques (IMPACT)},
  keywords = {data race},
  year = {2016}
}

@inproceedings{Chatarasi:lcpc:2016,
  author    = {Prasanth Chatarasi and
               Jun Shirako and
               Martin Kong and
               Vivek Sarkar},
  editor    = {Chen Ding and
               John Criswell and
               Peng Wu},
  title     = {{An Extended Polyhedral Model for {SPMD} Programs and Its Use in Static
               Data Race Detection}},
  booktitle = {Languages and Compilers for Parallel Computing - 29th International
               Workshop, {LCPC} 2016, Rochester, NY, USA, September 28-30, 2016,
               Revised Papers},
  series    = {Lecture Notes in Computer Science},
  volume    = {10136},
  pages     = {106--120},
  publisher = {Springer},
  year      = {2016},
  url       = {https://doi.org/10.1007/978-3-319-52709-3\_10},
  doi       = {10.1007/978-3-319-52709-3\_10},
}

@inproceedings{Chatarasi:pact:2015,
author={Chatarasi, Prasanth and Shirako, Jun and Sarkar, Vivek},
booktitle={2015 International Conference on Parallel Architecture and Compilation (PACT)},
title={{Polyhedral Optimizations of Explicitly Parallel Programs}},
year={2015},
volume={},
number={},
pages={213-226},
keywords={message passing;optimising compilers;parallel programming;program diagnostics;polyhedral optimizations;parallel programs;polyhedral model;algebraic framework;sequential affine subprograms;parallel software;polyhedral frameworks;program analysis;program transformation;explicit parallelism;OpenMP loop parallelism;task parallelism;task dependences;OpenMP 4.0;parallel loops;PLuTo;PolyAST;OpenMP benchmark programs;KASTORS;Rodinia benchmark;dependence analysis;polyhedral transformations;happens-before relations;optimizing compilers;Parallel processing;Benchmark testing;Arrays;Schedules;Kernel;Jacobian matrices;Pluto;Explicit parallelism;Polyhedral transformations;Task parallelism;OpenMP;Happens-before relations},
doi={10.1109/PACT.2015.44},
ISSN={1089-795X},
month={Oct},
publisher={IEEE},
address={San Francisco, CA, USA},
}

@inproceedings{Ye:correctness:2018,
  author    = {Fangke Ye and Markus Schordan and Chunhua Liao and Pei{-}Hung Lin and Ian Karlin and Vivek Sarkar},
  editor    = {Ignacio Laguna and Cindy Rubio{-}Gonz{\'{a}}lez},
  title     = {{Using Polyhedral Analysis to Verify OpenMP Applications are Data Race Free}},
  abstract  = {Among the most common and hardest to debug types of bugs in concurrent systems are data races. In this paper, we present an approach for verifying that an OpenMP program is data race free. We use polyhedral analysis to verify those parts of the program where we detect parallel affine loop nests. We show the applicability of polyhedral analysis with analysis-enabling program transformations for data race detection in HPC applications. We evaluate our approach with the dedicated data race benchmark suite DataRaceBench and the LLNL Proxy Application AMG2013 which consists of 75,000 LOC. Our evaluation shows that polyhedral analysis can classify 40% of the DataRaceBench 1.2.0 benchmarks as either data race free or having data races and verify that 41 of the 114 (36%) loop nests of AMG2013 are data race free.},
  keywords  = {concurrency control;message passing;parallel processing;program debugging;program processors;program verification;polyhedral analysis;OpenMP applications;OpenMP program;data race detection;LLNL Proxy Application AMG2013;program transformations;DataRaceBench;debug types;concurrent systems;parallel affine loop nests;HPC applications;Tools;Benchmark testing;Arrays;Computer bugs;Data models;Analytical models;OpenMP;Polyhedral-Analysis;Data-Race},
  booktitle = {2nd {IEEE/ACM} International Workshop on Software Correctness for
               {HPC} Applications, CORRECTNESS@SC 2018, Dallas, TX, USA, November
               12, 2018},
  pages     = {42--50},
  publisher = {{IEEE}},
  year      = {2018},
  isbn      = {978-1-7281-0226-9},
  url       = {https://doi.org/10.1109/Correctness.2018.00010},
  doi       = {10.1109/Correctness.2018.00010},
}

@inproceedings{Gu:sc:2018,
  author = {Gu, Yizi and Mellor-Crummey, John},
  title = {{Dynamic Data Race Detection for OpenMP Programs}},
  year = {2018},
  publisher = {IEEE Press},
  abstract = {Two concurrent accesses to a shared variable that are unordered by synchronization are said to be a data race if at least one access is a write. Data races cause shared memory parallel programs to behave unpredictably. This paper describes ROMP - a tool for detecting data races in executions of scalable parallel applications that employ OpenMP for node-level parallelism. The complexity of OpenMP, which includes primitives for managing data environments, SPMD and SIMD parallelism, work sharing, tasking, mutual exclusion, and ordering, presents a formidable challenge for data race detection. ROMP is a hybrid data race detector that tracks accesses, access orderings and mutual exclusion. Unlike other OpenMP race detectors, ROMP detects races with respect to concurrency rather than implementation threads. Experiments show that ROMP yields precise race reports for a broader set of OpenMP constructs than prior state-of-the-art race detectors.},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
  articleno = {61},
  numpages = {12},
  keywords = {DynInst, data race detection, OpenMP, OMPT},
  location = {Dallas, Texas},
  series = {SC '18}
}

@inproceedings{Engler:sosp:2003,
  author = {Engler, Dawson and Ashcraft, Ken},
  title = {{RacerX: Effective, Static Detection of Race Conditions and Deadlocks}},
  year = {2003},
  isbn = {1581137575},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/945445.945468},
  doi = {10.1145/945445.945468},
  abstract = {This paper describes RacerX, a static tool that uses flow-sensitive, interprocedural analysis to detect both race conditions and deadlocks. It is explicitly designed to find errors in large, complex multithreaded systems. It aggressively infers checking information such as which locks protect which operations, which code contexts are multithreaded, and which shared accesses are dangerous. It tracks a set of code features which it uses to sort errors both from most to least severe. It uses novel techniques to counter the impact of analysis mistakes. The tool is fast, requiring between 2-14 minutes to analyze a 1.8 million line system. We have applied it to Linux, FreeBSD, and a large commercial code base, finding serious errors in all of them. RacerX is a static tool that uses flow-sensitive, interprocedural analysis to detect both race conditions and deadlocks. It uses novel strategies to infer checking information such as which locks protect which operations, which code contexts are multithreaded, and which shared accesses are dangerous. We applied it to FreeBSD, Linux and a large commercial code base and found serious errors in all of them.},
  booktitle = {Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles},
  pages = {237--252},
  numpages = {16},
  keywords = {race detection, deadlock detection, program checking, data race},
  location = {Bolton Landing, NY, USA},
  series = {SOSP '03}
}

@inproceedings{Atzeni:ipdpsw:2018,
  author    = {Simone Atzeni and
               Ganesh Gopalakrishnan},
  title     = {{An Operational Semantic Basis for Building an OpenMP Data Race Checker}},
  abstract  = {OpenMP is the de facto standard to exploit the on-node parallelism in new generation supercomputers.Despite its overall ease of use, even expert users are known to create OpenMP programs that harbor concurrency errors, of which one of the most insidious of errors are {\em data races}.OpenMP is also a rapidly evolving standard, which means that future data races may be introduced within unfamiliar contexts.A simple and rigorous operational semantics for OpenMP can help build reliable race checkers and ward off future errors through programmer education and better tooling.This paper's key contribution is a simple operational semantics for OpenMP, with primitive events matching those generated by today's popular OpenMP runtimes and tracing methods such as OMPT.This makes our operational semantics more than a theoretical document for intellectual edification; it can serve as a blueprint for OpenMP event capture and tool building.We back this statement by summarizing the workings of a new data race checker for OpenMP being built based on this semantics.The larger purpose served by our semantics is to serve the needs of the OpenMP community with regard to their contemplated extensions to OpenMP, as well as future tooling efforts.},
  booktitle = {2018 {IEEE} International Parallel and Distributed Processing Symposium
               Workshops, {IPDPS} Workshops 2018, Vancouver, BC, Canada, May 21-25,
               2018},
  pages     = {395--404},
  publisher = {{IEEE} Computer Society},
  isbn      = {9781538655559},
  year      = {2018},
  url       = {https://doi.org/10.1109/IPDPSW.2018.00074},
  doi       = {10.1109/IPDPSW.2018.00074},
  keywords  = {application program interfaces;formal specification;programming language semantics;software engineering;operational semantic basis;OpenMP data race checker;formal characterization;operational semantics;OpenMP events;standard event collection mechanism;formal semantics;concurrent languages;multiple concurrency formalisms;Sword offline analysis phase design;Semantics; Concurrent computing;Runtime;Standards;Tools;Synchronization;Instruction sets;High Performance Computing;OpenMP;Operational Semantics of OpenMP;Data Race Checking},
}

@inproceedings{Kasikci:hotdep:2012,
  author = {Kasikci, Baris and Zamfir, Cristian and Candea, George},
  title = {{CoRD: A Collaborative Framework for Distributed Data Race Detection}},
  year = {2012},
  publisher = {USENIX Association},
  address = {USA},
  abstract = {Modern concurrent software is riddled with data races and these races constitute the source of many problems. Data races are hard to detect accurately before software is shipped and, once they cause failures in production, developers find it challenging to reproduce and debug them.Ideally, all data races should be known before software ships. Static data race detectors are fast, have few false negatives, but unfortunately have many false positives. Conversely, dynamic data race detectors do not have false positives, but have many false negatives and incur high runtime overhead. There is no silver bullet and, as a result, modern software still ships with numerous data races.We present CoRD, a collaborative distributed testing framework that aims to combine the best of the two approaches: CoRD first statically detects races and then dynamically validates them via crowdsourced executions of the program. Our initial results show that CoRD is more effective than static or dynamic detectors alone, and it introduces negligible runtime overhead.},
  booktitle = {Proceedings of the Eighth USENIX Conference on Hot Topics in System Dependability},
  keywords = {data race},
  pages = {4},
  numpages = {1},
  location = {Hollywood, CA},
  series = {HotDep'12}
}

@inproceedings{Effinger-dean:oopsla:2012,
 author = {Effinger-Dean, Laura and Lucia, Brandon and Ceze, Luis and Grossman, Dan and Boehm, Hans-J.},
 title = {{IFRit: Interference-free Regions for Dynamic Data-race Detection}},
 booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
 series = {OOPSLA '12},
 year = {2012},
 isbn = {978-1-4503-1561-6},
 location = {Tucson, Arizona, USA},
 pages = {467--484},
 url = {http://doi.acm.org/10.1145/2384616.2384650},
 doi = {10.1145/2384616.2384650},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {concurrency, data-race detection, interference-free regions},
}

@inproceedings{Yu:sosp:2005,
  author = {Yu, Yuan and Rodeheffer, Tom and Chen, Wei},
  title = {{RaceTrack: Efficient Detection of Data Race Conditions via Adaptive Tracking}},
  year = {2005},
  isbn = {1595930795},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1095810.1095832},
  doi = {10.1145/1095810.1095832},
  abstract = {Bugs due to data races in multithreaded programs often exhibit non-deterministic symptoms and are notoriously difficult to find. This paper describes RaceTrack, a dynamic race detection tool that tracks the actions of a program and reports a warning whenever a suspicious pattern of activity has been observed. RaceTrack uses a novel hybrid detection algorithm and employs an adaptive approach that automatically directs more effort to areas that are more suspicious, thus providing more accurate warnings for much less over-head. A post-processing step correlates warnings and ranks code segments based on how strongly they are implicated in potential data races. We implemented RaceTrack inside the virtual machine of Microsoft's Common Language Runtime (product version v1.1.4322) and monitored several major, real-world applications directly out-of-the-box,without any modification. Adaptive tracking resulted in a slowdown ratio of about 3x on memory-intensive programs and typically much less than 2x on other programs,and a memory ratio of typically less than 1.2x. Several serious data race bugs were revealed, some previously unknown.},
  booktitle = {Proceedings of the Twentieth ACM Symposium on Operating Systems Principles},
  pages = {221--234},
  numpages = {14},
  keywords = {virtual machine instrumentation, race detection, data race},
  location = {Brighton, United Kingdom},
  series = {SOSP '05}
}

@inproceedings{Ros:micro:2016,
 author = {Ros, Alberto and Kaxiras, Stefanos},
 title = {{Racer: TSO Consistency via Race Detection}},
 booktitle = {The 49th Annual IEEE/ACM International Symposium on Microarchitecture},
 series = {MICRO-49},
 year = {2016},
 location = {Taipei, Taiwan},
 pages = {33:1--33:13},
 articleno = {33},
 numpages = {13},
 url = {http://dl.acm.org/citation.cfm?id=3195638.3195678},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
}

@article{Blackshear:oopsla:2018,
  author = {Blackshear, Sam and Gorogiannis, Nikos and O'Hearn, Peter W. and Sergey, Ilya},
  title = {{RacerD: Compositional Static Race Detection}},
  year = {2018},
  issue_date = {November 2018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {2},
  number = {OOPSLA},
  url = {https://doi.org/10.1145/3276514},
  doi = {10.1145/3276514},
  abstract = {Automatic static detection of data races is one of the most basic problems in reasoning about concurrency. We present RacerD—a static program analysis for detecting data races in Java programs which is fast, can scale to large code, and has proven effective in an industrial software engineering scenario. To our knowledge, RacerD is the first inter-procedural, compositional data race detector which has been shown to have non-trivial precision and impact. Due to its compositionality, it can analyze code changes quickly, and this allows it to perform continuous reasoning about a large, rapidly changing codebase as part of deployment within a continuous integration ecosystem. In contrast to previous static race detectors, its design favors reporting high-confidence bugs over ensuring their absence. RacerD has been in deployment for over a year at Facebook, where it has flagged over 2500 issues that have been fixed by developers before reaching production. It has been important in enabling the development of new code as well as fixing old code: it helped support conversion of part of the main Facebook Android app from a single-threaded to a multi-threaded architecture. In this paper we describe RacerD’s design, implementation, deployment and impact.},
  journal = {Proc. ACM Program. Lang.},
  month = oct,
  articleno = {144},
  numpages = {28},
  keywords = {Concurrent Separation Logic, Race Freedom, Concurrency, Static Analysis, data race}
}

@inproceedings{Zheng:ppopp:2011,
 author = {Zheng, Mai and Ravi, Vignesh T. and Qin, Feng and Agrawal, Gagan},
 title = {{GRace: A Low-overhead Mechanism for Detecting Data Races in GPU Programs}},
 booktitle = {Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming},
 series = {PPoPP '11},
 year = {2011},
 isbn = {978-1-4503-0119-0},
 location = {San Antonio, TX, USA},
 pages = {135--146},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1941553.1941574},
 doi = {10.1145/1941553.1941574},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {concurrency, cuda, data race, gpu, multithreading},
}

@inproceedings{Feng:spaa:1997,
  abstract = {A parallel multithreaded program that is ostensibly deterministic may nevertheless behave nondeterministically due to bugs in the code. These bugs are called determinacy races, and they result when one thread updates a location in shared memory while another thread is concurrently accessing the location. We have implemented a provably efficient determinacy-race detector for Cilk, an algorithmic multithreaded programming language. If a Cilk program is run on a given input data set, our debugging tool, which we call the ``Nondeterminator,'' either determines at least one location in the program that is subject to a determinacy race, or else it certifies that the program is race free when run on the data set.},
  author = {Feng, Mingdong and Leiserson, Charles E.},
  booktitle = {Proceedings of the Ninth Annual ACM Symposium on Parallel Algorithms and Architectures},
  doi = {10.1145/258492.258493},
  isbn = {0897918908},
  issn = {1432-4350},
  number = {3},
  pages = {301--326},
  title = {{Efficient Detection of Determinacy Races in Cilk Programs}},
  url = {https://doi.org/10.1145/258492.258493},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  location = {Newport, Rhode Island, USA},
  volume = {32},
  series = {SPAA '97},
  keywords = {data race},
  year = {1997}
}

@inproceedings{Agrawal:soda:2018,
 author = {Agrawal, Kunal and Devietti, Joseph and Fineman, Jeremy T. and Lee, I-Ting Angelina and Utterback, Robert and Xu, Changming},
 title = {{Race Detection and Reachability in Nearly Series-parallel DAGs}},
 booktitle = {Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
 series = {SODA '18},
 year = {2018},
 isbn = {978-1-6119-7503-1},
 location = {New Orleans, Louisiana},
 pages = {156--171},
 numpages = {16},
 url = {http://dl.acm.org/citation.cfm?id=3174304.3175277},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
}

@inproceedings{Raman:rv:2010,
  author = {Raman, Raghavan and Zhao, Jisheng and Sarkar, Vivek and Vechev, Martin T. and Yahav, Eran},
  title = {{Efficient Data Race Detection for Async-Finish Parallelism}},
  year = {2010},
  isbn = {3642166113},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  abstract = {A major productivity hurdle for parallel programming is the presence of data races. Data races can lead to all kinds of harmful program behaviors, including determinism violations and corrupted memory. However, runtime overheads of current dynamic data race detectors are still prohibitively large (often incurring slowdowns of 10\texttimes{} or larger) for use in mainstream software development.In this paper, we present an efficient dynamic race detector algorithm targeting the async-finish task-parallel parallel programming model. The async and finish constructs are at the core of languages such as X10 and Habanero Java (HJ). These constructs generalize the spawn-sync constructs used in Cilk, while still ensuring that all computation graphs are deadlock-free.We have implemented our algorithm in a tool called TASKCHECKER and evaluated it on a suite of 12 benchmarks. To reduce overhead of the dynamic analysis, we have also implemented various static optimizations in the tool. Our experimental results indicate that our approach performs well in practice, incurring an average slowdown of 3.05\texttimes{} compared to a serial execution in the optimized case.},
  booktitle = {Proceedings of the First International Conference on Runtime Verification},
  keywords = {data race},
  pages = {368--383},
  numpages = {16},
  location = {St. Julians, Malta},
  url = {http://dl.acm.org/citation.cfm?id=1939399.1939430},
  series = {RV'10}
}

@article{Pozniansky:cpe:2007,
 author = {Pozniansky, Eli and Schuster, Assaf},
 title = {{MultiRace: Efficient On-the-fly Data Race Detection in Multithreaded C++ Programs: Research Articles}},
 journal = {Concurr. Comput. : Pract. Exper.},
 issue_date = {March 2007},
 volume = {19},
 number = {3},
 month = mar,
 year = {2007},
 issn = {1532-0626},
 pages = {327--340},
 numpages = {14},
 url = {https://doi.org/10.1002/cpe.v19:3},
 doi = {10.1002/cpe.v19:3},
 publisher = {John Wiley and Sons Ltd.},
 address = {Chichester, UK},
 keywords = {concurrency, data race, instrumentation, multithreading, synchronization},
}

@inproceedings{Raman:pldi:2012,
  author = {Raman, Raghavan and Zhao, Jisheng and Sarkar, Vivek and Vechev, Martin T. and Yahav, Eran},
  title = {{Scalable and Precise Dynamic Datarace Detection for Structured Parallelism}},
  year = {2012},
  isbn = {9781450312059},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2254064.2254127},
  doi = {10.1145/2254064.2254127},
  abstract = {Existing dynamic race detectors suffer from at least one of the following three limitations:(i)space overhead per memory location grows linearly with the number of parallel threads [13], severely limiting the parallelism that the algorithm can handle;(ii)sequentialization: the parallel program must be processed in a sequential order, usually depth-first [12, 24]. This prevents the analysis from scaling with available hardware parallelism, inherently limiting its performance;(iii) inefficiency: even though race detectors with good theoretical complexity exist, they do not admit efficient implem entations and are unsuitable for practical use [4, 18].We present a new precise dynamic race detector that leverages structured parallelism in order to address these limitations. Our algorithm requires constant space per memory location, works in parallel, and is efficient in practice. We implemented and evaluated our algorithm on a set of 15 benchmarks. Our experimental results indicate an average (geometric mean) slowdown of 2.78x on a 16-core SMP system.},
  booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages = {531–542},
  numpages = {12},
  keywords = {program analysis, parallelism, data races},
  location = {Beijing, China},
  series = {PLDI '12}
}

@inproceedings{Dorta:pdp:2005,
author={A. J. {Dorta} and C. {Rodriguez} and F. {de Sande}},
booktitle={13th Euromicro Conference on Parallel, Distributed and Network-Based Processing},
title={{The OpenMP source code repository}},
year={2005},
volume={},
number={},
pages={244-250},
keywords={open systems;Web sites;public domain software;message passing;shared memory systems;OpenMP source code repository;OmpSCR;Web site;program developing tool;shared memory multiprocessor platforms;Size measurement;Standards development;Time measurement;High performance computing;Discussion forums;Appraisal;Computer networks;Concurrent computing;Distributed computing;Sorting},
doi={10.1109/EMPDP.2005.41},
ISSN={1066-6192},
month={Feb},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Wilcox:ppopp:2018,
  abstract = {Dynamic data race detectors are valuable tools for testing and validating concurrent software, but to achieve good performance they are typically implemented using sophisticated concurrent algorithms. Thus, they are ironically prone to the exact same kind of concurrency bugs they are designed to detect. To address these problems, we have developed VerifiedFT, a clean slate redesign of the FastTrack race detector [19]. The VerifiedFT analysis provides the same precision guarantee as FastTrack, but is simpler to implement correctly and efficiently, enabling us to mechanically verify an implementation of its core algorithm using CIVL [27]. Moreover, VerifiedFT provides these correctness guarantees without sacrificing any performance over current state-of-the-art (but complex and unverified) FastTrack implementations for Java.},
  author = {Wilcox, James R. and Flanagan, Cormac and Freund, Stephen N.},
  doi = {10.1145/3178487.3178514},
  isbn = {9781450349826},
  booktitle = {Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming  - PPoPP '18},
  keywords = {2018,Data races, concurrency, dynamic analysis,a verified,acm reference format,and stephen n,concurrency,cormac flanagan,data races,dynamic analysis,freund,high-performance precise dynamic race,james r,verifiedft,wilcox},
  pages = {354--367},
  title = {{VerifiedFT: a verified, high-performance precise dynamic race detector}},
  url = {http://dl.acm.org/citation.cfm?doid=3178487.3178514},
  year = {2018}
}

@article{Bronevetsky:ijpp:2007,
author="Bronevetsky, Greg
and de Supinski, Bronis R.",
title={{Complete Formal Specification of the OpenMP Memory Model}},
journal="International Journal of Parallel Programming",
year="2007",
month="Aug",
day="01",
volume="35",
number="4",
pages="335--392",
issn="1573-7640",
doi="10.1007/s10766-007-0051-4",
url="https://doi.org/10.1007/s10766-007-0051-4"
}

@inproceedings{Collard:ppopp:1995,
  title = {{Fuzzy array dataflow analysis}},
  author = {Collard, Jean-Fran{\c{c}}ois and Barthou, Denis and Feautrier, Paul},
  booktitle = {Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {30},
  number = {8},
  numpages = {10},
  pages = {92--101},
  year = {1995},
  isbn = {0897917006},
  organization = {ACM},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.187&rep=rep1&type=pdf},
  doi = {10.1145/209936.209947},
  series = {PPOPP '95},
  location = {Santa Barbara, California, USA},
  keywords = {polyhedral},
  abstract = {
    Exact array dataflow analysis can be achieved in the general case if the only
      control structures are do-loops and structural ifs, and if loop counter bounds
      and array subscripts are affine expressions of englobing loop counters and
      possibly some integer constants. In this paper, we begin the study of dataflow
      analysis of dynamic control programs, where arbitrary ifs and whiles are
      allowed. In the general case, this dataflow analysis can only be fuzzy.
  }
}

@inproceedings{Benabderrahmane:cc:2010,
 title = {{The polyhedral model is more widely applicable than you think}},
 author = {Benabderrahmane, Mohamed-Walid and Pouchet, Louis-No{\"e}l and Cohen, Albert and Bastoul, C{\'e}dric},
 booktitle = {Compiler Construction},
 pages = {283--303},
 year = {2010},
 publisher = {Springer},
 url       = {https://doi.org/10.1007/978-3-642-11970-5\_16},
 doi       = {10.1007/978-3-642-11970-5\_16},
 keywords = {polyhedral},
 abstract = {
  The polyhedral model is a powerful framework for automatic optimization and
parallelization. It is based on an algebraic representation of programs,
allowing to construct and search for complex sequences of optimizations. This
model is now mature and reaches production compilers. The main limitation of
the polyhedral model is known to be its restriction to statically predictable,
loop-based program parts. This paper removes this limitation, allowing to
operate on general data-dependent control-flow. We embed control and exit
predicates as first-class citizens of the algebraic representation, from
program analysis to code generation. Complementing previous (partial) attempts
in this direction, our work concentrates on extending the code generation step
and does not compromise the expressiveness of the model. We present
experimental evidence that our extension is relevant for program optimization
and parallelization, showing performance improvements on benchmarks that were
thought to be out of reach of the polyhedral model.
},
 pdf = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.162.407&rep=rep1&type=pdf}
}

@article{Belaoucha:procedia:2010,
  title={{FADAlib: an open source C++ library for fuzzy array dataflow analysis}},
  author={Belaoucha, Marouane and Barthou, Denis and Eliche, Adrien and others},
  journal={Procedia Computer Science},
  volume={1},
  number={1},
  pages={2075--2084},
  year={2010},
  publisher={Elsevier}
}

@book{Padua:book:2011,
 editor = {Padua, David A.},
 title = {{Encyclopedia of Parallel Computing}},
 year = {2011},
 isbn = {0387097651, 9780387097657},
 publisher = {Springer Publishing Company, Incorporated},
}

@inbook{Feautrier:Encyclopedia:2011,
author = {Feautrier, Paul and Lengauer, Christian},
editor = {Padua, David},
title = {{Polyhedron Model}},
bookTitle = {Encyclopedia of Parallel Computing},
year = {2011},
publisher = {Springer US},
address = {Boston, MA},
pages = {1581--1592},
isbn = {978-0-387-09766-4},
doi = {10.1007/978-0-387-09766-4\_502},
url = {https://doi.org/10.1007/978-0-387-09766-4\_502}
}


@book{Kuck:book:1978,
 author = {Kuck, David J.},
 title = {{Structure of Computers and Computations}},
 year = {1978},
 isbn = {0471027162},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

@phdthesis{Wolfe:phdthesis:1982,
 author = {Wolfe, Michael J.},
 title = {{Optimizing Supercompilers for Supercomputers}},
 year = {1982},
 note = {AAI8303027},
 publisher = {University of Illinois at Urbana-Champaign},
 address = {Champaign, IL, USA},
}

@book{Wolfe:book:1995,
 author = {Wolfe, Michael J.},
 title = {{High Performance Compilers for Parallel Computing}},
 year = {1995},
 isbn = {0805327304},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
}

@book{Darte:book:2000,
 author = {Darte, Alain and Robert, Yves and Vivien, Fr{\'{e}}d{\'{e}}ric},
 title = {{Scheduling and Automatic Parallelization}},
 year = {2000},
 isbn      = {978-3-7643-4149-7},
 edition = {1st},
 publisher = {Birkh{\"{a}}user Boston},
}

@book{Kumar:book:2002,
 author = {Kumar, Vipin},
 title = {{Introduction to Parallel Computing}},
 year = {2002},
 isbn = {0201648652},
 edition = {2nd},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
}

@book{Kennedy:book:2001,
 author = {Kennedy, Ken and Allen, Randy},
 title = {{Optimizing Compilers for Modern Architectures: A Dependence-based Approach}},
 year = {2002},
 isbn = {1-55860-286-0},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}

@book{Banerjee:book:1996,
 author = {Banerjee, Utpal K.},
 title = {{Dependence Analysis}},
 year = {1996},
 isbn = {0792398092},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
}

@book{Banerjee:book:1994,
  author    = {Utpal K. Banerjee},
  title     = {{Loop Parallelization}},
  series    = {Loop transformations for restructuring compilers},
  publisher = {Kluwer Academic Publishers},
  address   = {Norwell, MA, USA},
  year      = {1994},
  isbn      = {978-0-7923-9455-6},
}

@book{Banerjee:book:1993,
 author = {Banerjee, Utpal K.},
 title = {{Loop Transformations for Restructuring Compilers: The Foundations}},
 year = {1993},
 isbn      = {978-0-7923-9318-4},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
}

@book{Banerjee:book:1988,
 author = {Banerjee, Utpal K.},
 title = {{Dependence Analysis for Supercomputing}},
 year = {1988},
 volume    = {60},
 isbn      = {978-0-89838-289-1},
 publisher = {Kluwer Academic Publishers},
 series    = {The Kluwer international series in engineering and computer science},
 address = {Norwell, MA, USA},
}

@inproceedings{Lattner:lcpc:2004,
  author={Chris Lattner and Vikram Adve},
  title={{The LLVM Compiler Framework and Infrastructure Tutorial}},
  month={Sep},
  year={2004},
  address={West Lafayette, Indiana},
  booktitle={LCPC'04 Mini Workshop on Compiler Research Infrastructures}
}

@inproceedings{Lattner:cgo:2004,
 author = {Lattner, Chris and Adve, Vikram},
 title = {{LLVM: A Compilation Framework for Lifelong Program Analysis \& Transformation}},
 booktitle = {Proceedings of the International Symposium on Code Generation and Optimization: Feedback-directed and Runtime Optimization},
 series = {CGO '04},
 year = {2004},
 isbn = {0-7695-2102-9},
 location = {Palo Alto, California},
 pages = {75--},
 url = {http://dl.acm.org/citation.cfm?id=977395.977673},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Verdoolaege:icms:2010,
 author = {Verdoolaege, Sven},
 title = {{Isl: An Integer Set Library for the Polyhedral Model}},
 booktitle = {Proceedings of the Third International Congress Conference on Mathematical Software},
 series = {ICMS'10},
 year = {2010},
 isbn = {3-642-15581-2, 978-3-642-15581-9},
 series = {LNCS 6327},
 location = {Kobe, Japan},
 pages = {299--302},
 numpages = {4},
 articleno={1250010},
 url = {http://dl.acm.org/citation.cfm?id=1888390.1888455},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {polyhedral},
}

@article{Grosser:ppl:2012,
 title = {{Polly -- Performing polyhedral optimizations on a low-level intermediate representation}},
 author = {Grosser, Tobias and Gr{\"o}{\ss}linger, Armin and Lengauer, Christian},
 journal = {Parallel Processing Letters},
 volume = {22},
 number = {04},
 articleno = {1},
 numpages  = {27},
 year = {2012},
 publisher = {World Scientific},
 keywords = {polyhedral},
 abstract = {
  The polyhedral model for loop parallelization has proved to be an effective
tool for advanced optimization and automatic parallelization of programs in
higher-level languages. Yet, to integrate such optimizations seamlessly into
production compilers, they must be performed on the compiler's internal,
low-level, intermediate representation (IR). With Polly, we present an
infrastructure for polyhedral optimizations on such an IR. We describe the
detection of program parts amenable to a polyhedral optimization (so-called
static control parts), their translation to a Z-polyhedral representation,
optimizations on this representation and the generation of optimized IR code.
Furthermore, we define an interface for connecting external optimizers and
present a novel way of using the parallelism they introduce to generate SIMD
and OpenMP code. To evaluate Polly, we compile the PolyBench 2.0 benchmarks
fully automatically with PLuTo as external optimizer and parallelizer. We can
report on significant speedups.
},
 url = {http://www.worldscientific.com/doi/abs/10.1142/S0129626412500107},
 doi       = {10.1142/S0129626412500107},
}

@phdthesis{Grosser:phdthesis:2014,
  author    = {Tobias Grosser},
  title     = {{A decoupled approach to high-level loop optimization : tile shapes,
               polyhedral building blocks and low-level compilers. (Une approche
               d{\'{e}}coupl{\'{e}}e pour l'optimization de boucle {\`{a}}
               haut niveau)}},
  school    = {Pierre and Marie Curie University, Paris, France},
  year      = {2014},
  url       = {https://tel.archives-ouvertes.fr/tel-01144563},
  timestamp = {Thu, 30 Jun 2016 14:34:56 +0200},
  biburl    = {http://dblp.dagstuhl.de/rec/bib/phd/hal/Grosser14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Yang:ijpp:1995,
 author = {Yang, Yi-Qing and Ancourt, Corinne and Irigoin, Fran\c{c}ois},
 title = {{Minimal Data Dependence Abstractions for Loop Transformations: Extended Version}},
 journal = {Int. J. Parallel Program.},
 issue_date = {Aug. 1995},
 volume = {23},
 number = {4},
 month = aug,
 year = {1995},
 issn = {0885-7458},
 pages = {359--388},
 numpages = {30},
 url = {http://dx.doi.org/10.1007/BF02577771},
 doi = {10.1007/BF02577771},
 publisher = {Plenum Press},
 address = {New York, NY, USA},
 keywords = {data dependence abstraction, parallelizing compiler, program transformation},
}	

@inproceedings{Wang:lcpc:1994,
 author = {Yang, Yi-Qing and Ancourt, Corinne and Irigoin, Fran\c{c}ois},
 title = {{Minimal Data Dependence Abstractions for Loop Transformations}},
 booktitle = {Proceedings of the 7th International Workshop on Languages and Compilers for Parallel Computing},
 series = {LCPC '94},
 year = {1995},
 isbn = {3-540-58868-X},
 pages = {201--216},
 numpages = {16},
 url = {http://dl.acm.org/citation.cfm?id=645672.665551},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@inproceedings{Goff:pldi:1991,
 author = {Goff, Gina and Kennedy, Ken and Tseng, Chau-Wen},
 title = {{Practical Dependence Testing}},
 booktitle = {Proceedings of the ACM SIGPLAN 1991 Conference on Programming Language Design and Implementation},
 series = {PLDI '91},
 year = {1991},
 isbn = {0-89791-428-7},
 location = {Toronto, Ontario, Canada},
 pages = {15--29},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/113445.113448},
 doi = {10.1145/113445.113448},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Psarris:pact:1999,
author = {Psarris, Kleanthis and Kyriakopoulos, Konstantinos},
title = {{Data Dependence Testing in Practice}},
year = {1999},
isbn = {0769504256},
publisher = {IEEE Computer Society},
address = {USA},
booktitle = {Proceedings of the 1999 International Conference on Parallel Architectures and Compilation Techniques},
pages = {264},
numpages = {1},
keywords = {Dependence Analysis, Automatic Parallelization, Compiler Optimization, Data Dependence},
series = {PACT '99}
}

@article{Eigenmann:tpds:1998,
 author = {Eigenmann, Rudolf and Hoeflinger, Jay and Padua, David A.},
 title = {{On the Automatic Parallelization of the Perfect Benchmarks\&\#174}},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 issue_date = {January 1998},
 volume = {9},
 number = {1},
 month = jan,
 year = {1998},
 issn = {1045-9219},
 pages = {5--23},
 numpages = {19},
 url = {http://dx.doi.org/10.1109/71.655238},
 doi = {10.1109/71.655238},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Program parallelization, parallelization techniques, restructuring compilers, performance evaluation.},
}

@article{Sreraman:ijpp:2000,
 author = {Sreraman, N. and Govindarajan, R.},
 title = {{A Vectorizing Compiler for Multimedia Extensions}},
 journal = {Int. J. Parallel Program.},
 issue_date = {August 2000},
 volume = {28},
 number = {4},
 month = aug,
 year = {2000},
 issn = {0885-7458},
 pages = {363--400},
 numpages = {38},
 url = {http://dx.doi.org/10.1023/A:1007559022013},
 doi = {10.1023/A:1007559022013},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {MMX instruction set, subword parallelism, vectorizing compiler},
}

@inproceedings{Blume:sc:1994,
 author = {Blume, William and Eigenmann, Rudolf},
 title = {{The Range Test: A Dependence Test for Symbolic, Non-linear Expressions}},
 booktitle = {Proceedings of the 1994 ACM/IEEE Conference on Supercomputing},
 series = {Supercomputing '94},
 year = {1994},
 isbn = {0-8186-6605-6},
 location = {Washington, D.C.},
 pages = {528--537},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=602770.602858},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords={parallelising compilers;program compilers;parallel programming;constraint handling;program testing;range test;dependence test;symbolic nonlinear expressions;data dependence tests;loop bounds;array subscripts;symbolic inequalities;permutation;loop nest;symbolic analyses;constraint propagation techniques;Polaris;parallelizing compiler;Sequential analysis;Program processors;Research and development;Polarization;Data analysis;Performance evaluation;Contracts;Government;Benchmark testing;Oceans},
}

@article{Psarris:jpdc:1996,
 author = {Psarris, Kleanthis},
 title = {{The Banerjee-Wolfe and GCD Tests on Exact Data Dependence Information}},
 journal = {J. Parallel Distrib. Comput.},
 issue_date = {Feb. 1, 1996},
 volume = {32},
 number = {2},
 month = feb,
 year = {1996},
 issn = {0743-7315},
 pages = {119--138},
 numpages = {20},
 url = {http://dx.doi.org/10.1006/jpdc.1996.0009},
 doi = {10.1006/jpdc.1996.0009},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
}

@inproceedings{Yu:icpp:2000,
 author = {Yu, Yijun and D'Hollander, Erik H.},
 title = {{Partitioning Loops with Variable Dependence Distances}},
 booktitle = {Proceedings of the Proceedings of the 2000 International Conference on Parallel Processing},
 series = {ICPP '00},
 year = {2000},
 isbn = {0-7695-0768-9},
 pages = {209--},
 url = {http://dl.acm.org/citation.cfm?id=850941.852911},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {loop parallelization, dependence equation, distance vector, pseudo distance matrix, uni-modular transformation, iteration space partitioning 1},
}

@article{Kyriakopoulos:ijpp:2004,
 author = {Kyriakopoulos, Konstantinos and Psarris, Kleanthis},
 title = {{Data Dependence Analysis Techniques for Increased Accuracy and Extracted Parallelism}},
 journal = {Int. J. Parallel Program.},
 issue_date = {August 2004},
 volume = {32},
 number = {4},
 month = aug,
 year = {2004},
 issn = {0885-7458},
 pages = {317--359},
 numpages = {43},
 url = {http://dx.doi.org/10.1023/B:IJPP.0000035817.01263.d0},
 doi = {10.1023/B:IJPP.0000035817.01263.d0},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {automatic parallelization, compiler optimization, data dependence, parallelizing compilers, program analysis},
}

@inproceedings{Hoeflinger:lcpc:2000,
 author = {Hoeflinger, Jay and Paek, Yunheung},
 title = {{A Comparative Analysis of Dependence Testing Mechanisms}},
 booktitle = {Proceedings of the 13th International Workshop on Languages and Compilers for Parallel Computing-Revised Papers},
 series = {LCPC '00},
 year = {2001},
 isbn = {3-540-42862-3},
 pages = {289--303},
 numpages = {15},
 url = {http://dl.acm.org/citation.cfm?id=645678.663934},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@article{Kong:tpds:1991,
 author = {Kong, Xiangyun and Klappholz, David and Psarris, Kleanthis},
 title = {{The I Test: An Improved Dependence Test for Automatic Parallelization and Vectorization}},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 issue_date = {July 1991},
 volume = {2},
 number = {3},
 month = jul,
 year = {1991},
 issn = {1045-9219},
 pages = {342--349},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/71.86109},
 doi = {10.1109/71.86109},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Banerjee tests, GCD, I test, Index Termsautomatic parallelization, loop iterations, loops, parallel programming, program compilers, program testing, subscript dependence test, vectorization},
}

@inproceedings{Chang:ics:1998,
 author = {Chang, Weng-Long and Chu, Chih-Ping},
 title = {{The Infinity Lambda Test}},
 booktitle = {Proceedings of the 12th International Conference on Supercomputing},
 series = {ICS '98},
 year = {1998},
 isbn = {0-89791-998-X},
 location = {Melbourne, Australia},
 pages = {196--203},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/277830.277872},
 doi = {10.1145/277830.277872},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Weng-Long:ipps:1998,
 author = {Weng-Long Chang and Chih-Ping Chu and Jesse Wu},
 title = {{The Generalized Lambda Test}},
 booktitle = {Proceedings of the 12th. International Parallel Processing Symposium on International Parallel Processing Symposium},
 abstract = {We generalize the /spl lambda/ test. The generalized /spl lambda/ test can be applied towards determining whether there exist data dependencies for coupled arrays with both constant and variable limits under any given direction vectors, improving the applicable range of the /spl lambda/ test. Experimental data reflecting the effect of the generalized /spl lambda/ test are also presented.},
 keywords = {parallel programming;parallelising compilers;program testing;lambda calculus;generalized lambda test;data dependencies;coupled arrays;variable limits;direction vectors;parallel systems;Testing;Vectors;Mathematics;Data analysis;Nonlinear equations},
 series = {IPPS '98},
 year = {1998},
 pages = {181--186},
 url = {https://ieeexplore.ieee.org/document/669908},
 doi = {10.1109/IPPS.1998.669908},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Chang:lcpc:1998,
 author = {Chang, Weng-Long and Chu, Chih-Ping},
 title = {{The I+ Test}},
 booktitle = {Proceedings of the 11th International Workshop on Languages and Compilers for Parallel Computing},
 series = {LCPC '98},
 year = {1999},
 isbn = {3-540-66426-2},
 pages = {367--381},
 numpages = {15},
 url = {http://dl.acm.org/citation.cfm?id=645676.663777},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@article{Zhao:js:2015,
 author = {Zhao, Jie and Zhao, Rongcai and Chen, Xi and Zhao, Bo},
 title = {{An Improved Nonlinear Data Dependence Test}},
 journal = {J. Supercomput.},
 issue_date = {January   2015},
 volume = {71},
 number = {1},
 month = jan,
 year = {2015},
 issn = {0920-8542},
 pages = {340--368},
 numpages = {29},
 url = {http://dx.doi.org/10.1007/s11227-014-1298-3},
 doi = {10.1007/s11227-014-1298-3},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Data dependence test, Interval equation, Nonlinear subscript, Parallelizing compiler},
}

@inproceedings{Niedzielski:lcpc:1999,
 author = {Niedzielski, David and Psarris, Kleanthis},
 title = {{An Analytical Comparison of the I-Test and Omega Test}},
 booktitle = {Proceedings of the 12th International Workshop on Languages and Compilers for Parallel Computing},
 series = {LCPC '99},
 year = {2000},
 isbn = {3-540-67858-1},
 pages = {251--270},
 numpages = {20},
 url = {http://dl.acm.org/citation.cfm?id=645677.663780},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@article{Wu:is:2007,
 author = {Wu, Jia-Hwa and Chu, Chih-Ping},
 title = {{An Exact Data Dependence Testing Method for Quadratic Expressions}},
 journal = {Inf. Sci.},
 issue_date = {December, 2007},
 volume = {177},
 number = {23},
 month = dec,
 year = {2007},
 issn = {0020-0255},
 pages = {5316--5328},
 numpages = {13},
 url = {http://dx.doi.org/10.1016/j.ins.2007.06.006},
 doi = {10.1016/j.ins.2007.06.006},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Data dependence test, Parallelizing compilers},
}

@article{Chang:js:2005,
 author = {Chang, Weng-Long and Chu, Chih-Ping and Wu, Jia-Hwa},
 title = {{A Polynomial-Time Dependence Test for Determining Integer-Valued Solutions in Multi-Dimensional Arrays Under Variable Bounds}},
 journal = {J. Supercomput.},
 issue_date = {February 05},
 volume = {31},
 number = {2},
 month = feb,
 year = {2005},
 issn = {0920-8542},
 pages = {111--135},
 numpages = {25},
 url = {http://dx.doi.org/10.1007/s11227-005-0032-6},
 doi = {10.1007/s11227-005-0032-6},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {data dependence analysis, loop parallelization, loop vectorization, parallelizing/vectorizing compiler},
}

@article{Psarris:tpds:1993,
 author = {Psarris, Kleanthis and Kong, Xiangyun and Klappholz, David},
 title = {{The Direction Vector I Test}},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 issue_date = {November 1993},
 volume = {4},
 number = {11},
 month = nov,
 year = {1993},
 issn = {1045-9219},
 pages = {1280--1290},
 numpages = {11},
 url = {http://dx.doi.org/10.1109/71.250105},
 doi = {10.1109/71.250105},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Banerjee test, GCD test, Index Termsdirection vector I test, algorithm theory, arbitrary direction vector, data dependence tests, parallel programming, parallelism detection, parallelization},
}

@article{Nugteren:taco:2013,
 author = {Nugteren, Cedric and Custers, Pieter and Corporaal, Henk},
 title = {{Algorithmic Species: A Classification of Affine Loop Nests for Parallel Programming}},
 journal = {ACM Trans. Archit. Code Optim.},
 issue_date = {January 2013},
 volume = {9},
 number = {4},
 month = jan,
 year = {2013},
 issn = {1544-3566},
 pages = {40:1--40:25},
 articleno = {40},
 numpages = {25},
 url = {http://doi.acm.org/10.1145/2400682.2400699},
 doi = {10.1145/2400682.2400699},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Algorithm classification, parallel programming, polyhedral model},
}

@article{Pugh:cacm:1992,
 author = {Pugh, William},
 title = {{A Practical Algorithm for Exact Array Dependence Analysis}},
 journal = {Commun. ACM},
 issue_date = {Aug. 1992},
 volume = {35},
 number = {8},
 month = aug,
 year = {1992},
 issn = {0001-0782},
 pages = {102--114},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/135226.135233},
 doi = {10.1145/135226.135233},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Omega test, dependence analysis, integer programming, linear Diophantine equations},
}

@inproceedings{Hoeflinger:lcpc:1999,
 author = {Hoeflinger, Jay and Paek, Yunheung},
 title = {{The Access Region Test}},
 booktitle = {Proceedings of the 12th International Workshop on Languages and Compilers for Parallel Computing},
 series = {LCPC '99},
 year = {2000},
 isbn = {3-540-67858-1},
 pages = {271--285},
 numpages = {15},
 url = {http://dl.acm.org/citation.cfm?id=645677.663779},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@inproceedings{Kyriakopoulos:pact:2005,
 author = {Kyriakopoulos, Konstantinos and Psarris, Kleanthis},
 title = {{Efficient Techniques for Advanced Data Dependence Analysis}},
 booktitle = {Proceedings of the 14th International Conference on Parallel Architectures and Compilation Techniques},
 series = {PACT '05},
 year = {2005},
 isbn = {0-7695-2429-X},
 pages = {143--156},
 numpages = {14},
 url = {http://dx.doi.org/10.1109/PACT.2005.19},
 doi = {10.1109/PACT.2005.19},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Pugh:pldi:1994,
 author = {Pugh, William},
 title = {{Counting Solutions to Presburger Formulas: How and Why}},
 booktitle = {Proceedings of the ACM SIGPLAN 1994 Conference on Programming Language Design and Implementation},
 series = {PLDI '94},
 year = {1994},
 isbn = {0-89791-662-X},
 location = {Orlando, Florida, USA},
 pages = {121--134},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/178243.178254},
 doi = {10.1145/178243.178254},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Pugh:toplas:1998,
 author = {Pugh, William and Wonnacott, David},
 title = {{Constraint-based Array Dependence Analysis}},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {May 1998},
 volume = {20},
 number = {3},
 month = may,
 year = {1998},
 issn = {0164-0925},
 pages = {635--678},
 numpages = {44},
 url = {http://doi.acm.org/10.1145/291889.291900},
 doi = {10.1145/291889.291900},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Presburger Arithmetic, array dataflow analysis, dependence abstraction, dependence analysis, parallelization, static analysis},
}

@article{Pugh:tpds:1995,
 author = {Pugh, William and Wonnacott, David},
 title = {{Going Beyond Integer Programming with the Omega Test to Eliminate False Data Dependences}},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 issue_date = {February 1995},
 volume = {6},
 number = {2},
 month = feb,
 year = {1995},
 issn = {1045-9219},
 pages = {204--211},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/71.342135},
 doi = {10.1109/71.342135},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
}

@inproceedings{Gupta:popl:2006,
 author    = {Gautam Gupta and Sanjay Rajopadhye},
 editor    = {J. Gregory Morrisett and Simon L. Peyton Jones},
 title     = {{Simplifying Reductions}},
 booktitle = {Proceedings of the 33rd {ACM} {SIGPLAN-SIGACT} Symposium on Principles
             of Programming Languages, {POPL} 2006, Charleston, South Carolina,
             USA, January 11-13, 2006},
 series = {POPL '06},
 year = {2006},
 isbn = {1-59593-027-2},
 location = {Charleston, South Carolina, USA},
 pages = {30--41},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1111037.1111041},
 doi = {10.1145/1111037.1111041},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {equational programming, incremental computation, loop optimization, polyhedral model, program transformation},
}

@inproceedings{Bondhugula:pldi:2008,
  author = {Bondhugula, Uday and Hartono, Albert and Ramanujam, J. and Sadayappan, P.},
  title = {{A Practical Automatic Polyhedral Parallelizer and Locality Optimizer}},
  year = {2008},
  isbn = {9781595938602},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1375581.1375595},
  doi = {10.1145/1375581.1375595},
  abstract = {We present the design and implementation of an automatic polyhedral source-to-source transformation framework that can optimize regular programs (sequences of possibly imperfectly nested loops) for parallelism and locality simultaneously. Through this work, we show the practicality of analytical model-driven automatic transformation in the polyhedral model -- far beyond what is possible by current production compilers. Unlike previous works, our approach is an end-to-end fully automatic one driven by an integer linear optimization framework that takes an explicit view of finding good ways of tiling for parallelism and locality using affine transformations. The framework has been implemented into a tool to automatically generate OpenMP parallel code from C program sections. Experimental results from the tool show very high speedups for local and parallel execution on multi-cores over state-of-the-art compiler frameworks from the research community as well as the best native production compilers. The system also enables the easy use of powerful empirical/iterative optimization for general arbitrarily nested loop sequences.},
  booktitle = {Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages = {101–113},
  numpages = {13},
  keywords = {loop transformations, polyhedral model, locality optimization, tiling, automatic parallelization, affine transformations},
  location = {Tucson, AZ, USA},
  series = {PLDI '08}
}

@inproceedings{Baskaran:ics:2008,
 author = {Baskaran, Muthu Manikandan and Bondhugula, Uday and Krishnamoorthy, Sriram and Ramanujam, J. and Rountev, Atanas and Sadayappan, P.},
 title = {{A Compiler Framework for Optimization of Affine Loop Nests for Gpgpus}},
 booktitle = {Proceedings of the 22Nd Annual International Conference on Supercomputing},
 series = {ICS '08},
 year = {2008},
 isbn = {978-1-60558-158-3},
 location = {Island of Kos, Greece},
 pages = {225--234},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1375527.1375562},
 doi = {10.1145/1375527.1375562},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {GPU, empirical tuning, memory access optimization, polyhedral model},
}

@inproceedings{Krishnamoorthy:pldi:2007,
 author = {Krishnamoorthy, Sriram and Baskaran, Muthu Manikandan and Bondhugula, Uday and Ramanujam, J. and Rountev, Atanas and Sadayappan, P.},
 title = {{Effective automatic parallelization of stencil computations}},
 booktitle = {Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation},
 series = {PLDI '07},
 isbn = {978-1-59593-633-2},
 year = {2007},
 location = {San Diego, California, USA},
 pages = {235--244},
 numpages = {10},
 publisher = {{ACM}},
 address = {New York, NY, USA},
 doi = {10.1145/1250734.1250761},
 url = {http://drona.csa.iisc.ernet.in/~uday/publications/uday-pldi07.pdf},
 keywords = {automatic parallelization, load, stencil computations, tiling, polyhedral},
 abstract = {
  Performance optimization of stencil computations has been widely studied in the
literature, since they occur in many computationally intensive scientific and
engineering applications. Compiler frameworks have also been developed that can
transform sequential stencil codes for optimization of data locality and
parallelism. However, loop skewing is typically required in order to tile
stencil codes along the time dimension, resulting in load imbalance in
pipelined parallel execution of the tiles. In this paper, we develop an
approach for automatic parallelization of stencil codes, that explicitly
addresses the issue of load-balanced execution of tiles. Experimental results
are provided that demonstrate the effectiveness of the approach.
}
}

@inproceedings{Bondhugula:cc:2008,
  author = {Uday Bondhugula and Muthu Manikandan Baskaran and Sriram Krishnamoorthy and J. Ramanujam and Atanas Rountev and P. Sadayappan},
  title = {{Automatic Transformations for Communication-Minimized Parallelization and Locality Optimization in the Polyhedral Model}},
  booktitle = {International Conference on Compiler Construction (ETAPS CC)},
  year = {2008},
  month = {April},
  url = {http://drona.csa.iisc.ernet.in/~uday/publications/uday-cc08.pdf},
  doi       = {10.1007/978-3-540-78791-4\_9},
  keywords = {polyhedral},
  abstract = {
  The polyhedral model provides powerful abstractions to optimize loop nests with
    regular accesses.  Affine transformations in this model capture a complex
    sequence of execution-reordering loop transformations that can
    improve performance by parallelization as well as locality
    enhancement.  Although a significant body of research has addressed
    affine scheduling and partitioning, the problem of automatically
    finding good affine transforms for communication-optimized
    coarse-grained parallelization together with locality optimization
    for the general case of arbitrarily-nested loop sequences remains a
    challenging problem.

    We propose an automatic transformation framework to
    optimize arbitrarily-nested loop sequences with affine dependences
    for parallelism and locality simultaneously. The approach finds
    good tiling hyperplanes by embedding a powerful and versatile cost
    function into an Integer Linear Programming formulation. These
    tiling hyperplanes are used for communication-minimized
    coarse-grained parallelization as well as for locality
    optimization. The approach enables the minimization of inter-tile
    communication volume in the processor space, and minimization of
    reuse distances for local execution at each node. Programs
    requiring one-dimensional versus multi-dimensional time schedules
    (with scheduling-based approaches) are all handled with the same
    algorithm.  Synchronization-free parallelism, permutable loops or
    pipelined parallelism at various levels can be detected.
    Preliminary studies of the framework show promising results.
    }
}

@inproceedings{Baskaran:ppopp:2008,
 author = {Baskaran, Muthu Manikandan and Bondhugula, Uday and Krishnamoorthy, Sriram and Ramanujam, J. and Rountev, Atanas and Sadayappan, P.},
 title = {{Automatic Data Movement and Computation Mapping for Multi-level Parallel Architectures with Explicitly Managed Memories}},
 booktitle = {Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
 series = {PPoPP '08},
 year = {2008},
 isbn = {978-1-59593-795-7},
 location = {Salt Lake City, UT, USA},
 pages = {1--10},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1345206.1345210},
 doi = {10.1145/1345206.1345210},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data movement, graphics processor unit, multi-level tiling, scratchpad memory},
}

@inproceedings{Pouchet:popl:2011,
  author = {Pouchet, Louis-No\"{e}l and Bondhugula, Uday and Bastoul, C{\'e}dric and Cohen, Albert and Ramanujam, J. and Sadayappan, P. and Vasilache, Nicolas},
  title = {{Loop Transformations: Convexity, Pruning and Optimization}},
  booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  series = {POPL '11},
  year = {2011},
  isbn = {978-1-4503-0490-0},
  location = {Austin, Texas, USA},
  pages = {549--562},
  numpages = {14},
  url = {http://doi.acm.org/10.1145/1926385.1926449},
  doi = {10.1145/1926385.1926449},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {affine scheduling, compilation, compiler optimization, loop transformations, parallelism},
}

@inproceedings{Bandishti:sc:2012,
  title = {{Tiling Stencil Computations to Maximize Parallelism}},
  author = {Bandishti, Vinayaka and Pananilath, Irshad and Bondhugula, Uday},
  booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
  series = {SC '12},
  year = {2012},
  isbn = {978-1-4673-0804-5},
  location = {Salt Lake City, Utah},
  pages = {40:1--40:11},
  articleno = {40},
  numpages = {11},
  pages = {40},
  year = {2012},
  url = {http://www.csa.iisc.ernet.in/~uday/publications/stencils_sc12.pdf},
  publisher = {IEEE Computer Society Press},
  address = {Los Alamitos, CA, USA},
  keywords = {compilers, program transformation, polyhedral},
  abstract = {
    Most stencil computations allow tile-wise concurrent start, i.e., there always
      exists a face of the iteration space and a set of tiling hyperplanes such that
      all tiles along that face can be started concurrently. This provides load
      balance and maximizes parallelism. However, existing automatic tiling
      frameworks often choose hyperplanes that lead to pipelined start-up and load
      imbalance. We address this issue with a new tiling technique that ensures
      concurrent start-up as well as perfect load-balance whenever possible. We first
      provide necessary and sufficient conditions on tiling hyperplanes to enable
      concurrent start for programs with affine data accesses. We then provide an
      approach to find such hyperplanes. Experimental evaluation on a 12-core Intel
      Westmere shows that our code is able to outperform a tuned domain-specific
      stencil code generator by 4% to 27%, and previous compiler techniques by a
      factor of 2x to 10.14 x.
  }
}

@inproceedings{Baskaran:ppopp:2009,
 author = {Baskaran, Muthu Manikandan and Vydyanathan, Nagavijayalakshmi and Bondhugula, Uday and Ramanujam, J. and Rountev, Atanas and Sadayappan, P.},
 title = {{Compiler-Assisted Dynamic Scheduling for Effective Parallelization of Loop Nests on Multicore Processors}},
 year = {2009},
 isbn = {9781605583976},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 url = {https://doi.org/10.1145/1504176.1504209},
 doi = {10.1145/1504176.1504209},
 abstract = {
  Recent advances in polyhedral compilation technology have made it feasible to
  automatically transform affine sequential loop nests for tiled parallel
  execution on multi-core processors. However, for multi-statement input
  programs with statements of different dimensionalities, such as Cholesky or
  LU decomposition, the parallel tiled code generated by existing automatic
  parallelization approaches may suffer from significant load imbalance,
  resulting in poor scalability on multi-core systems. In this paper, we develop
  a completely automatic parallelization approach for transforming input affine
  sequential codes into efficient parallel codes that can be executed on a
  multi-core system in a load-balanced manner. In our approach, we employ a
  compile-time technique that enables dynamic extraction of inter-tile
  dependences at run-time, and dynamic scheduling of the parallel tiles on the
  processor cores for improved scalable execution. Our approach obviates the
  need for programmer intervention and re-writing of existing algorithms for
  efficient parallel execution on multi-cores. We demonstrate the usefulness of
  our approach through comparisons using linear algebra computations: LU and
  Cholesky decomposition.
 },
 booktitle = {Proceedings of the 14th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
 pages = {219–228},
 numpages = {10},
 keywords = {compile-time optimization, dynamic scheduling, run-time optimization, polyhedral},
 location = {Raleigh, NC, USA},
 series = {PPoPP '09}
}

@inproceedings{Lu:pact:2009,
 author = {Lu, Qingda and Alias, Christophe and Bondhugula, Uday and Henretty, Thomas and Krishnamoorthy, Sriram and Ramanujam, J. and Rountev, Atanas and Sadayappan, P. and Chen, Yongjian and Lin, Haibo and Ngai, Tin-fook},
 title = {{Data Layout Transformation for Enhancing Data Locality on NUCA Chip Multiprocessors}},
 booktitle = {Proceedings of the 2009 18th International Conference on Parallel Architectures and Compilation Techniques},
 series = {PACT '09},
 year = {2009},
 isbn = {978-0-7695-3771-9},
 pages = {348--357},
 numpages = {10},
 url = {http://dx.doi.org/10.1109/PACT.2009.36},
 doi = {10.1109/PACT.2009.36},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Data Layout Optimization, Polyhedral Model, NUCA Cache},
}

@inproceedings{Pouchet:sc:2010,
 author = {Pouchet, Louis-No\"{e}l and Bondhugula, Uday and Bastoul, C{\'e}dric and Cohen, Albert and Ramanujam, J. and Sadayappan, P.},
 title = {{Combined Iterative and Model-driven Optimization in an Automatic Parallelization Framework}},
 booktitle = {Proceedings of the 2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis},
 series = {SC '10},
 year = {2010},
 isbn = {978-1-4244-7559-9},
 pages = {1--11},
 numpages = {11},
 url = {http://dx.doi.org/10.1109/SC.2010.14},
 doi = {10.1109/SC.2010.14},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Bondhugula:pact:2010,
  author = {Bondhugula, Uday and G{\"u}nl{\"u}k, Oktay and Dash, Sanjeeb and Renganarayanan, Lakshminarayanan},
  title = {{A Model for Fusion and Code Motion in an Automatic Parallelizing Compiler}},
  booktitle = {Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques},
  series = {PACT '10},
  year = {2010},
  isbn = {978-1-4503-0178-7},
  location = {Vienna, Austria},
  pages = {343--352},
  numpages = {10},
  url = {http://drona.csa.iisc.ernet.in/~uday/publications/uday-pact10.pdf},
  doi = {10.1145/1854273.1854317},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {automatic parallelization, locality optimization, loop fusion, polyhedral model, prefetching},
  abstract = {
    Loop fusion has been studied extensively, but in a manner isolated from other
      transformations. This was mainly due to the lack of a powerful intermediate
      representation for application of compositions of high-level transformations.
      Fusion presents strong interactions with parallelism and locality. Currently,
    there exist no models to determine good fusion structures integrated with all
      components of an auto-parallelizing compiler. This is also one of the reasons
      why all the benefits of optimization and automatic parallelization of long
      sequences of loop nests spanning hundreds of lines of code have never been
      explored.

      We present a fusion model in an integrated automatic parallelization framework
      that simultaneously optimizes for hardware prefetch stream buffer utilization,
    locality, and parallelism. Characterizing the legal space of fusion structures
      in the polyhedral compiler framework is not difficult. However, incorporating
      useful optimization criteria into such a legal space to pick good fusion
      structures is very hard. The model we propose captures utilization of hardware
      prefetch streams, loss of parallelism, as well as constraints imposed by
      privatization and code expansion into a single convex optimization space. The
      model scales very well to program sections spanning hundreds of lines of code.
      It has been implemented into the polyhedral pass of the IBM XL optimizing
      compiler. Experimental results demonstrate its effectiveness in finding good
      fusion structures for codes including SPEC benchmarks and large applications.
      An improvement ranging from 5% to nearly a factor of 2.75x is obtained over the
      current production compiler optimizer on these benchmarks.
  }
}

@inproceedings{Mullapudi:asplos:2015,
  author = {Mullapudi, Ravi Teja and Vasista, Vinay and Bondhugula, Uday},
  title = {{PolyMage: Automatic Optimization for Image Processing Pipelines}},
  booktitle = {Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems},
  series = {ASPLOS '15},
  year = {2015},
  isbn = {978-1-4503-2835-7},
  location = {Istanbul, Turkey},
  pages = {429--443},
  numpages = {15},
  url = {http://mcl.csa.iisc.ernet.in/polymage.html},
  doi = {10.1145/2694344.2694364},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {domain-specific language, image processing, locality, multicores, parallelism, polyhedral optimization, tiling, vectorization},
  abstract = {
    This paper presents the design and implementation of PolyMage, a
      domain-specific language and compiler for image processing pipelines.
      An image processing pipeline can be viewed as a graph of interconnected
      stages which process images successively. Each stage typically performs
      one of point-wise, stencil, reduction or data-dependent operations on
      image pixels. Individual stages in a pipeline typically exhibit abundant
      data parallelism that can be exploited with relative ease. However, the
      stages also require high memory bandwidth preventing effective
      utilization of parallelism available on modern architectures. For
      applications that demand high performance, the traditional options are
      to use optimized libraries like OpenCV or to optimize manually.  While
      using libraries precludes optimization across library routines, manual
      optimization accounting for both parallelism and locality is very
      tedious.

      The focus of our system, PolyMage, is on automatically generating
      high-performance implementations of image processing pipelines expressed
      in a high-level declarative language. Our optimization approach
      primarily relies on the transformation and code generation capabilities
      of the polyhedral compiler framework. To the best of our knowledge, this
      is the first model-driven compiler for image processing pipelines that
      performs complex fusion, tiling, and storage optimization automatically.
      Experimental results on a modern multicore system show that the
      performance achieved by our automatic approach is up to 1.81$\times$
      better than that achieved through manual tuning in Halide, a
      state-of-the-art language and compiler for image processing pipelines.
      For a camera raw image processing pipeline, our performance is
      comparable to that of a hand-tuned implementation.}
}

@inproceedings{Bondhugula:ipdps:2006,
 author = {Bondhugula, Uday and Devulapalli, Ananth and Fernando, Joseph and Wyckoff, Pete and Sadayappan, P.},
 title = {{Parallel FPGA-based All-pairs Shortest-paths in a Directed Graph}},
 booktitle = {Proceedings of the 20th International Conference on Parallel and Distributed Processing},
 series = {IPDPS'06},
 year = {2006},
 isbn = {1-4244-0054-6},
 location = {Rhodes Island, Greece},
 pages = {112--112},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=1898953.1899043},
 doi       = {10.1109/IPDPS.2006.1639347},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Bondhugula:pact:2014,
 author = {Bondhugula, Uday and Bandishti, Vinayaka and Cohen, Albert and Potron, Guillain and Vasilache, Nicolas},
 title = {{Tiling and Optimizing Time-iterated Computations on Periodic Domains}},
 booktitle = {Proceedings of the 23rd International Conference on Parallel Architectures and Compilation},
 series = {PACT '14},
 year = {2014},
 isbn = {978-1-4503-2809-8},
 location = {Edmonton, AB, Canada},
 pages = {39--50},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2628071.2628106},
 doi = {10.1145/2628071.2628106},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automatic parallelization, periodic, polyhedral model, stencils, tiling},
}

@inproceedings{Acharya:ppopp:2015,
  author = {Acharya, Aravind and Bondhugula, Uday},
  title = {{Pluto+: Near-Complete Modeling of Affine Transformations for Parallelism and Locality}},
  booktitle = {Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  series = {PPoPP 2015},
  year = {2015},
  isbn = {978-1-4503-3205-7},
  location = {San Francisco, CA, USA},
  pages = {54--64},
  numpages = {11},
  url = {http://mcl.csa.iisc.ernet.in/downloads/publications/acharya15ppopp.pdf},
  doi = {10.1145/2688500.2688512},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Affine transformations, affine scheduling, automatic parallelization, polyhedral model, stencil computations, tiling},
  abstract = {
    Affine transformations have proven to be very powerful for loop restructuring
      due to their ability to model a very wide range of transformations.  A
      single multi-dimensional affine function can represent a long and complex
      sequence of simpler transformations. Existing affine transformation
      frameworks like the Pluto algorithm, that include a cost function for
      modern multicore architectures where coarse-grained parallelism and
      locality are crucial, consider only a sub-space of transformations to avoid
      a combinatorial explosion in finding the transformations. The ensuing
      practical tradeoffs lead to the exclusion of certain useful
      transformations, in particular, transformation compositions involving loop
      reversals and loop skewing by negative factors. In this paper, we propose
      an approach to address this limitation by modeling a much larger space of
      affine transformations in conjunction with the Pluto algorithm's cost
      function. We perform an experimental evaluation of both, the effect on
      compilation time, and performance of generated codes.  The evaluation shows
      that our new framework, Pluto+, provides no degradation in performance in
      any of the Polybench benchmarks.  For Lattice Boltzmann Method (LBM) codes
      with periodic boundary conditions, it provides a mean speedup of 1.33$\times$ over
      Pluto.  We also show that Pluto+ does not increase compile times
      significantly.  Experimental results on Polybench show that Pluto+
      increases overall polyhedral source-to-source optimization time only by
      15%. In cases where it improves execution time significantly, it increased
      polyhedral optimization time only by 2.04$\times$.}
}

@article{Bondhugula:toplas:2016,
 author = {Bondhugula, Uday and Acharya, Aravind and Cohen, Albert},
 title = {{The Pluto+ Algorithm: A Practical Approach for Parallelization and Locality Optimization of Affine Loop Nests}},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {May 2016},
 volume = {38},
 number = {3},
 month = apr,
 year = {2016},
 issn = {0164-0925},
 pages = {12:1--12:32},
 articleno = {12},
 numpages = {32},
 url = {http://doi.acm.org/10.1145/2896389},
 doi = {10.1145/2896389},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Automatic parallelization, affine transformations, locality optimization, loop transformations, polyhedral model, tiling},
}

@inproceedings{Eisenbeis:ics:1992,
 author = {Eisenbeis, Christine and Sogno, Jean-Claude},
 title = {{A General Algorithm for Data Dependence Analysis}},
 booktitle = {Proceedings of the 6th International Conference on Supercomputing},
 series = {ICS '92},
 year = {1992},
 isbn = {0-89791-485-6},
 location = {Washington, D. C., USA},
 pages = {292--302},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/143369.143422},
 doi = {10.1145/143369.143422},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Baghdadi:pact:2015,
  author = {Baghdadi, Riyadh and Beaugnon, Ulysse and Cohen, Albert and Grosser, Tobias and Kruse, Michael and Reddy, Chandan and Verdoolaege, Sven and Betts, Adam and Donaldson, Alastair F. and Ketema, Jeroen and Absar, Javed and Haastregt, Sven van and Kravets, Alexey and Lokhmotov, Anton and David, Robert and Hajiyev, Elnar},
  title = {{PENCIL: A Platform-Neutral Compute Intermediate Language for Accelerator Programming}},
  booktitle = {Proceedings of the 2015 International Conference on Parallel Architecture and Compilation (PACT)},
  series = {PACT '15},
  year = {2015},
  isbn = {978-1-4673-9524-3},
  pages = {138--149},
  numpages = {12},
  volume = {},
  number = {},
  pages = {138-149},
  keywords = {application program interfaces;graphics processing units;parallel architectures;parallel programming;program compilers;specification languages;platform-neutral compute intermediate language;accelerator programming;GPUs;low-level APIs;CUDA;automatic parallelization;domain specific languages;performance portability;GNU C99;portable implementation language;DSL compilers;PENCIL-to-OpenCL backend;polyhedral compiler;data-dependent control flow;nonaffine array accesses;image processing kernels;Rodinia suites;SHOC suites;DSL embedding scenarios;linear algebra;signal processing radar applications;SpearDE;AMD Radeon HD 5670 GPU platform;R9 285 GPU platform;NVIDIA GTX 470 GPU platform;ARM Mali-T604 GPU platform;DSL;Optimization;Kernel;Image processing;Graphics processing units;Benchmark testing;Arrays;automatic optimization;intermediate language;polyhedral model;domain specific languages;OpenCL,polyhedral},
  doi = {10.1109/PACT.2015.17},
  issn = {1089-795X},
  month = oct,
  publisher = {IEEE Computer Society},
  address = {Washington, DC, USA},
  url = {https://ieeexplore.ieee.org/document/7429301},
  doi = {10.1109/PACT.2015.17},
}

@article{Grosser:toplas:2015,
 author = {Grosser, Tobias and Verdoolaege, Sven and Cohen, Albert},
 title = {{Polyhedral AST Generation Is More Than Scanning Polyhedra}},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {August 2015},
 volume = {37},
 number = {4},
 month = jul,
 year = {2015},
 issn = {0164-0925},
 pages = {12:1--12:50},
 articleno = {12},
 numpages = {50},
 url = {http://doi.acm.org/10.1145/2743016},
 doi = {10.1145/2743016},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Polyhedral compilation, Presburger relations, code generation, index set splitting, unrolling},
}

@inproceedings{Grosser:cgo:2014,
 author = {Grosser, Tobias and Cohen, Albert and Holewinski, Justin and Sadayappan, P. and Verdoolaege, Sven},
 title = {{Hybrid Hexagonal/Classical Tiling for GPUs}},
 booktitle = {Proceedings of Annual IEEE/ACM International Symposium on Code Generation and Optimization},
 series = {CGO '14},
 year = {2014},
 isbn = {978-1-4503-2670-4},
 location = {Orlando, FL, USA},
 pages = {66:66--66:75},
 articleno = {66},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2544137.2544160},
 doi = {10.1145/2544137.2544160},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CUDA, GPGPU, Polyhedral compilation, code generation, loop transformations, stencil, time tiling},
}

@inproceedings{Grosser:gpgpu:2013,
 title = {{Split tiling for {GPU}s: automatic parallelization using trapezoidal tiles}},
 author = {Grosser, Tobias and Cohen, Albert and Kelly, Paul H. J. and Ramanujam, J. and Sadayappan, P. and Verdoolaege, Sven},
 booktitle = {Proceedings of the 6th Workshop on General Purpose Processor Using Graphics Processing Units},
 series = {GPGPU-6},
 pages = {24--31},
 numpages = {8},
 year = {2013},
 location = {Houston, Texas, USA},
 publisher = {ACM},
 address = {New York, NY, USA},
 isbn = {978-1-4503-2017-7},
 pdf = {http://hal.inria.fr/hal-00786812/PDF/paper.pdf},
 url = {http://doi.acm.org/10.1145/2458523.2458526},
 doi = {10.1145/2458523.2458526},
 keywords = {CUDA, GPGPU, code generation, compilers, index set splitting, loop transformations, polyhedral model, stencil, time tiling},
 abstract = {
  Tiling is a key technique to enhance data reuse. For computations structured as
one sequential outer "time" loop enclosing a set of parallel inner loops,
tiling only the parallel inner loops may not enable enough data reuse in the
cache. Tiling the inner loops along with the outer time loop enhances data
locality but may require other transformations like loop skewing that inhibit
inter-tile parallelism.

One approach to tiling that enhances data locality without inhibiting
inter-tile parallelism is split tiling, where tiles are subdivided into a
sequence of trapezoidal computation steps. In this paper, we develop an
approach to generate split tiled code for GPUs in the PPCG polyhedral code
generator. We propose a generic algorithm to calculate index-set splitting that
enables us to perform tiling for locality and synchronization avoidance, while
simultaneously maintaining parallelism, without the need for skewing or
redundant computations. Our algorithm performs split tiling for an arbitrary
number of dimensions and without the need to construct any large integer linear
program. The method and its implementation are evaluated on standard stencil
kernels and compared with a state-of-the-art polyhedral compiler and with a
domain-specific stencil compiler, both targeting CUDA GPUs.
}
}

@article{Baghdadi:taco:2013,
 author = {Baghdadi, Riyadh and Cohen, Albert and Verdoolaege, Sven and Trifunovi\'{c}, Konrad},
 title = {{Improved Loop Tiling Based on the Removal of Spurious False Dependences}},
 journal = {ACM Trans. Archit. Code Optim.},
 issue_date = {January 2013},
 volume = {9},
 number = {4},
 month = {January},
 year = {2013},
 issn = {1544-3566},
 pages = {52:1--52:26},
 articleno = {52},
 numpages = {26},
 url = {http://doi.acm.org/10.1145/2400682.2400711},
 doi = {10.1145/2400682.2400711},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Tiling, compiler, expansion, false dependences, memory-based dependences, polyhedral},
}

@article{Verdoolaege:taco:2013,
 author = {Verdoolaege, Sven and Carlos Juega, Juan and Cohen, Albert and P\'{e}rez, Jos\'{e} Ignacio G\'{o}mez and Tenllado, Christian and Catthoor, Francky},
 title = {{Polyhedral Parallel Code Generation for CUDA}},
 journal = {ACM Trans. Archit. Code Optim.},
 issue_date = {January 2013},
 volume = {9},
 number = {4},
 month = jan,
 year = {2013},
 issn = {1544-3566},
 pages = {54:1--54:23},
 articleno = {54},
 numpages = {23},
 url = {http://doi.acm.org/10.1145/2400682.2400713},
 doi = {10.1145/2400682.2400713},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {C-to-CUDA, CUDA, GPU, PPCG., Par4All, Polyhedral model, code generation, compilers, loop transformations, polyhedral},
}

@article{Verdoolaege:toplas:2012,
 author = {Verdoolaege, Sven and Janssens, Gerda and Bruynooghe, Maurice},
 title = {{Equivalence Checking of Static Affine Programs Using Widening to Handle Recurrences}},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {October 2012},
 volume = {34},
 number = {3},
 month = nov,
 year = {2012},
 issn = {0164-0925},
 pages = {11:1--11:35},
 articleno = {11},
 numpages = {35},
 url = {http://doi.acm.org/10.1145/2362389.2362390},
 doi = {10.1145/2362389.2362390},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Commutativity, equivalence checking, polytope model, recurrences, widening},
}

@inproceedings{Verdoolaege:sas:2011,
 author = {Verdoolaege, Sven and Cohen, Albert and Beletska, Anna},
 title = {{Transitive Closures of Affine Integer Tuple Relations and Their Overapproximations}},
 booktitle = {Proceedings of the 18th International Conference on Static Analysis},
 series = {SAS'11},
 year = {2011},
 isbn = {978-3-642-23701-0},
 location = {Venice, Italy},
 pages = {216--232},
 numpages = {17},
 url = {http://dl.acm.org/citation.cfm?id=2041552.2041570},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@article{Verdoolaege:jet:2010,
 title = {{Experience with Widening Based Equivalence Checking in Realistic Multimedia Systems}},
 author = {Verdoolaege, Sven and Palkovi{\v{c}}, Martin and Bruynooghe, Maurice and Janssens, Gerda and Catthoor, Francky},
 journal = {Journal of Electronic Testing},
 volume = {26},
 number = {2},
 month = apr,
 pages = {279--292},
 numpages = {14},
 year = {2010},
 issn = {0923-8174},
 url = {http://www.cs.kuleuven.be/publicaties/rapporten/cw/CW572.pdf},
 doi = {10.1007/s10836-009-5140-4},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {Formal verification, Static affine programs, Widening, polyhedral},
 abstract = {
  The application of loop and data transformations to array and loop intensive
programs is crucial to obtain a good performance. Designers often apply these
transformations manually or semi-automatically. For the class of static affine
programs, automatic methods exist for proving the correctness of these
transformations. Realistic multimedia systems, however, often contain
constructs that fall outside of this class. We present an extension of a
widening based approach to handle the most relevant of these constructs, viz.
accesses to array slices, data dependent accesses and data dependent
assignments, and report on some experiments with non-trivial applications.
}
}

@article{Clauss:tvlsi:2009,
 author = {Clauss, Philippe and Fern\'{a}ndez, Federico Javier and Garbervetsky, Diego and Verdoolaege, Sven},
 title = {{Symbolic Polynomial Maximization over Convex Sets and Its Application to Memory Requirement Estimation}},
 journal = {IEEE Trans. Very Large Scale Integr. Syst.},
 issue_date = {August 2009},
 volume = {17},
 number = {8},
 month = aug,
 year = {2009},
 issn = {1063-8210},
 pages = {983--996},
 numpages = {14},
 url = {http://dx.doi.org/10.1109/TVLSI.2008.2002049},
 doi = {10.1109/TVLSI.2008.2002049},
 publisher = {IEEE Educational Activities Department},
 address = {Piscataway, NJ, USA},
 keywords = {Bernstein expansion, convex polytopes, memory requirement, program optimization, static program analysis},
}

@inproceedings{Verdoolaege:cav:2009,
 author = {Verdoolaege, Sven and Janssens, Gerda and Bruynooghe, Maurice},
 title = {{Equivalence Checking of Static Affine Programs Using Widening to Handle Recurrences}},
 booktitle = {Proceedings of the 21st International Conference on Computer Aided Verification},
 series = {CAV '09},
 month = {June},
 year = {2009},
 isbn = {978-3-642-02657-7},
 location = {Grenoble, France},
 pages = {599--613},
 numpages = {15},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 url = {http://www.cs.kuleuven.ac.be/publicaties/rapporten/cw/CW565.pdf},
 doi = {10.1007/978-3-642-02658-4\_44},
 keywords = {polyhedral},
 abstract = {
  Designers often apply manual or semi-automatic loop and data transformations on
array and loop intensive programs to improve performance. The transformations
should preserve the functionality, however, and this paper presents an
automatic method for constructing equivalence proofs for the class of static
affine programs. The equivalence checking is performed on a dependence graph
abstraction and uses a new approach based on widening to handle recurrences.
Unlike transitive closure based approaches, this widening approach can also
handle non-uniform recurrences. The implementation is publicly available and is
the first of its kind to fully support commutative operations.
}
}

@article{Kjeldsberg:jsps:2008,
 author = {Kjeldsberg, Per Gunnar and Catthoor, Francky and Verdoolaege, Sven and Palkovi\v{c}, Martin and Vandecappelle, Arnout and Hu, Qubo and Aas, Einar J.},
 title = {{Guidance of Loop Ordering for Reduced Memory Usage in Signal Processing Applications}},
 journal = {J. Signal Process. Syst.},
 issue_date = {December  2008},
 volume = {53},
 number = {3},
 month = dec,
 year = {2008},
 issn = {1939-8018},
 pages = {301--321},
 numpages = {21},
 url = {http://dx.doi.org/10.1007/s11265-008-0178-6},
 doi = {10.1007/s11265-008-0178-6},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Code transformation, High level synthesis, Memory architecture exploration, Memory optimization, Multi-media},
}

@article{Verdoolaege:jsc:2008,
 author = {Verdoolaege, Sven and Woods, Kevin},
 title = {{Counting with Rational Generating Functions}},
 journal = {J. Symb. Comput.},
 issue_date = {February, 2008},
 volume = {43},
 number = {2},
 month = feb,
 year = {2008},
 issn = {0747-7171},
 pages = {75--91},
 numpages = {17},
 url = {http://dx.doi.org/10.1016/j.jsc.2007.07.007},
 doi = {10.1016/j.jsc.2007.07.007},
 publisher = {Academic Press, Inc.},
 address = {Duluth, MN, USA},
 keywords = {Barvinok algorithm, Parametric counting functions, Parametric polytopes, Piecewise quasi-polynomials, Rational generating functions, Vector partition functions},
}

@article{Verdoolaege:algorithmica:2007,
 author = {Verdoolaege, Sven and Seghir, Rachid and Beyls, Kristof and Loechner, Vincent and Bruynooghe, Maurice},
 title = {{Counting Integer Points in Parametric Polytopes Using Barvinok's Rational Functions}},
 journal = {Algorithmica},
 year = {2007},
 volume = {48},
 number = {1},
 month = mar,
 issn = {0178-4617},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
 pages = {37--66},
 numpages = {30},
 url = {http://dtai.cs.kuleuven.be/publications/files/41970.pdf},
 doi = {10.1007/s00453-006-1231-0},
 keywords = {polyhedral},
 abstract = {
  Many compiler optimization techniques depend on the ability to calculate the
number of elements that satisfy certain conditions. If these conditions can be
represented by linear constraints, then such problems are equivalent to
counting the number of integer points in (possibly) parametric polytopes. It is
well known that the enumerator of such a set can be represented by an explicit
function consisting of a set of quasi-polynomials, each associated with a
chamber in the parameter space. Previously, interpolation was used to obtain
these quasi-polynomials, but this technique has several disadvantages. Its
worst-case computation time for a single quasi-polynomial is exponential in the
input size, even for fixed dimensions. The worst-case size of such a
quasi-polynomial (measured in bits needed to represent the quasi-polynomial) is
also exponential in the input size. Under certain conditions this technique
even fails to produce a solution. Our main contribution is a novel method for
calculating the required quasi-polynomials analytically. It extends an existing
method, based on Barvinok's decomposition, for counting the number of integer
points in a non-parametric polytope. Our technique always produces a solution
and computes polynomially-sized enumerators in polynomial time (for fixed
dimensions).
}
}

@article{Verdoolaege:ejes:2007,
 title = {{PN: a tool for improved derivation of process networks}},
 author = {Verdoolaege, Sven and Nikolov, Hristo and Stefanov, Todor},
 journal = {EURASIP journal on Embedded Systems},
 issue_date = {January 2007},
 volume = {2007},
 number = {1},
 month = jan,
 pages = {19--19},
 year = {2007},
 issn = {1687-3955},
 url = {http://artemisia.liacs.nl/publications/Verdoolaege2007PN.pdf},
 doi = {10.1155/2007/75947},
 publisher = {Hindawi Publishing Corp.},
 address = {New York, NY, United States},
 keywords = {polyhedral},
 abstract = {
  Current emerging embedded System-on-Chip platforms are increasingly becoming
multiprocessor architectures. System designers experience significant
difficulties in programming these platforms. The applications are typically
specified as sequential programs that do not reveal the available parallelism
in an application, thereby hindering the effcient mapping of an application
onto a parallel multiprocessor platform. In this paper, we present our compiler
techniques for facilitating the migration from a sequential application
specification to a parallel application specification using the process network
model of computation. Our work is inspired by a previous research project
called Compaan. With our techniques we address optimization issues such as the
generation of process networks with simplified topology and communication
without sacrificing the process networks' performance. Moreover, we describe a
technique for compile-time memory requirement estimation which we consider as
an important contribution of this paper. We demonstrate the usefulness of our
techniques on several examples.
}
}

@inproceedings{Verdoolaege:cc:2005,
 author = {Verdoolaege, Sven and Beyls, Kristof and Bruynooghe, Maurice and Catthoor, Francky},
 title = {{Experiences with Enumeration of Integer Projections of Parametric Polytopes}},
 booktitle = {Proceedings of the 14th International Conference on Compiler Construction},
 series = {CC'05},
 year = {2005},
 isbn = {3-540-25411-0, 978-3-540-25411-9},
 location = {Edinburgh, UK},
 pages = {91--105},
 numpages = {15},
 url = {http://dx.doi.org/10.1007/978-3-540-31985-6\_7},
 doi = {10.1007/978-3-540-31985-6\_7},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@inproceedings{Verdoolaege:cases:2004,
 author = {Verdoolaege, Sven and Seghir, Rachid and Beyls, Kristof and Loechner, Vincent and Bruynooghe, Maurice},
 title = {{Analytical Computation of Ehrhart Polynomials: Enabling More Compiler Analyses and Optimizations}},
 booktitle = {Proceedings of the 2004 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems},
 series = {CASES '04},
 year = {2004},
 isbn = {1-58113-890-3},
 location = {Washington DC, USA},
 pages = {248--258},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1023833.1023868},
 doi = {10.1145/1023833.1023868},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Barvinok's decomposition, Ehrhart polynomial, compiler analysis, parametric polytope, polyhedral model, quasi-polynomial, signed unimodular decomposition},
}

@inproceedings{Knudsen:asiacrypt:1998,
 author = {Knudsen, Lars R. and Meier, Willi and Preneel, Bart and Rijmen, Vincent and Verdoolaege, Sven},
 title = {{Analysis Methods for (Alleged) RCA}},
 booktitle = {Proceedings of the International Conference on the Theory and Applications of Cryptology and Information Security: Advances in Cryptology},
 series = {ASIACRYPT '98},
 year = {1998},
 isbn = {3-540-65109-8},
 pages = {327--341},
 numpages = {15},
 url = {http://dl.acm.org/citation.cfm?id=647094.716579},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@inproceedings{Grosser:ics:2016,
 author = {Grosser, Tobias and Hoefler, Torsten},
 title = {{Polly-ACC Transparent Compilation to Heterogeneous Hardware}},
 booktitle = {Proceedings of the 2016 International Conference on Supercomputing},
 series = {ICS '16},
 year = {2016},
 isbn = {978-1-4503-4361-9},
 location = {Istanbul, Turkey},
 pages = {1:1--1:13},
 articleno = {1},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/2925426.2926286},
 doi = {10.1145/2925426.2926286},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Auto-Parallelization, GPGPU, Polyhedral Compilation},
}

@inproceedings{Alves:oopsla:2015,
 author = {Alves, P{\'e}ricles and Gruber, Fabian and Doerfert, Johannes and Lamprineas, Alexandros and Grosser, Tobias and Rastello, Fabrice and Pereira, Fernando Magno Quint\~{a}o},
 title = {{Runtime Pointer Disambiguation}},
 booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
 series = {OOPSLA 2015},
 year = {2015},
 isbn = {978-1-4503-3689-5},
 location = {Pittsburgh, PA, USA},
 pages = {589--606},
 numpages = {18},
 url = {http://doi.acm.org/10.1145/2814270.2814285},
 doi = {10.1145/2814270.2814285},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Alias analysis, dynamic guards, optimization},
}

@inproceedings{Gysi:ics:2015,
 author = {Gysi, Tobias and Grosser, Tobias and Hoefler, Torsten},
 title = {{MODESTO: Data-centric Analytic Optimization of Complex Stencil Programs on Heterogeneous Architectures}},
 booktitle = {Proceedings of the 29th ACM on International Conference on Supercomputing},
 series = {ICS '15},
 year = {2015},
 isbn = {978-1-4503-3559-1},
 location = {Newport Beach, California, USA},
 pages = {177--186},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2751205.2751223},
 doi = {10.1145/2751205.2751223},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {fusion, heterogeneous systems, performance model, stencil, tiling},
}

@inproceedings{Grosser:ics:2015,
 author = {Grosser, Tobias and Ramanujam, J. and Pouchet, Louis-No\"{e}l and Sadayappan, P. and Pop, Sebastian},
 title = {{Optimistic Delinearization of Parametrically Sized Arrays}},
 booktitle = {Proceedings of the 29th ACM on International Conference on Supercomputing},
 series = {ICS '15},
 year = {2015},
 isbn = {978-1-4503-3559-1},
 location = {Newport Beach, California, USA},
 pages = {351--360},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2751205.2751248},
 doi = {10.1145/2751205.2751248},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {linear memory layout, multi-dimensional arrays, polyhedral analysis},
}

@inproceedings{Stock:pldi:2014,
 author = {Stock, Kevin and Kong, Martin and Grosser, Tobias and Pouchet, Louis-No\"{e}l and Rastello, Fabrice and Ramanujam, J. and Sadayappan, P.},
 title = {{A Framework for Enhancing Data Reuse via Associative Reordering}},
 booktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
 series = {PLDI '14},
 year = {2014},
 isbn = {978-1-4503-2784-8},
 location = {Edinburgh, United Kingdom},
 pages = {65--76},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2594291.2594342},
 doi = {10.1145/2594291.2594342},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {polyhedral},
}

@inproceedings{Bastoul:pact:2004,
 author = {Bastoul, C{\'e}dric},
 title = {{Code Generation in the Polyhedral Model Is Easier Than You Think}},
 booktitle = {Proceedings of the 13th International Conference on Parallel Architectures and Compilation Techniques},
 series = {PACT '04},
 year = {2004},
 month = {September},
 isbn = {0-7695-2229-7},
 pages = {7--16},
 numpages = {10},
 url = {http://dx.doi.org/10.1109/PACT.2004.11},
 doi = {10.1109/PACT.2004.11},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {polyhedral},
 abstract = {
  Many advances in automatic parallelization and optimization have been
  achieved through the polyhedral model. It has been extensively shown that this
  computational model provides convenient abstractions to reason about and apply
  program transformations. Nevertheless, the complexity of code generation has
  long been a deterrent for using polyhedral representation in optimizing
  compilers. First, code generators have a hard time coping with generated code
  size and control overhead that may spoil theoretical benefits achieved by the
  transformations. Second, this step is usually time consuming, hampering the
  integration of the polyhedral framework in production compilers or
  feedback-directed, iterative optimization schemes. Moreover, current code
  generation algorithms only cover a restrictive set of possible transformation
  functions. This paper discusses a general transformation framework able to
  deal with non-unimodular, non-invertible, non-integral or even non-uniform
  functions. It presents several improvements to a state-of-the-art code
  generation algorithm. Two directions are explored: generated code size and
  code generator efficiency. Experimental evidence proves the ability of the
  improved method to handle real-life problems.
 }
}

@inproceedings{Bastoul:cc:2016,
 author = {Bastoul, C{\'e}dric},
 title = {{Mapping Deviation: A Technique to Adapt or to Guard Loop Transformation Intuitions for Legality}},
 booktitle = {Proceedings of the 25th International Conference on Compiler Construction},
 series = {CC 2016},
 year = {2016},
 isbn = {978-1-4503-4241-4},
 location = {Barcelona, Spain},
 pages = {229--239},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2892208.2892216},
 doi = {10.1145/2892208.2892216},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Dependence Analysis, Loop Transformations, Polyhedral Model, ompilation},
}

@inproceedings{Bastoul:ispdc:2003,
 author = {Bastoul, C{\'e}dric},
 title = {{Efficient Code Generation for Automatic Parallelization and Optimization}},
 booktitle = {Proceedings of the Second International Conference on Parallel and Distributed Computing},
 series = {ISPDC'03},
 year = {2003},
 isbn = {0-7695-2069-3},
 location = {Ljubljana, Slovenia},
 pages = {23--30},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1899290.1899294},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Vasilache:cc:2006,
 author = {Nicolas Vasilache and
           C{\'e}dric Bastoul and
           Albert Cohen},
 title = {{Polyhedral Code Generation in the Real World}},
 booktitle = {Proceedings of the 15th International Conference on Compiler Construction},
 series = {CC'06},
 year = {2006},
 pages = {185--201},
 numpages = {17},
 volume = {3923},
 isbn = {3-540-33050-X, 978-3-540-33050-9},
 location = {Vienna, Austria},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 url = {http://icps.u-strasbg.fr/~bastoul/research/papers/VBC06-CC.pdf},
 doi = {10.1007/11688839\_16},
 keywords = {polyhedral},
 abstract = {
  The polyhedral model is known to be a powerful framework to reason about high
level loop transformations. Recent developments in optimizing compilers broke
some generally accepted ideas about the limitations of this model. First,
thanks to advances in dependence analysis for irregular access patterns, its
applicability which was supposed to be limited to very simple loop nests has
been extended to wide code regions. Then, new algorithms made it possible to
compute the target code for hundreds of statements while this code generation
step was expected not to be scalable. Such theoretical advances and new
software tools allowed actors from both academia and industry to study more
complex and realistic cases. Unfortunately, despite strong optimization
potential of a given transformation for e.g., parallelism or data locality,
code generation may still be challenging or result in high control overhead.
This paper presents scalable code generation methods that make possible the
application of increasingly complex program transformations. By studying the
transformations themselves, we show how it is possible to benefit from their
properties to dramatically improve both code generation quality and space/time
complexity, with respect to the best state-of-the-art code generation tool. In
addition, we build on these improvements to present a new algorithm improving
generated code performance for strided domains and reindexed schedules.
}
}

@article{Girbal:ijpp:2006,
 author = {Girbal, Sylvain and Vasilache, Nicolas and Bastoul, C{\'e}dric and Cohen, Albert and Parello, David and Sigler, Marc and Temam, Olivier},
 title = {{Semi-automatic Composition of Loop Transformations for Deep Parallelism and Memory Hierarchies}},
 journal = {Int. J. Parallel Program.},
 issue_date = {June 2006},
 volume = {34},
 number = {3},
 month = jun,
 year = {2006},
 issn = {0885-7458},
 pages = {261--317},
 numpages = {57},
 url = {http://dx.doi.org/10.1007/s10766-006-0012-3},
 doi = {10.1007/s10766-006-0012-3},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {automatic parallelization, compiler optimization, polyhedral model, semi-automatic program transformation}
}

@inproceedings{Vasilache:ics:2006,
  author = {Vasilache, Nicolas and Bastoul, C\'{e}dric and Cohen, Albert and Girbal, Sylvain},
  title = {{Violated Dependence Analysis}},
  year = {2006},
  isbn = {1595932828},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1183401.1183448},
  doi = {10.1145/1183401.1183448},
  abstract = {The polyhedral model is a powerful framework to reason about high level loop transformations. Yet the lack of scalable algorithms and tools has deterred actors from both academia and industry to put this model to practical use. Indeed, for fundamental complexity reasons, its applicability has long been limited to simple kernels. Recent developments broke some generally accepted ideas about these limitations. In particular, new algorithms made it possible to compute the target code for full SPEC benchmarks while this code generation step was expected not to be scalable.Instancewise array dependence analysis computes a finite, intensional representation of the (statically unbounded) set of all dynamic dependences. This problem has always been considered non-scalable and/or an overkill with respect to less expressive and faster dependence tests. On the contrary, this article presents experimental evidence of its applicability to full SPEC CPU2000 benchmarks. To make this possible, we revisit the characterization of data dependences, considering relations between time dimensions of the transformed space. Beyond algorithmic benefits, this naturally leads to a novel way of reasoning about violated dependences across arbitrary transformation sequences. Reasoning about violated dependences relieves the compiler designer from the cumbersome task of implementing specific legality checks for each single transformation. It also allows, in the case of invalid transformations, to precisely determine the violated dependences that need to be corrected. Identifying these violations can in turn enable automatic correction schemes to fix an illegal transformation sequence with minimal changes.},
  booktitle = {Proceedings of the 20th Annual International Conference on Supercomputing},
  pages = {335–344},
  numpages = {10},
  keywords = {data race},
  location = {Cairns, Queensland, Australia},
  series = {ICS '06}
}

@inproceedings{Pouchet:cgo:2007,
 author = {Pouchet, Louis-No\"{e}l and Bastoul, C{\'e}dric and Cohen, Albert and Vasilache, Nicolas},
 title = {{Iterative Optimization in the Polyhedral Model: Part I, One-Dimensional Time}},
 booktitle = {Proceedings of the International Symposium on Code Generation and Optimization},
 series = {CGO '07},
 year = {2007},
 isbn = {0-7695-2764-7},
 pages = {144--156},
 numpages = {13},
 keywords = {polyhedral},
 url = {http://www.cse.ohio-state.edu/~pouchet/doc/cgo-article.07.pdf},
 doi = {10.1109/CGO.2007.21},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{Salva:iwomp:2007,
 author = {Salva, S{\'e}bastien and Delamare, Cl{\'e}ment and Bastoul, C{\'e}dric},
 title = {{Web Service Call Parallelization Using OpenMP}},
 booktitle = {Proceedings of the 3rd International Workshop on OpenMP: A Practical Programming Model for the Multi-Core Era},
 series = {IWOMP '07},
 year = {2008},
 isbn = {978-3-540-69302-4},
 location = {Beijing, China},
 pages = {185--194},
 numpages = {10},
 url = {http://dx.doi.org/10.1007/978-3-540-69303-1\_21},
 doi = {10.1007/978-3-540-69303-1\_21},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@inproceedings{Pouchet:pldi:2008,
 author = {Pouchet, Louis-No\"{e}l and Bastoul, C{\'e}dric and Cohen, Albert and Cavazos, John},
 title = {{Iterative Optimization in the Polyhedral Model: Part Ii, Multidimensional Time}},
 booktitle = {Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation},
 series = {PLDI '08},
 year = {2008},
 isbn = {978-1-59593-860-2},
 location = {Tucson, AZ, USA},
 pages = {90--100},
 numpages = {11},
 url = {http://www.cse.ohio-state.edu/~pouchet/doc/pldi-article.08.pdf},
 doi = {10.1145/1375581.1375594},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {affine scheduling, genetic algorithm, iterative compilation, loop transformation, polyhedral},
}

@inproceedings{Hartono:ics:2009,
 author = {Hartono, Albert and Baskaran, Muthu Manikandan and Bastoul, C{\'e}dric and Cohen, Albert and Krishnamoorthy, Sriram and Norris, Boyana and Ramanujam, J. and Sadayappan, P.},
 title = {{Parametric Multi-level Tiling of Imperfectly Nested Loops}},
 booktitle = {Proceedings of the 23rd International Conference on Supercomputing},
 series = {ICS '09},
 year = {2009},
 isbn = {978-1-60558-498-0},
 location = {Yorktown Heights, NY, USA},
 pages = {147--157},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1542275.1542301},
 doi = {10.1145/1542275.1542301},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {imperfectly nested loops, parametric tiling},
}

@inproceedings{Leung:gpgpu:2010,
 author = {Leung, Allen and Vasilache, Nicolas and Meister, Beno\^{\i}t and
Baskaran, Muthu Manikandan and Wohlford, David and Bastoul, C{\'e}dric and Lethin,
Richard},
 title = {{A Mapping Path for multi-GPGPU Accelerated Computers from a Portable High Level Programming Abstraction}},
 booktitle = {Proceedings of the 3rd Workshop on General-Purpose Computation on Graphics Processing Units},
 series = {GPGPU-3},
 year = {2010},
 pages = {51--61},
 numpages = {11},
 isbn = {978-1-60558-935-0},
 location = {Pittsburgh, Pennsylvania, USA},
 publisher = {ACM},
 address = {New York, NY, USA},
 url = {http://www.researchgate.net/publication/220938996_A_mapping_path_for_multi-GPGPU_accelerated_computers_from_a_portable_high_level_programming_abstraction/file/79e41502512b8a3f2b.pdf},
 doi = {10.1145/1735688.1735698},
 keywords = {CUDA, GPGPU, automatic translation, compiler optimziation, parallelization, polyhedral model},
 abstract = {
  Programmers for GPGPU face rapidly changing substrate of programming
abstractions, execution models, and hardware implementations. It has been
established, through numerous demonstrations for particular conjunctions of
application kernel, programming languages, and GPU hardware instance, that it
is possible to achieve significant improvements in the price/performance and
energy/performance over general purpose processors. But these demonstrations
are each the result of significant dedicated programmer labor, which is likely
to be duplicated for each new GPU hardware architecture to achieve performance
portability.

This paper discusses the implementation, in the R-Stream compiler, of a source
to source mapping pathway from a high-level, textbook-style algorithm
expression method in ANSI C, to multi-GPGPU accelerated computers. The compiler
performs hierarchical decomposition and parallelization of the algorithm
between and across host, multiple GPGPUs, and within-GPU. The semantic
transformations are expressed within the polyhedral model, including
optimization of integrated parallelization, locality, and contiguity tradeoffs.
Hierarchical tiling is performed. Communication and synchronizations operations
at multiple levels are generated automatically. The resulting mapping is
currently emitted in the CUDA programming language.

The GPU backend adds to the range of hardware and accelerator targets for
R-Stream and indicates the potential for performance portability of single
sources across multiple hardware targets.
}
}

@inproceedings{Bagneres:cgo:2016,
 author = {Bagn\`{e}res, L{\'e}na\"{\i}c and Zinenko, Oleksandr and Huot, St{\'e}phane and Bastoul, C{\'e}dric},
 title = {{Opening Polyhedral Compiler's Black Box}},
 booktitle = {Proceedings of the 2016 International Symposium on Code Generation and Optimization},
 series = {CGO 2016},
 year = {2016},
 isbn = {978-1-4503-3778-6},
 location = {Barcelona, Spain},
 pages = {128--138},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2854038.2854048},
 doi = {10.1145/2854038.2854048},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Compiler Optimization, Interactive Compilation, Loop Transformations},
}

@inproceedings{Bao:popl:2016,
 author = {Bao, Wenlei and Krishnamoorthy, Sriram and Pouchet, Louis-No\"{e}l and Rastello, Fabrice and Sadayappan, P.},
 title = {{PolyCheck: Dynamic Verification of Iteration Space Transformations on Affine Programs}},
 booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
 series = {POPL '16},
 year = {2016},
 isbn = {978-1-4503-3549-2},
 location = {St. Petersburg, FL, USA},
 pages = {539--554},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/2837614.2837656},
 doi = {10.1145/2837614.2837656},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Dynamic verification, iteration space transformation, static analysis},
}

@inproceedings{Rauchwerger:pldi:1995,
 author = {Rauchwerger, Lawrence and Padua, David A.},
 title = {{The LRPD Test: Speculative Run-time Parallelization of Loops with Privatization and Reduction Parallelization}},
 booktitle = {Proceedings of the ACM SIGPLAN 1995 Conference on Programming Language Design and Implementation},
 series = {PLDI '95},
 year = {1995},
 isbn = {0-89791-697-2},
 location = {La Jolla, California, USA},
 pages = {218--232},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/207110.207148},
 doi = {10.1145/207110.207148},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Kuck:popl:1981,
 author = {David J. Kuck and Robert H. Kuhn and David A. Padua and Bruce Leasure and Michael J. Wolfe},
 title = {{Dependence Graphs and Compiler Optimizations}},
 booktitle = {Proceedings of the 8th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
 series = {POPL '81},
 year = {1981},
 isbn = {0-89791-029-X},
 location = {Williamsburg, Virginia},
 pages = {207--218},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/567532.567555},
 doi = {10.1145/567532.567555},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Padua:cacm:1986,
 author = {Padua, David A. and Wolfe, Michael J.},
 title = {{Advanced Compiler Optimizations for Supercomputers}},
 journal = {Commun. ACM},
 issue_date = {Dec. 1986},
 volume = {29},
 number = {12},
 month = dec,
 year = {1986},
 issn = {0001-0782},
 pages = {1184--1201},
 numpages = {18},
 url = {http://doi.acm.org/10.1145/7902.7904},
 doi = {10.1145/7902.7904},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Budnik:tc:1971,
 author = {Budnik, Paul and Kuck, David J.},
 title = {{The Organization and Use of Parallel Memories}},
 journal = {IEEE Trans. Comput.},
 issue_date = {December 1971},
 volume = {20},
 number = {12},
 month = dec,
 year = {1971},
 issn = {0018-9340},
 pages = {1566--1569},
 numpages = {4},
 url = {http://dx.doi.org/10.1109/T-C.1971.223171},
 doi = {10.1109/T-C.1971.223171},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Memory conflicts, parallel computer, parallel memory, pipeline computer, skewed array storage.},
}

@inproceedings{Cybenko:ics:1990,
 author = {Cybenko, George and Kipp, Lyle and Pointer, Lynn and Kuck, David J.},
 title = {{Supercomputer Performance Evaluation and the Perfect Benchmarks}},
 booktitle = {Proceedings of the 4th International Conference on Supercomputing},
 series = {ICS '90},
 year = {1990},
 isbn = {0-89791-369-8},
 location = {Amsterdam, The Netherlands},
 pages = {254--266},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/77726.255163},
 doi = {10.1145/77726.255163},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Kuck:csur:1977,
 author = {Kuck, David J.},
 title = {{A Survey of Parallel Machine Organization and Programming}},
 journal = {ACM Comput. Surv.},
 issue_date = {March 1977},
 volume = {9},
 number = {1},
 month = mar,
 year = {1977},
 issn = {0360-0300},
 pages = {29--59},
 numpages = {31},
 url = {http://doi.acm.org/10.1145/356683.356686},
 doi = {10.1145/356683.356686},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Censier:tc:1978,
 author = {Censier, Lucien M. and Feautrier, Paul},
 title = {{A New Solution to Coherence Problems in Multicache Systems}},
 journal = {IEEE Trans. Comput.},
 issue_date = {December 1978},
 volume = {27},
 number = {12},
 month = dec,
 year = {1978},
 issn = {0018-9340},
 pages = {1112--1118},
 numpages = {7},
 url = {http://dx.doi.org/10.1109/TC.1978.1675013},
 doi = {10.1109/TC.1978.1675013},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Caches, coherence, memory hierarchy, multiprocessor systems, nonstore-through, nonstore-through, Caches, coherence, memory hierarchy, multiprocessor systems},
}

@inbook{Feautrier:book:1996,
 author = {Paul Feautrier},
 title = {{Automatic Parallelization in the Polytope Model}},
 booktitle = {The Data Parallel Programming Model: Foundations, HPF Realization, and Scientific Applications},
 chapter = {6},
 year = {1996},
 editor = {Perrin, Guy-Ren{\'e} and Darte, Alain},
 publisher = {Springer-Verlag},
 volume = {1132},
 pages = {79--103},
 series = {LNCS},
 isbn = {978-3-540-70646-5},
 doi = {10.1007/3-540-61736-1_44},
 url = {http://www.researchgate.net/publication/2508644\_Automatic\_Parallelization\_in\_the\_Polytope\_Model/file/5046351a4f6b578814.pdf},
 keywords = {polyhedral},
 abstract = {
  The aim of this paper is to explain the importance of polytope and polyhedra in
automatic parallelization. We show that the semantics of parallel programs is
best described geometrically, as properties of sets of integral points in
n-dimensional spaces, where n is related to the maximum nesting depth of DO
loops. The needed properties translate nicely to properties of polyhedra, for
which many algorithms have been designed for the needs of optimization and
operation research. We show how these ideas apply to scheduling, placement and
parallel code generation.
}
}

@inproceedings{Feautrier:ics:1988,
 title = {{Array Expansion}},
 author = {Feautrier, Paul},
 booktitle = {Proceedings of the 2nd International Conference on Supercomputing},
 series = {ICS '88},
 pages = {429--441},
 numpages = {13},
 year = {1988},
 isbn = {0-89791-272-1},
 location = {St. Malo, France},
 url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.5704&rep=rep1&type=pdf},
 doi = {10.1145/55364.55406},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {polyhedral},
 abstract = {
  A common problem in restructuring programs for vector or parallel execution is
the suppression of false dependencies which originate in the reuse of the same
memory cell for unrelated values. The method is simple and well understood in
the case of scalars. This paper gives the general solution for the case of
arrays. The expansion is done in two steps: first, modify all definitions of
the offending array in order to obtain the single assignment property. Then,
reconstruct the original data flow by adapting all uses of the array. This is
done with the help of a new algorithm for solving parametric integer programs.
The technique is quite general and may be used for other purposes, including
program checking, collecting array predicates, etc ...
},
}

@article{Lefebvre:pc:1998,
 author = {Lefebvre, Vincent and Feautrier, Paul},
 title = {{Automatic Storage Management for Parallel Programs}},
 journal = {Parallel Comput.},
 issue_date = {May, 1998},
 volume = {24},
 number = {3-4},
 month = may,
 year = {1998},
 issn = {0167-8191},
 pages = {649--671},
 numpages = {23},
 url = {http://dx.doi.org/10.1016/S0167-8191(98)00029-5},
 doi = {10.1016/S0167-8191(98)00029-5},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {array dataflow analysis, automatic parallelization, memory management, scheduling},
}

@article{Barthou:jpdc:1997,
 author = {Barthou, Denis and Collard, Jean-Fran\c{c}ois and Feautrier, Paul},
 title = {{Fuzzy Array Dataflow Analysis}},
 journal = {J. Parallel Distrib. Comput.},
 issue_date = {Feb. 1997},
 volume = {40},
 number = {2},
 month = feb,
 year = {1997},
 issn = {0743-7315},
 pages = {210--226},
 numpages = {17},
 url = {http://dx.doi.org/10.1006/jpdc.1996.1261},
 doi = {10.1006/jpdc.1996.1261},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
}

@inproceedings{Alias:sas:2010,
 author = {Alias, Christophe and Darte, Alain and Feautrier, Paul and Gonnord, Laure},
 title = {{Multi-dimensional Rankings, Program Termination, and Complexity Bounds of Flowchart Programs}},
 booktitle = {Proceedings of the 17th International Conference on Static Analysis},
 series = {SAS'10},
 year = {2010},
 isbn = {3-642-15768-8, 978-3-642-15768-4},
 location = {Perpignan, France},
 pages = {117--133},
 numpages = {17},
 url       = {https://doi.org/10.1007/978-3-642-15769-1\_8},
 doi       = {10.1007/978-3-642-15769-1\_8},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@inproceedings{Feautrier:lcpc:1994,
  author = {Feautrier, Paul},
  title = {{Fine-Grain Scheduling Under Resource Constraints}},
  booktitle = {Proceedings of the 7th International Workshop on Languages and Compilers for Parallel Computing},
  series = {LCPC '94},
  year = {1995},
  isbn = {3-540-58868-X},
  pages = {1--15},
  numpages = {15},
  url       = {https://doi.org/10.1007/BFb0025867},
  doi       = {10.1007/BFb0025867},
  publisher = {Springer-Verlag},
  address = {London, UK, UK},
}

@article{Feautrier:ijpp:1991,
 title = {{Dataflow Analysis of Array and Scalar References}},
 author = {Feautrier, Paul},
 journal = {International Journal of Parallel Programming},
 volume = {20},
 number = {1},
 pages = {23--53},
 year = {1991},
 publisher = {Springer},
 keywords = {polyhedral},
 issn      = {1573-7640},
 url       = {http://dx.doi.org/10.1007/BF01407931},
 doi       = {10.1007/BF01407931},
 abstract = {
  Given a program written in a simple imperative language (assignment
  statements,for loops, affine indices and loop limits), this paper presents an
  algorithm for analyzing the patterns along which values flow as the execution
  proceeds. For each array or scalar reference, the result is the name and
  iteration vector of the source statement as a function of the iteration
  vector of the referencing statement. The paper discusses several applications
  of the method: conversion of a program to a set of recurrence equations,
  array and scalar expansion, program verification and parallel program
  construction.
 }
}

@article{Griebl:ijpp:2000,
 title = {{Index set splitting}},
 author = {Griebl, Martin and Feautrier, Paul and Lengauer, Christian},
 journal = {International Journal of Parallel Programming},
 volume = {28},
 number = {6},
 month = dec,
 pages = {607--631},
 numpages = {25},
 year = {2000},
 issn = {0885-7458},
 publisher = {Plenum Press},
 address = {New York, NY, USA},
 url = {http://www.infosun.fim.uni-passau.de/cl/publications/docs/GFL00ijpp.pdf},
 doi = {10.1023/A:1007516818651},
 keywords = {automatic loop parallelization, polytope model, scheduling, polyhedral},
 abstract = {
  There are many algorithms for the space-time mapping of nested loops. Some
of them even make the optimal choices within their framework. We propose a
preprocessing phase for algorithms in the polytope model, which extends the
model and yields space-time mappings whose schedule is, in some cases, orders
of magnitude faster. These are cases in which the dependence graph has small
irregularities. The basic idea is to split the index set of the loop nests into parts
with a regular dependence structure and apply the existing space-time mapping
algorithms to these parts individually. This work is based on a seminal idea in
the more limited context of loop parallelization at the code level. We elevate the
idea to the model level (our model is the polytope model), which increases its
applicability by providing a clearer and wider range of choices at an acceptable
analysis cost. Index set splitting is one facet in the effort to extend the power of
the polytope model and to enable the generation of competitive target code.}
}

@inproceedings{Triolet:cc:1986,
 author = {Triolet, R{\'e}mi and Irigoin, Fran\c{c}ois and Feautrier, Paul},
 title = {{Direct Parallelization of Call Statements}},
 booktitle = {Proceedings of the 1986 SIGPLAN Symposium on Compiler Construction},
 series = {SIGPLAN '86},
 year = {1986},
 isbn = {0-89791-197-0},
 location = {Palo Alto, California, USA},
 pages = {176--185},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/12276.13329},
 doi = {10.1145/12276.13329},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Allen:toplas:1987,
 author = {Allen, Randy and Kennedy, Ken},
 title = {{Automatic Translation of FORTRAN Programs to Vector Form}},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {Oct. 1987},
 volume = {9},
 number = {4},
 month = oct,
 year = {1987},
 issn = {0164-0925},
 pages = {491--542},
 numpages = {52},
 url = {http://doi.acm.org/10.1145/29873.29875},
 doi = {10.1145/29873.29875},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Wolfe:tpds:1992,
 author = {Wolfe, Michael J. and  Tseng, Chau-Wen},
 title = {{The Power Test for Data Dependence}},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 issue_date = {September 1992},
 volume = {3},
 number = {5},
 month = sep,
 year = {1992},
 issn = {1045-9219},
 pages = {591--601},
 numpages = {11},
 url = {http://dx.doi.org/10.1109/71.159042},
 doi = {10.1109/71.159042},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Fourier-Motzkin method, Index Termsvariable elimination, compiler, data dependence decision algorithm, extended GCDalgorithm, inequalities, interactive program restructuring environment, parallel algorithms, parallel programming, power test, program compilers, programming theory, simultaneous loop limits},
}

@book{Banerjee:book:2013a,
 author = {Banerjee, Utpal K.},
 title = {{Loop Transformations for Restructuring Compilers: The Foundations}},
 year = {2013},
 isbn = {1475783507, 9781475783506},
 publisher = {Springer Publishing Company, Incorporated},
}

@book{Banerjee:book:2013b,
 author = {Banerjee, Utpal K.},
 title = {{Dependence Analysis}},
 year = {2013},
 isbn = {1475770588, 9781475770582},
 publisher = {Springer Publishing Company, Incorporated},
}

@article{Banerjee:toplas:2011,
 author = {Banerjee, Utpal K.},
 title = {{Mathematical Foundation of Trace Scheduling}},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {April 2011},
 volume = {33},
 number = {3},
 month = may,
 year = {2011},
 issn = {0164-0925},
 pages = {10:1--10:24},
 articleno = {10},
 numpages = {24},
 url = {http://doi.acm.org/10.1145/1961204.1961206},
 doi = {10.1145/1961204.1961206},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Trace scheduling, compensation code, trace replacement},
}

@inproceedings{Kejariwal:cf:2010,
  author = {Kejariwal, Arun and Girkar, Milind and Tian, Xinmin and Saito, Hideki and Nicolau, Alexandru and Veidenbaum, Alexander V. and Banerjee, Utpal K. and Polychronopoulos, Constantine D.},
  title = {{Exploitation of Nested Thread-level Speculative Parallelism on Multi-core Systems}},
  booktitle = {Proceedings of the 7th ACM International Conference on Computing Frontiers},
  series = {CF '10},
  year = {2010},
  isbn = {978-1-4503-0044-5},
  location = {Bertinoro, Italy},
  pages = {99--100},
  numpages = {2},
  url = {http://doi.acm.org/10.1145/1787275.1787302},
  doi = {10.1145/1787275.1787302},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {performance, thread-level speculation},
}

@inproceedings{Kejariwal:icpe:2010,
 author = {Kejariwal, Arun and Girkar, Milind and Tian, Xinmin and Saito, Hideki and Nicolau, Alexandru and Veidenbaum, Alexander V. and Banerjee, Utpal K. and Polychronopoulos, Constantine D.},
 title = {{On the Efficacy of Call Graph-level Thread-level Speculation}},
 booktitle = {Proceedings of the First Joint WOSP/SIPEW International Conference on Performance Engineering},
 series = {WOSP/SIPEW '10},
 year = {2010},
 isbn = {978-1-60558-563-5},
 location = {San Jose, California, USA},
 pages = {247--248},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1712605.1712645},
 doi = {10.1145/1712605.1712645},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {performance, thread-level speculation},
}

@inproceedings{Kejariwal:icpp:2009,
  author = {Kejariwal, Arun and Nicolau, Alexandru and Veidenbaum, Alexander V. and Banerjee, Utpal K. and Polychronopoulos, Constantine D.},
  title = {{Efficient Scheduling of Nested Parallel Loops on Multi-Core Systems}},
  booktitle = {Proceedings of the 2009 International Conference on Parallel Processing},
  series = {ICPP '09},
  year = {2009},
  isbn = {978-0-7695-3802-0},
  pages = {74--83},
  numpages = {10},
  url = {http://dx.doi.org/10.1109/ICPP.2009.19},
  doi = {10.1109/ICPP.2009.19},
  publisher = {IEEE Computer Society},
  address = {Washington, DC, USA},
  keywords = {Multithreading, Cost modeling, Load balancing, Cache misses},
}

@inproceedings{Kejariwal:systor:2009,
 author = {Kejariwal, Arun and Nicolau, Alexandru and Banerjee, Utpal K. and Veidenbaum, Alexander V. and Polychronopoulos, Constantine D.},
 title = {{Cache-aware Partitioning of Multi-dimensional Iteration Spaces}},
 booktitle = {Proceedings of SYSTOR 2009: The Israeli Experimental Systems Conference},
 series = {SYSTOR '09},
 year = {2009},
 isbn = {978-1-60558-623-6},
 location = {Haifa, Israel},
 pages = {15:1--15:12},
 articleno = {15},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1534530.1534551},
 doi = {10.1145/1534530.1534551},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {iteration space, parallel loops, partitioning},
}

@inproceedings{Kejariwal:ppopp:2008,
 author = {Kejariwal, Arun and Nicolau, Alexandru and Banerjee, Utpal K. and Veidenbaum, Alexander V. and Polychronopoulos, Constantine D.},
 title = {{Cache-aware Iteration Space Partitioning}},
 booktitle = {Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
 series = {PPoPP '08},
 year = {2008},
 isbn = {978-1-59593-795-7},
 location = {Salt Lake City, UT, USA},
 pages = {269--270},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1345206.1345250},
 doi = {10.1145/1345206.1345250},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {caches, load balancing},
}

@inproceedings{Kejariwal:ppopp:2007,
 author = {Kejariwal, Arun and Tian, Xinmin and Girkar, Milind and Li, Wei and Kozhukhov, Sergey and Banerjee, Utpal K. and Nicolau, Alexandru and Veidenbaum, Alexander V. and Polychronopoulos, Constantine D.},
 title = {{Tight Analysis of the Performance Potential of Thread Speculation Using Spec CPU 2006}},
 booktitle = {Proceedings of the 12th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
 series = {PPoPP '07},
 year = {2007},
 isbn = {978-1-59593-602-8},
 location = {San Jose, California, USA},
 pages = {215--225},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1229428.1229475},
 doi = {10.1145/1229428.1229475},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {conflict probability, misspeculation penalty, performance evaluation, speculative execution, threading overhead},
}

@inproceedings{Kejariwal:spaa:2006,
 author = {Kejariwal, Arun and Nicolau, Alexandru and Saito, Hideki and Tian, Xinmin and Girkar, Milind and Banerjee, Utpal K. and Polychronopoulos, Constantine D.},
 title = {{A General Approach for Partitioning N-dimensional Parallel Nested Loops with Conditionals}},
 booktitle = {Proceedings of the Eighteenth Annual ACM Symposium on Parallelism in Algorithms and Architectures},
 series = {SPAA '06},
 year = {2006},
 isbn = {1-59593-452-9},
 location = {Cambridge, Massachusetts, USA},
 pages = {49--58},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1148109.1148117},
 doi = {10.1145/1148109.1148117},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fourier-Motzkin elimination, affine, conditionals, parallel loops, partitioning},
}

@inproceedings{Banerjee:padtad:2006,
  author = {Banerjee, Utpal K. and Bliss, Brian E. and Ma, Zhiqiang and Petersen, Paul},
  title = {{A Theory of Data Race Detection}},
  year = {2006},
  isbn = {1595934146},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1147403.1147416},
  doi = {10.1145/1147403.1147416},
  abstract = {This paper presents a rigorous mathematical theory for the detection of data races in threaded programs. After creating a structure with precise definitions and theorems, it goes on to develop four algorithms with the goal of detecting at least one race in the situation where the history kept on previous memory accesses is limited. The algorithms demonstrate the tradeoff between the amount of access history kept and the kinds of data races that can be detected. One of these algorithms is a reformulation of a previously known algorithm; the other three are new. One of the new ones is actually used in the tool called Intel® Thread Checker.},
  booktitle = {Proceedings of the 2006 Workshop on Parallel and Distributed Systems: Testing and Debugging},
  pages = {69--78},
  numpages = {10},
  keywords = {data race, vector clock, happens-before, access conflict, dependence, thread, synchronization},
  location = {Portland, Maine, USA},
  series = {PADTAD '06}
}

@inproceedings{Kejariwal:ics:2006a,
  author = {Kejariwal, Arun and Saito, Hideki and Tian, Xinmin and Girkar, Milind and Li, Wel and Banerjee, Utpal K. and Nicolau, Alexandru and Polychronopoulos, Constantine D.},
  title = {{Lightweight Lock-free Synchronization Methods for Multithreading}},
  booktitle = {Proceedings of the 20th Annual International Conference on Supercomputing},
  series = {ICS '06},
  year = {2006},
  isbn = {1-59593-282-8},
  location = {Cairns, Queensland, Australia},
  pages = {361--371},
  numpages = {11},
  url = {http://doi.acm.org/10.1145/1183401.1183452},
  doi = {10.1145/1183401.1183452},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@inproceedings{Kejariwal:ics:2006b,
  author = {Kejariwal, Arun and Tian, Xinmin and Li, Wei and Girkar, Milind and Kozhukhov, Sergey and Saito, Hideki and Banerjee, Utpal K. and Nicolau, Alexandru and Veidenbaum, Alexander V. and Polychronopoulos, Constantine D.},
  title = {{On the Performance Potential of Different Types of Speculative Thread-level Parallelism: The DL Version of This Paper Includes Corrections That Were Not Made Available in the Printed Proceedings}},
  booktitle = {Proceedings of the 20th Annual International Conference on Supercomputing},
  series = {ICS '06},
  year = {2006},
  isbn = {1-59593-282-8},
  location = {Cairns, Queensland, Australia},
  pages = {24--},
  url = {http://doi.acm.org/10.1145/1183401.1183407},
  doi = {10.1145/1183401.1183407},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {DOALL loops, control dependence, data dependence, performance evaluation, speculative execution, value dependence},
}

@inproceedings{Kejariwal:ppopp:2005,
 author = {Kejariwal, Arun and Nicolau, Alexandru and Banerjee, Utpal K. and Polychronopoulos, Constantine D.},
 title = {{A Novel Approach for Partitioning Iteration Spaces with Variable Densities}},
 booktitle = {Proceedings of the Tenth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
 series = {PPoPP '05},
 year = {2005},
 isbn = {1-59593-080-9},
 location = {Chicago, IL, USA},
 pages = {120--131},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1065944.1065962},
 doi = {10.1145/1065944.1065962},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {iteration space, parallel loops, partitioning, unimodular transformation},
}

@article{Banerjee:ijpp:2004,
 author = {Banerjee, Utpal K.},
 title = {{Guest Editor's Introduction}},
 journal = {Int. J. Parallel Program.},
 issue_date = {June 2004},
 volume = {32},
 number = {3},
 month = jun,
 year = {2004},
 issn = {0885-7458},
 pages = {165--166},
 numpages = {2},
 url = {http://dx.doi.org/10.1023/B:IJPP.0000029472.57467.79},
 doi = {10.1023/B:IJPP.0000029472.57467.79},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
}

@inproceedings{Chang:lcpc:1996,
  author = {Chang, Pohua P. and Chen, Dong-yuan and Lee, Yong-Fong and Wu, Youfeng and Banerjee, Utpal K.},
  title = {{Bidirectional Scheduling: A New Global Code Scheduling Approach}},
  booktitle = {Proceedings of the 9th International Workshop on Languages and Compilers for Parallel Computing},
  series = {LCPC '96},
  year = {1996},
  isbn = {3-540-63091-0},
  pages = {222--230},
  numpages = {9},
  url       = {https://doi.org/10.1007/BFb0017255},
  doi       = {10.1007/BFb0017255},
  publisher = {Springer-Verlag},
  address = {London, UK, UK},
}

@inproceedings{Sridharan:lcpc:1996,
  author = {Sridharan, K. and Chang, Pohua P. and Banerjee, Utpal K. and Narayanaswamy, Ravi and Rao, Suresh},
  title = {{Memory Optimizations in the Intel Reference Compiler}},
  booktitle = {Proceedings of the 9th International Workshop on Languages and Compilers for Parallel Computing},
  series = {LCPC '96},
  year = {1996},
  isbn = {3-540-63091-0},
  pages = {608--610},
  numpages = {3},
  url       = {https://doi.org/10.1007/BFb0017285},
  doi       = {10.1007/BFb0017285},
  publisher = {Springer-Verlag},
  address = {London, UK, UK},
}

@inproceedings{Radigan:lcpc:1995,
 author = {Radigan, James and Chang, Pohua P. and Banerjee, Utpal K.},
 title = {{Integer Loop Code Generation for VLIW}},
 booktitle = {Proceedings of the 8th International Workshop on Languages and Compilers for Parallel Computing},
 series = {LCPC '95},
 year = {1996},
 isbn = {3-540-60765-X},
 pages = {318--330},
 numpages = {13},
 url = {http://dl.acm.org/citation.cfm?id=645673.665704},
 publisher = {Springer-Verlag},
 address = {London, UK, UK},
}

@inproceedings{Banerjee:lcpc:1990,
 author = {Banerjee, Utpal K.},
 title = {{A Theory of Loop Permutations}},
 booktitle = {Selected Papers of the Second Workshop on Languages and Compilers for Parallel Computing},
 year = {1990},
 location = {Urbana, Illinois, USA},
 pages = {54--74},
 numpages = {21},
 url = {http://dl.acm.org/citation.cfm?id=92402.92408},
 publisher = {Pitman Publishing},
 address = {London, UK, UK},
}

@article{Wolfe:ijpp:1987,
 author = {Wolfe, Michael J. and Banerjee, Utpal K.},
 title = {{Data Dependence and Its Application to Parallel Processing}},
 journal = {Int. J. Parallel Program.},
 issue_date = {April 1987},
 volume = {16},
 number = {2},
 month = apr,
 year = {1987},
 issn = {0885-7458},
 pages = {137--178},
 numpages = {42},
 url = {http://dx.doi.org/10.1007/BF01379099},
 doi = {10.1007/BF01379099},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
}

@inproceedings{Banerjee:isca:1984,
  author    = {Utpal K. Banerjee and
               Daniel D. Gajski},
  editor    = {Dharma P. Agrawal},
  title     = {{Fast Execution of Loops With {IF} Statements}},
  booktitle = {Proceedings of the 11th Annual International Symposium on Computer Architecture},
  series = {ISCA '84},
  pages     = {126--132},
  publisher = {{ACM}},
  address = {New York, NY, USA},
  year      = {1984},
  isbn = {0-8186-0538-3},
  url       = {https://doi.org/10.1145/800015.808174},
  doi       = {10.1145/800015.808174},
}

@phdthesis{Banerjee:phdthesis:1979,
 author = {Banerjee, Utpal K.},
 title = {{Speedup of Ordinary Programs}},
 year = {1979},
 note = {AAI8008967},
 publisher = {University of Illinois at Urbana-Champaign},
 address = {Champaign, IL, USA},
}

@inproceedings{Narayanasamy:pldi:2007,
author = {Narayanasamy, Satish and Wang, Zhenghao and Tigani, Jordan and Edwards, Andrew and Calder, Brad},
title = {{Automatically Classifying Benign and Harmful Data Races Using Replay Analysis}},
year = {2007},
isbn = {9781595936332},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1250734.1250738},
doi = {10.1145/1250734.1250738},
booktitle = {Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {22-31},
numpages = {10},
keywords = {replay, concurrency Bbugs, benign data races},
location = {San Diego, California, USA},
series = {PLDI '07}
}

@article{Lamport:cacm:1978,
 author = {Lamport, Leslie},
 title = {{Time, Clocks, and the Ordering of Events in a Distributed System}},
 journal = {Commun. ACM},
 issue_date = {July 1978},
 volume = {21},
 number = {7},
 month = jul,
 year = {1978},
 issn = {0001-0782},
 pages = {558--565},
 url = {http://doi.acm.org/10.1145/359545.359563},
 doi = {10.1145/359545.359563},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {clock synchronization, computer networks, distributed systems, multiprocess systems},
}


@inproceedings{Jannesari:ipdps:2009,
  author = {Jannesari, Ali and Kaibin Bao and Pankratius, Victor and Tichy, Walter F.},
  title = {{Helgrind+: An Efficient Dynamic Race Detector}},
  year = {2009},
  isbn = {9781424437511},
  publisher = {IEEE Computer Society},
  address = {USA},
  url = {https://doi.org/10.1109/IPDPS.2009.5160998},
  doi = {10.1109/IPDPS.2009.5160998},
  abstract = {Finding synchronization defects is difficult due to non-deterministic orderings of parallel threads. Current tools for detecting synchronization defects tend to miss many data races or produce an overwhelming number of false alarms. In this paper, we describe Helgrind+, a dynamic race detection tool that incorporates correct handling of condition variables and a combination of the lockset algorithm and happens-before relation. We compare our techniques with Intel Thread Checker and the original Helgrind tool on two substantial benchmark suites. Helgrind+ reduces the number of both false negatives (missed races) and false positives. The additional accuracy incurs almost no performance overhead.},
  keywords = {parallel programming;synchronisation;Helgrind+;dynamic race detector;synchronization defects;parallel threads;lockset algorithm;happens-before relation;Intel Thread Checker;Yarn;Detectors;Dynamic programming;Switches;Testing;Debugging;Parallel programming;Parallel processing;System recovery;Event detection, data race},
  booktitle = {Proceedings of the 2009 IEEE International Symposium on Parallel&amp;Distributed Processing},
  pages = {1–13},
  numpages = {13},
  series = {IPDPS '09}
}

@inproceedings{Bienia:pact:2008,
author = {Bienia, Christian and Kumar, Sanjeev and Singh, Jaswinder Pal and Li, Kai},
booktitle={2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)},
title={{The PARSEC benchmark suite: Characterization and architectural implications}},
year={2008},
volume={},
number={},
pages={72-81},
keywords={Benchmark testing;Computational modeling;Synchronization;Animation;Computers;Algorithm design and analysis;Program processors;benchmark suite;performance measurement;multithreading;shared-memory computers},
doi={},
ISSN={},
month={Oct},
}

@inproceedings{Nethercote:pldi:2007,
 author = {Nethercote, Nicholas and Seward, Julian},
 title = {{Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation}},
 booktitle = {Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation},
 series = {PLDI '07},
 year = {2007},
 isbn = {978-1-59593-633-2},
 location = {San Diego, California, USA},
 pages = {89--100},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1250734.1250746},
 doi = {10.1145/1250734.1250746},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Memcheck, Valgrind, dynamic binary analysis, dynamic binary instrumentation, shadow values},
}

@book{Nielson:book:2007,
address = {London},
author = {Nielson, Hanne Riis and Nielson, Flemming},
doi = {10.1007/978-1-84628-692-6},
isbn = {978-1-84628-691-9},
publisher = {Springer London},
series = {Undergraduate Topics in Computer Science},
title = {{Semantics with Applications: An Appetizer}},
url = {http://link.springer.com/10.1007/978-1-84628-692-6},
year = {2007}
}

@article{Blumofe:jpdc:1996,
title = {{Cilk: An Efficient Multithreaded Runtime System}},
journal = "Journal of Parallel and Distributed Computing",
volume = "37",
number = "1",
pages = "55 - 69",
year = "1996",
issn = "0743-7315",
doi =  {https://doi.org/10.1006/jpdc.1996.0107},
url = "http://www.sciencedirect.com/science/article/pii/S0743731596901070",
author = "Robert D. Blumofe and Christopher F. Joerg and Bradley C. Kuszmaul and Charles E. Leiserson and Keith H. Randall and Yuli Zhou",
abstract = "Cilk (pronounced “silk”) is a C-based runtime system for multithreaded parallel programming. In this paper, we document the efficiency of the Cilk work-stealing scheduler, both empirically and analytically. We show that on real and synthetic applications, the “work” and “critical-path length” of a Cilk computation can be used to model performance accurately. Consequently, a Cilk programmer can focus on reducing the computation's work and critical-path length, insulated from load balancing and other runtime scheduling issues. We also prove that for the class of “fully strict” (well-structured) programs, the Cilk scheduler achieves space, time, and communication bounds all within a constant factor of optimal. The Cilk runtime system currently runs on the Connection Machine CM5 MPP, the Intel Paragon MPP, the Sun Sparcstation SMP, and the Cilk-NOW network of workstations. Applications written in Cilk include protein folding, graphic rendering, backtrack search, and the ★Socrates chess program, which won second prize in the 1995 ICCA World Computer Chess Championship."
}

@article{Bezanson:srev:2017,
  title={{Julia: A fresh approach to numerical computing}},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
  journal={SIAM review},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM},
  url={https://doi.org/10.1137/141000671}
}

@phdthesis{Chamberlain:phdthesis:2001,
  title={{The design and implementation of a region-based parallel language}},
  author={Chamberlain, Bradford L.},
  school={University of Washington},
  year={2001},
}

@article{Chamberlain:hpca:2007,
 author = {Bradford L. Chamberlain and David Callahan and Hans P. Zima},
 title = {{Parallel Programmability and the Chapel Language}},
 journal = {Int. J. High Perform. Comput. Appl.},
 issue_date = {August    2007},
 volume = {21},
 number = {3},
 month = aug,
 year = {2007},
 issn = {1094-3420},
 pages = {291--312},
 url = {http://dx.doi.org/10.1177/1094342007078442},
 doi = {10.1177/1094342007078442},
 publisher = {Sage Publications, Inc.},
 address = {Thousand Oaks, CA, USA},
 keywords = {Chapel, parallel languages, parallel programming, productivity, programming models},
}

@inproceedings{Charles:oopsla:2005,
 author = {Charles, Philippe and Grothoff, Christian and Saraswat, Vijay A. and Donawa, Christopher and Kielstra, Allan and Ebcioglu, Kemal and von Praun, Christoph and Sarkar, Vivek},
 title = {{X10: An Object-oriented Approach to Non-uniform Cluster Computing}},
 booktitle = {Proceedings of the 20th Annual ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications},
 series = {OOPSLA '05},
 year = {2005},
 isbn = {1-59593-031-0},
 location = {San Diego, CA, USA},
 pages = {519--538},
 url = {http://doi.acm.org/10.1145/1094811.1094852},
 doi = {10.1145/1094811.1094852},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Java, X10, atomic blocks, clocks, data distribution, multithreading, non-uniform cluster computing (NUCC), partitioned global address space (PGAS), places, productivity, scalability},
}

@techreport{Forum:1994:MMI:898758,
 author = {Forum, Message P},
 title = {{MPI: A Message-Passing Interface Standard}},
 year = {1994},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autk_cs%3Ancstrl.utk_cs%2F%2FUT-CS-94-230},
 publisher = {University of Tennessee},
 address = {Knoxville, TN, USA},
}

@article{Dagum:cse:1998,
  title={{OpenMP: an industry standard API for shared-memory programming}},
  author={Dagum, Leonardo and Enon, Rameshm},
  journal={Computational Science \& Engineering, IEEE},
  volume={5},
  number={1},
  pages={46--55},
  year={1998},
  publisher={IEEE}
}

@inproceedings{Liao:iwomp:2017,
author={Liao, Chunhua and Lin, Pei-Hung and Schordan, Markus and Karlin, Ian},
title={{A Semantics-Driven Approach to Improving DataRaceBench's OpenMP Standard Coverage}},
booktitle={Evolving OpenMP for Evolving Architectures},
year={2018},
publisher={Springer International Publishing},
address="Cham",
pages={189--202},
isbn={978-3-319-98521-3}
}

@article{posix2017,
author={POSIX - Austin Joint Working Group},
journal={IEEE Std 1003.1-2017 (Revision of IEEE Std 1003.1-2008)},
title={{IEEE Standard for Information Technology--Portable Operating System Interface (POSIX(R)) Base Specifications, Issue 7}},
year={2018},
pages={1-3951},
keywords={IEEE Standards;Operating systems;Access control;Information technology;Utility programs;Synchronization;Batch production systems;Application programming interfaces;application program interface (API);argument;asynchronous;basic regular expression (BRE);batch job;batch system;built-in utility;byte;child;command language interpreter;CPU;extended regular expression (ERE);FIFO;file access control mechanism;IEEE 1003.1(TM);input/output (I/O);job control;network;parent;portable operating system interface (POSIX(R));shell;stream;string;synchronous;system;thread;X/Open System Interface (XSI)},
doi={10.1109/IEEESTD.2018.8277153},
ISSN={},
month={Jan},}

@inproceedings{Quinlan:cetus:2011,
  title={{The {ROSE} source-to-source compiler infrastructure}},
  author={Quinlan, Daniel J. and Liao, Chunhua},
  booktitle={Cetus users and compiler infrastructure workshop, in conjunction with PACT},
  volume={2011},
  pages={1},
  year={2011},
  organization={Citeseer}
}

@inproceedings{Schordan:mpl:2003,
author="Schordan, Markus
and Quinlan, Dan",
title={{A Source-To-Source Architecture for User-Defined Optimizations}},
booktitle="Modular Programming Languages",
year="2003",
publisher="Springer Berlin Heidelberg",
pages="214--223",
abstract="We present an architecture for the specification of source-to-source transformations. New source code can be specified as source-fragments. The translation of source-fragments to the intermediate representation is accomplished by invoking the frontend. For any inserted fragment we can guarantee that it is typed correctly. If no error is reported on inserted fragments, the whole program can always be compiled without errors. Based on a given abstract attribute grammar the user can specify transformations as semantic actions and can combine the computation of attributes with restructure operations on the intermediate representation.",
isbn="978-3-540-45213-3"
}

@inproceedings{Moura:tacas:2008,
author="de Moura, Leonardo
and Bj{\o}rner, Nikolaj",
title={{Z3: An Efficient SMT Solver}},
booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="337--340",
abstract="Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.",
isbn="978-3-540-78800-3"
}

@inproceedings{Eichenberger:iwomp:2013,
  author = {Eichenberger, Alexandre E. and Mellor-Crummey, John and Schulz, Martin and Wong, Michael and Copty, Nawal and Dietrich, Robert and Liu, Xu and Loh, Eugene and Lorenz, Daniel},
  editor = {Rendell, Alistair P. and Chapman, Barbara M. and M{\"u}ller, Matthias S.},
  title = {{OMPT: An OpenMP Tools Application Programming Interface for Performance Analysis}},
  booktitle = {OpenMP in the Era of Low Power Devices and Accelerators},
  year = {2013},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {171--185},
  abstract = {A shortcoming of OpenMP standards to date is that they lack an application programming interface (API) to support construction of portable, efficient, and vendor-neutral performance tools. To address this issue, the tools working group of the OpenMP Language Committee has designed OMPT---a performance tools API for OpenMP. OMPT enables performance tools to gather useful performance information from applications with low overhead and to map this information back to a user-level view of applications. OMPT provides three principal capabilities: (1) runtime state tracking, which enables a sampling-based performance tool to understand what an application thread is doing, (2) callbacks and inquiry functions that enable sampling-based performance tools to attribute application performance to complete calling contexts, and (3) additional callback notifications that enable construction of more full-featured monitoring capabilities. The earnest hope of the tools working group is that OMPT be adopted as part of the OpenMP standard and supported by all standard-compliant OpenMP implementations.},
  keywords = {data race},
  isbn = {978-3-642-40698-0},
  doi = {10.1007/978-3-642-40698-0\_13},
}

@inproceedings{Mellor-Crummey:sc:1991,
  author = {Mellor-Crummey, John},
  title = {{On-the-Fly Detection of Data Races for Programs with Nested Fork-Join Parallelism}},
  year = {1991},
  isbn = {0897914597},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/125826.125861},
  doi = {10.1145/125826.125861},
  booktitle = {Proceedings of the 1991 ACM/IEEE Conference on Supercomputing},
  keywords = {data race},
  pages = {24--33},
  numpages = {10},
  location = {Albuquerque, New Mexico, USA},
  series = {Supercomputing '91}
}

@inproceedings{Pugh:sc:1991,
 author = {Pugh, William},
 title = {{The Omega Test: A Fast and Practical Integer Programming Algorithm for Dependence Analysis}},
 booktitle = {Proceedings of the 1991 ACM/IEEE Conference on Supercomputing},
 series = {Supercomputing '91},
 year = {1991},
 isbn = {0-89791-459-7},
 location = {Albuquerque, New Mexico, USA},
 pages = {4--13},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/125826.125848},
 doi = {10.1145/125826.125848},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Chang:pdsn:1999,
  title={{The Generalized Lambda Test: A Multi-Dimensional Version of Banerjee's Algorithm}},
  author = {Chang, Weng{-}Long and Chu, Chih{-}Ping and Wu, Jesse},
  journal={International Journal of Parallel and Distributed Systems and Networks},
  volume={2},
  pages={69--78},
  year={1999}
}

@article{Li:tpds:1990,
 author = {Li, Zhiyuan and Yew, Pen{-}Chung and Zhu, Chuan{-}Qi},
 title = {{An Efficient Data Dependence Analysis for Parallelizing Compilers}},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 issue_date = {January 1990},
 volume = {1},
 number = {1},
 month = jan,
 year = {1990},
 issn = {1045-9219},
 pages = {26--34},
 numpages = {9},
 url = {https://doi.org/10.1109/71.80122},
 doi = {10.1109/71.80122},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {FORTRAN, Fortran program parallelization restructurer, Index Termsprogram restructuring, Parafrase, array subscripts, convex set, data dependence analysis, hyperplanes, lambda test, linear inequalities, loop bounds, multidimensional array references, numerical methods, parallel programming, parallelizing compilers, program compilers},
}

@article{Leveson:computer:1993,
author={Leveson, Nancy G. and Turner, Clark S.},
journal={Computer},
title={{An investigation of the Therac-25 accidents}},
year={1993},
volume={26},
number={7},
pages={18-41},
keywords={accidents;government policies;linear accelerators;medical computing;radiation therapy;software engineering;systems engineering;system operation;accidents;Therac-25 medical electron accelerator;radiation overdoses;software-related overdoses;system development;system engineering;software engineering;government regulation;safety-critical systems;Accidents;Software safety;Food manufacturing;Computer industry;Food industry;Electron accelerators;Biomedical applications of radiation;Injuries;History;Drugs},
doi={10.1109/MC.1993.274940},
ISSN={1558-0814},
month={July},
}

@article{lions1996flight,
  title={{Flight 501 failure}},
  author={Lions, Jacques-Louis and others},
  year={1996},
}

@article{popper2012knight,
  title={{Knight Capital says trading glitch cost it \$440 million}},
  author={Popper, Nathaniel},
  journal={New York Times},
  volume={2},
  year={2012}
}

@inproceedings{Barua:iwomp:2019,
  author    = {Prithayan Barua and
               Jun Shirako and
               Whitney Tsang and
               Jeeva Paudel and
               Wang Chen and
               Vivek Sarkar},
  editor    = {Xing Fan and
               Bronis R. de Supinski and
               Oliver Sinnen and
               Nasser Giacaman},
  title     = {{OMPSan: Static Verification of OpenMP's Data Mapping Constructs}},
  booktitle = {OpenMP: Conquering the Full Hardware Spectrum - 15th International
               Workshop on OpenMP, {IWOMP} 2019, Auckland, New Zealand, September
               11-13, 2019, Proceedings},
  abstract  = {OpenMP offers directives for offloading computations from CPU hosts to accelerator devices such as GPUs. A key underlying challenge is in efficiently managing the movement of data across the host and the accelerator. User experiences have shown that memory management in OpenMP programs with offloading capabilities is non-trivial and error-prone.},
  series    = {Lecture Notes in Computer Science},
  volume    = {11718},
  pages     = {3--18},
  publisher = {Springer},
  year      = {2019},
  url       = {https://doi.org/10.1007/978-3-030-28596-8\_1},
  isbn      = {978-3-030-28596-8},
  doi       = {10.1007/978-3-030-28596-8\_1},
}

@inproceedings{Betts:oopsla:2012,
author = {Betts, Adam and Chong, Nathan and Donaldson, Alastair F. and Qadeer, Shaz and Thomson, Paul},
title = {{GPUVerify: A Verifier for GPU Kernels}},
year = {2012},
isbn = {9781450315616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2384616.2384625},
doi = {10.1145/2384616.2384625},
booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
pages = {113-132},
numpages = {20},
keywords = {concurrency, GPUs, data races, verification, barrier synchronization},
location = {Tucson, Arizona, USA},
series = {OOPSLA '12},
}

@inproceedings{Li:sc:2014,
  author = {Li, Peng and Li, Guodong and Gopalakrishnan, Ganesh},
  title = {{Practical Symbolic Race Checking of GPU Programs}},
  year = {2014},
  isbn = {9781479955008},
  publisher = {IEEE Press},
  url = {https://doi.org/10.1109/SC.2014.20},
  doi = {10.1109/SC.2014.20},
  abstract = {Even the careful GPU programmer can inadvertently introduce data races while writing and optimizing code. Currently available GPU race checking methods fall short either in terms of their formal guarantees, ease of use, or practicality. Existing symbolic methods: (1) do not fully support existing CUDA kernels; (2) may require user-specified assertions or invariants; (3) often require users to guess which inputs may be safely made concrete; (4) tend to explode in complexity when the number of threads is increased; and (5) explode in the face of thread-ID based decisions, especially in a loop. We present SESA, a new tool combining Symbolic Execution and Static Analysis to analyze C++ CUDA programs that overcomes all these limitations. SESA also scales well to handle non-trivial benchmarks such as Parboil and Lonestar, and is the only tool of its class that handles such practical examples. This paper presents SESA's methodological innovations and practical results.},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages = {179–190},
  numpages = {12},
  keywords = {symbolic execution, parallelism, taint analysis, virtual machine, GPU, CUDA, formal verification, data flow analsis,data race},
  location = {New Orleans, Louisana},
  series = {SC '14}
}

@inproceedings{Peng:pldi:2018,
  author = {Peng, Yuanfeng and Grover, Vinod and Devietti, Joseph},
  title = {{CURD: A Dynamic CUDA Race Detector}},
  year = {2018},
  isbn = {9781450356985},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3192366.3192368},
  doi = {10.1145/3192366.3192368},
  abstract = {As GPUs have become an integral part of nearly every pro- cessor, GPU programming has become increasingly popular. GPU programming requires a combination of extreme levels of parallelism and low-level programming, making it easy for concurrency bugs such as data races to arise. These con- currency bugs can be extremely subtle and di cult to debug due to the massive numbers of threads running concurrently on a modern GPU. While some tools exist to detect data races in GPU pro- grams, they are often prohibitively slow or focused only on a small class of data races in shared memory. Compared to prior work, our race detector, CURD, can detect data races precisely on both shared and global memory, selects an appropriate race detection algorithm based on the synchronization used in a program, and utilizes efficient compiler instrumentation to reduce performance overheads. Across 53 benchmarks, we find that using CURD incurs an aver- age slowdown of just 2.88x over native execution. CURD is 2.1x faster than Nvidia’s CUDA-Racecheck race detector, de- spite detecting a much broader class of races. CURD finds 35 races across our benchmarks, including bugs in established benchmark suites and in sample programs from Nvidia.},
  booktitle = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages = {390–403},
  numpages = {14},
  keywords = {GPUs, data race detection, Nvidia CUDA},
  location = {Philadelphia, PA, USA},
  series = {PLDI 2018}
}

@article{Li:taco:2017,
  author = {Li, Pengcheng and Hu, Xiaoyu and Chen, Dong and Brock, Jacob and Luo, Hao and Zhang, Eddy Z. and Ding, Chen},
  title = {{LD: Low-Overhead GPU Race Detection Without Access Monitoring}},
  year = {2017},
  issue_date = {April 2017},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {14},
  number = {1},
  issn = {1544-3566},
  url = {https://doi.org/10.1145/3046678},
  doi = {10.1145/3046678},
  abstract = {Data race detection has become an important problem in GPU programming. Previous designs of CPU race-checking tools are mainly task parallel and incur high overhead on GPUs due to access instrumentation, especially when monitoring many thousands of threads routinely used by GPU programs.This article presents a novel data-parallel solution designed and optimized for the GPU architecture. It includes compiler support and a set of runtime techniques. It uses value-based checking, which detects the races reported in previous work, finds new races, and supports race-free deterministic GPU execution. More important, race checking is massively data parallel and does not introduce divergent branching or atomic synchronization. Its slowdown is less than 5 \texttimes{} for over half of the tests and 10 \texttimes{} on average, which is orders of magnitude more efficient than the cuda-memcheck tool by Nvidia and the methods that use fine-grained access instrumentation.},
  journal = {ACM Trans. Archit. Code Optim.},
  month = mar,
  articleno = {9},
  numpages = {25},
  keywords = {low overhead, instrumentation-free, GPU race detection, value-based checking, data race}
}

@inproceedings{Li:sc:2012,
author={Li, Peng and Li, Guodong and Gopalakrishnan, Ganesh},
booktitle={SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
title={{Parametric flows: Automated behavior equivalencing for symbolic analysis of races in CUDA programs}},
year={2012},
volume={},
number={},
pages={1-10},
}

@inproceedings{Li:ppopp:2012,
author = {Li, Guodong and Li, Peng and Sawaya, Geof and Gopalakrishnan, Ganesh and Ghosh, Indradeep and Rajan, Sreeranga P.},
title = {{GKLEE: Concolic Verification and Test Generation for GPUs}},
year = {2012},
isbn = {9781450311601},
publisher = {Association for Computing Machinery},
address = {USA},
url = {https://doi.org/10.1145/2145816.2145844},
doi = {10.1145/2145816.2145844},
booktitle = {Proceedings of the 17th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {215-224},
numpages = {10},
keywords = {automatic test generation, GPU, CUDA, virtual machine, parallelism, formal verification, symbolic execution},
location = {New Orleans, Louisiana, USA},
series = {PPoPP 12}
}


@inproceedings{Li:fse:2010,
author = {Li, Guodong and Gopalakrishnan, Ganesh},
title = {{Scalable SMT-Based Verification of GPU Kernel Functions}},
year = {2010},
isbn = {9781605587912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882291.1882320},
doi = {10.1145/1882291.1882320},
booktitle = {Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {187-196},
numpages = {10},
keywords = {formal verification, concurrency, gpu, cuda, satisfiability modulo theories (decision procedures)},
location = {Santa Fe, New Mexico, USA},
series = {FSE '10}
}

@article{Zheng:tpds:2014,
author={Zheng, Mai and Ravi, Vignesh T. and Qin, Feng and Agrawal, Gagan},
journal={IEEE Transactions on Parallel and Distributed Systems},
title={{GMRace: Detecting Data Races in GPU Programs via a Low-Overhead Scheme}},
year={2014},
volume={25},
number={1},
pages={104-115},
}

@article{Acharya:taco:2020,
author = {Acharya, Aravind and Bondhugula, Uday and Cohen, Albert},
title = {{Effective Loop Fusion in Polyhedral Compilation Using Fusion Conflict Graphs}},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3416510},
doi = {10.1145/3416510},
abstract = {Polyhedral auto-transformation frameworks are known to find efficient loop transformations that maximize locality and parallelism and minimize synchronization. While complex loop transformations are routinely modeled in these frameworks, they tend to rely on ad hoc heuristics for loop fusion. Although there exist multiple loop fusion models with cost functions to maximize locality and parallelism, these models involve separate optimization steps rather than seamlessly integrating with other loop transformations like loop permutation, scaling, and shifting. Incorporating parallelism-preserving loop fusion heuristics into existing affine transformation frameworks like Pluto, LLVM-Polly, PPCG, and PoCC requires solving a large number of Integer Linear Programming formulations, which increase auto-transformation times significantly.In this work, we incorporate polynomial time loop fusion heuristics into the Pluto-lp-dfp framework. We present a data structure called the fusion conflict graph (FCG), which enables us to efficiently model loop fusion in the presence of other affine loop transformations. We propose a clustering heuristic to group the vertices of the FCG, which further enables us to provide three different polynomial time greedy fusion heuristics, namely, maximal fusion, typed fusion, and hybrid fusion, while maintaining the compile time improvements of Pluto-lp-dfp over Pluto. Our experiments reveal that the hybrid fusion model, in conjunction with Pluto’s cost function, finds efficient transformations that outperform PoCC and Pluto by mean factors of 1.8\texttimes{} and 1.07\texttimes{}, respectively, with a maximum performance improvement of 14\texttimes{} over PoCC and 2.6\texttimes{} over Pluto.},
journal = {ACM Trans. Archit. Code Optim.},
month = sep,
articleno = {26},
numpages = {26},
keywords = {pluto algorithm, Affine transformations, fusion conflict graph}
}


@inproceedings{Swain:sc:2020,
author = {Swain, Bradley and Li, Yanze and Liu, Peiming and Laguna, Ignacio and Georgakoudis, Giorgis and Huang, Jeff},
title = {{OMPRacer: A Scalable and Precise Static Race Detector for OpenMP Programs}},
year = {2020},
isbn = {9781728199986},
publisher = {IEEE Press},
abstract = {We present OMPRacer, a static tool that uses flow-sensitive, interprocedural analysis to detect data races in OpenMP programs. OMPRacer is fast, scalable, has high code coverage, and supports the most common OpenMP features by combining state-of-the-art pointer analysis, novel value-flow analysis, happens-before tracking, and generalized modelling of OpenMP APIs.Unlike dynamic tools that currently dominate data race detection, OMPRacer achieves almost 100\% code coverage using static analysis to detect a broader category of races without running the program or relying on specific input or runtime behaviour. OMPRacer has competitive precision with dynamic tools like Archer and ROMP: passing 105/116 cases in DataRaceBench with a total accuracy of 91\%.OMPRacer has been used to analyze several Exascale Computing Project proxy applications containing over 2 million lines of code in under 10 minutes. OMPRacer has revealed previously unknown races in an ECP proxy app and a production simulation for COVID19.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {54},
numpages = {14},
keywords = {data race detection, static analysis, nondeterminism, OpenMP, bug detection},
location = {Atlanta, Georgia},
series = {SC '20}
}
@software{Swain:zenodo:2020,
  author       = {Swain, Brad},
  title        = {{OMPRacer}},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {0.1.1},
  doi          = {10.5281/zenodo.3963710},
  url          = {https://doi.org/10.5281/zenodo.3963710}
}


@article{Bora:taco:2020,
  author = {Bora, Utpal and Das, Santanu and Kukreja, Pankaj and Joshi, Saurabh and Upadrasta, Ramakrishna and Rajopadhye, Sanjay},
  title = {{LLOV: A Fast Static Data-Race Checker for OpenMP Programs}},
  year = {2020},
  issue_date = {November 2020},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {17},
  number = {4},
  issn = {1544-3566},
  url = {https://doi.org/10.1145/3418597},
  doi = {10.1145/3418597},
  abstract = {In the era of Exascale computing, writing efficient parallel programs is indispensable, and, at the same time, writing sound parallel programs is very difficult. Specifying parallelism with frameworks such as OpenMP is relatively easy, but data races in these programs are an important source of bugs. In this article, we propose LLOV, a fast, lightweight, language agnostic, and static data race checker for OpenMP programs based on the LLVM compiler framework. We compare LLOV with other state-of-the-art data race checkers on a variety of well-established benchmarks. We show that the precision, accuracy, and the F1 score of LLOV is comparable to other checkers while being orders of magnitude faster. To the best of our knowledge, LLOV is the only tool among the state-of-the-art data race checkers that can verify a C/C++ or FORTRAN program to be data race free.},
  journal = {ACM Trans. Archit. Code Optim.},
  month = dec,
  articleno = {35},
  numpages = {26},
  keywords = {OpenMP, program verification, polyhedral compilation, static analysis, data race detection, shared memory programming}
}



@misc{valgrind2007helgrind,
  author = {Valgrind-project},
  title = {{Helgrind: a thread error detector}},
  howpublished = "\url{http://valgrind.org/docs/manual/hg-manual.html}",
  year = {2007},
  note = "[Online; accessed 08-May-2019]"
}

@misc{valgrind2007drd,
  author = {Valgrind-project},
  title = {{DRD: a thread error detector}},
  howpublished = "\url{http://valgrind.org/docs/manual/drd-manual.html}",
  year = {2007},
  note = "[Online; accessed 08-May-2019]"
}

@misc{valgrind2003url,
  author = {Nethercote, Nicholas and Seward, Julian},
  title = {{Valgrind: A program supervision  framework}},
  howpublished = "\url{http://valgrind.org/}",
  year = {2003},
  note = "[Online; accessed 08-May-2019]"
}

@misc{top500url,
  author = {TOP500.Org},
  title = {{Top 500 Supercomputer Sites}},
  howpublished = "\url{https://top500.org/lists/top500/2021/06/}",
  year = {2021},
  note = "[Online; accessed 28-June-2021]"
}

@misc{ompSCRgit,
  author={A. J. {Dorta} and C. {Rodriguez} and F. {de Sande} and U. Bora},
  title = {{OpenMP Source Code Repository (updates to support latest compilers and scripts)}},
  howpublished = "\url{https://github.com/utpalbora/OmpSCR\_v2.0.git}",
  year = {2019},
  note = "[Online; accessed 19-May-2019]"
}

@misc{ompSCR,
  author={A. J. {Dorta} and C. {Rodriguez} and F. {de Sande}},
  title = {{OpenMP Source Code Repository}},
  howpublished = "\url{https://sourceforge.net/projects/ompscr/files/OmpSCR/}",
  year = {2004},
  note = "[Online; accessed 19-May-2019]"
}

@misc{openmp45spec,
  author = {{OpenMP Architecture Review Board}},
  title = {{OpenMP Application Programming Interface  Version 4.5}},
  howpublished = "\url{https://www.openmp.org/wp-content/uploads/openmp-4.5.pdf}",
  year = {2015},
  note = "[Online; accessed 19-May-2019]"
}

@misc{openmpspecs,
  author = {{OpenMP Architecture Review Board}},
  title = {{OpenMP Application Programming Interface}},
  howpublished = "\url{https://www.openmp.org}",
  year = {1997},
  note = "[Online; accessed 19-October-2019]"
}


@article{Bernstein:TEC:1966,
author={Bernstein, A. J.},
journal={IEEE Transactions on Electronic Computers},
title={{Analysis of Programs for Parallel Processing}},
year={1966},
volume={EC-15},
number={5},
pages={757-763},
doi={10.1109/PGEC.1966.264565}
}

@inproceedings{Wang:ics:2021,
author = {Wang, Wenwen and Lin, Pei-Hung},
title = {{Does It Matter? OMPSanitizer: An Impact Analyzer of Reported Data Races in OpenMP Programs}},
year = {2021},
isbn = {9781450383356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447818.3460379},
doi = {10.1145/3447818.3460379},
abstract = {Data races are a primary source of concurrency bugs in parallel programs. Yet, debugging data races is not easy, even with a large amount of data race detection tools. In particular, there still exists a manually-intensive and time-consuming investigation process after data races are reported by existing race detection tools. To address this issue, we present OMPSanitizer in this paper. OMPSanitizer employs a novel and semantic-aware impact analysis mechanism to assess the potential impact of detected data races so that developers can focus on data races with a high probability to produce a harmful impact. This way, OMPSanitizer can remove the heavy debugging burden of data races from developers and simultaneously enhance the debugging efficiency. We have implemented OMPSanitizer based on the widely-used dynamic binary instrumentation infrastructure, Intel Pin. Our evaluation results on a broad range of OpenMP programs from the DataRaceBench benchmark suite and an ECP Proxy application demonstrate that OMPSanitizer can precisely report the impact of data races detected by existing race detectors, e.g., Helgrind and ThreadSanitizer. We believe OMPSanitizer will provide a new perspective on automating the debugging support for data races in OpenMP programs.},
booktitle = {Proceedings of the ACM International Conference on Supercomputing},
pages = {40–51},
numpages = {12},
keywords = {parallel program testing and debugging, OpenMP, data race analysis, happens-before orders, concurrency bugs, multithreading},
location = {Virtual Event, USA},
series = {ICS '21}
}

@inproceedings{Cousot:ISP:1976,
   author =    {Cousot, P{.} and Cousot, R{.}},
   title =     {{Static determination of dynamic properties of programs}},
   pages =     {106--130},
   booktitle = {Proceedings of the Second International Symposium on Programming},
   publisher = {Dunod, Paris, France},
   year =      1976,
}

@misc{pgi,
  author = {PGI},
  year = {2018},
  title = {{PGI Accelerator Compilers with OpenACC Directives}},
  howpublished = "\url{https://www.pgroup.com/resources/accel.htm}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{gcc,
  author = {Project GNU},
  year = {2019},
  title = {{GCC, the GNU Compiler Collection}},
  howpublished = "\url{https://gcc.gnu.org/}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{icc,
  author = {Intel},
  year = {2019},
  title = {{The Intel C++ Compiler}},
  howpublished = "\url{https://software.intel.com/en-us/c-compilers}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{intelinspector,
  author = {Intel},
  title = {{Intel Inspector}},
  year={2019},
  howpublished = "\url{https://software.intel.com/en-us/inspector}",
  note = "[Online; accessed 08-May-2019]"
}

@misc{llvm,
  author = {LLVM},
  title = {{The LLVM Compiler Infrastructure}},
  year={2019},
  howpublished = "\url{http://llvm.org/}",
  note = "[Online; accessed 08-May-2019]"
}

@misc{polly,
  author = {LLVM/Polly},
  title = {{Polly: LLVM Framework for High-Level Loop and Data-Locality Optimizations}},
  year={2019},
  howpublished = "\url{https://polly.llvm.org/}",
  note = "[Online; accessed 08-May-2019]"
}

@misc{llvm-lai,
  author = {LLVM},
  title = {{Loop Access Info, Class Reference}},
  year={2019},
  howpublished = "\url{https://llvm.org/doxygen/classllvm_1_1LoopAccessInfo.html}",
  note = "[Online; accessed 08-May-2019]"
}

@misc{llvm-aa,
  author = {LLVM},
  title = {{LLVM Alias Analysis Infrastructure}},
  year={2020},
  howpublished = "\url{https://llvm.org/docs/AliasAnalysis.html}",
  note = "[Online; accessed 06-May-2020]"
}

@misc{clang,
  author = {LLVM/Clang},
  year = {2019},
  title = {{Clang: A C language family frontend for LLVM}},
  howpublished = "\url{https://clang.llvm.org}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{llvm-ir,
  author = {LLVM},
  year = {2019},
  title = {{LLVM Language Reference Manual}},
  howpublished = "\url{https://llvm.org/docs/LangRef.html}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{flang,
  author = {LLVM/Flang},
  title = {{Flang: A Fortran Compiler Targeting LLVM}},
  year={2019},
  howpublished = "\url{https://github.com/flang-compiler/flang/wiki}",
  note = "[Online; accessed 08-May-2019]"
}

@misc{utpal2016gsoc,
  author = {Bora, Utpal and Doerfert, Johannes and  Grosser, Tobias and Upadrasta, Ramakrishna},
  title = {{GSoC 2016: PolyhedralInfo - Polly as an analysis pass in LLVM}},
  howpublished = "\url{https://llvmdevelopersmeetingbay2016.sched.com/event/8Z2Z/lightning-talks}",
  year = {2016},
  note = "[Online; accessed 08-May-2019]"
}

@misc{openacc,
  author = {OpenACC},
  title = {{The OpenACC Application Programming Interface,v2.7 (November 2018)}},
  year={2019},
  howpublished = "\url{https://www.openacc.org/specification}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{opencl,
  author = {Khronos OpenCL Working Group},
  title = {{The OpenCL Specification, v2.2-11 (July 2019).}},
  year={2019},
  howpublished = "\url{https://www.khronos.org/registry/OpenCL/}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{cudaruntime,
  author = {NVIDIA},
  title = {{NVIDIA CUDA Runtime API v10.1.168 (May 2019).}},
  year={2019},
  howpublished = "\url{https://docs.nvidia.com/cuda/cuda-runtime-api/index.html}",
  note = "[Online; accessed 08-August-2019]"
}

@article{Pheatt:jcsc:2008,
author = {Pheatt, Chuck},
title = {{Intel\textregistered Threading Building Blocks}},
year = {2008},
issue_date = {April 2008},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {23},
number = {4},
issn = {1937-4771},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {298},
numpages = {1}
}

@misc{inteltbburl,
  author = {Intel},
  title = {{Intel\textsuperscript{\textregistered} Threading Building Blocks}},
  year={2019},
  howpublished = "\url{https://software.intel.com/en-us/tbb}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{cuda,
  author = {NVIDIA},
  title = {{CUDA C Programming Guide v10.1.168 (May 2019).}},
  year={2019},
  howpublished = "\url{https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{openmpi,
  author = {The Open MPI Development Team},
  title = {{Open MPI: Open Source High Performance Computing (May 2019).}},
  year={2019},
  howpublished = "\url{https://www.open-mpi.org/doc/v4.0/}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{mpi,
  author = {MPI},
  title = {{MPI-3.1 (May 2019).}},
  year={2019},
  howpublished = "\url{https://www.mpi-forum.org/docs/}",
  note = "[Online; accessed 08-August-2019]"
}

@misc{drbv12url,
  author = {Liao, Chunhua and Lin, Pei-Hung and Asplund, Joshua and Schordan, Markus and Karlin, Ian},
  title = {{DataRaceBench v1.2.0}},
  howpublished = "\url{https://github.com/LLNL/dataracebench}",
  year = {2018},
  note = "[Online; accessed 19-May-2019]"
}

@misc{drbForturl,
  author = {Kukreja, Pankaj and Shukla, Himanshu and Bora, Utpal},
  title = {{DataRaceBench FORTRAN}},
  howpublished = "\url{https://github.com/IITH-Compilers/drb_fortran}",
  year = {2019},
  note = "[Online; accessed 19-October-2019]"
}

@misc{poccurl,
  author = {Pouchet, Louis-No\"{e}l},
  title = {{PoCC, the POlyhedral Compiler Collection package. A full source-to-source polyhedral compiler.}},
  howpublished = "\url{https://sourceforge.net/projects/pocc/}",
  year = {2013},
  note = "[Online; accessed 15-May-2020]"
}

@misc{polyopturl,
  author = {Pouchet, Louis-No\"{e}l},
  title = {{PolyOpt/C: a Polyhedral Optimizer for the ROSE compiler}},
  howpublished = "\url{http://web.cs.ucla.edu/~pouchet/software/polyopt/}",
  year = {2012},
  note = "[Online; accessed 15-May-2020]"
}

@misc{plutourl,
  author = {Bondhugula, Uday},
  title = {{PLUTO - An automatic parallelizer and locality optimizer for affine loop nests}},
  howpublished = "\url{http://pluto-compiler.sourceforge.net/}",
  year = {2017},
  note = "[Online; accessed 15-May-2020]"
}
@misc{cuda-memcheck,
  author = {NVIDIA},
  title = {{CUDA-MEMCHECK}},
  howpublished = "\url{https://docs.nvidia.com/cuda/cuda-memcheck/index.html}",
  year = {2020},
  note = "[Online; accessed 21-July-2020]",
}

@misc{arm-ddt,
  author = {ARM},
  title = {{ARM DDT}},
  howpublished = "\url{https://www.arm.com/products/development-tools/server-and-hpc/forge/ddt}",
  year = {2020},
  note = "[Online; accessed 21-July-2020]",
}

@misc{chapel,
  author = {Cray},
  address= {Seattle, WA},
  year = {2019},
  title = {{Chapel language specification (version 0.9)}},
  howpublished = "\url{http://chapel.cray.com/papers.html}",
}

@inproceedings{Bora:llvm-hpc:2021,
  author={Bora, Utpal and Vaishay, Shraiysh and Joshi, Saurabh and Upadrasta, Ramakrishna},
  booktitle={{2021 IEEE/ACM 7th Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)}},
  title={{OpenMP aware MHP Analysis for Improved Static Data-Race Detection}},
  year={2021},
  volume={},
  number={},
  pages={1-11},
  abstract={{Data races, a major source of bugs in concurrent programs, can result in loss of manpower and time as well as data loss due to system failures. OpenMP, the de facto shared memory parallelism framework used in the HPC community, also suffers from data races. To detect race conditions in OpenMP programs and improve turnaround time and/or developer productivity, we present a data flow analysis based, fast, static data race checker in the LLVM compiler framework. Our tool can detect races in the presence or absence of explicit barriers, with implicit or explicit synchronization. In addition, our tool effectively works for the OpenMP target offloading constructs and also supports the frequently used OpenMP constructs.We formalize and provide a data flow analysis framework to perform Phase Interval Analysis (PIA) of OpenMP programs. Phase intervals are then used to compute the MHP (and its complement NHP) sets for the programs, which, in turn, are used to detect data races statically.We evaluate our work using multiple OpenMP race detection benchmarks and real world applications. Our experiments show that the checker is comparable to the state-of-the-art in various performance metrics with around 90% accuracy, almost perfect recall, and significantly lower runtime and memory footprint.}},
  keywords={},
  doi={10.1109/LLVMHPC54804.2021.00006},
  series={{LLVM-HPC '21}},
  ISSN={},
  month={Nov},
}

@inproceedings{Lattner:cgo:2021,
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
   title={{MLIR: Scaling Compiler Infrastructure for Domain Specific Computation}},
   year={2021},
   volume={},
   number={},
   pages={2-14},
   doi={10.1109/CGO51591.2021.9370308}
}

@misc{Gansner:misc:2006,
  title={{Drawing graphs with \textit{dot}}},
  author={Gansner, Emden and Koutsofios, Eleftherios and North, Stephen},
  year={2006},
  publisher={Technical report, AT\&T Research. URL https://www.graphviz.org/pdf/dotguide.pdf}
}
@inproceedings{Naumovich:fse:1998,
  author = {Naumovich, Gleb and Avrunin, George S.},
  title = {{A Conservative Data Flow Algorithm for Detecting All Pairs of Statements That May Happen in Parallel}},
  year = {1998},
  isbn = {1581131089},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/288195.288213},
  doi = {10.1145/288195.288213},
  abstract = {Information about which pairs of statements in a concurrent program can execute in parallel is important for optimizing and debugging programs, for detecting anomalies, and for improving the accuracy of data flow analysis. In this paper, we describe a new data flow algorithm that finds a conservative approximation of the set of all such pairs. We have carried out an initial comparison of the precision of our algorithm and that of the most precise of the earlier approaches, Masticola and Ryder's non-concurrency analysis [8], using a sample of 159 concurrent Ada programs that includes the collection assembled by Masticola and Ryder. For these examples, our algorithm was almost always more precise than non-concurrency analysis, in the sense that the set of pairs identified by our algorithm as possibly happening in parallel is a proper subset of the set identified by non-concurrency analysis. In 132 cases, we were able to use reachability analysis to determine exactly the set of pairs of statements that may happen in parallel. For these cases, there were a total of only 10 pairs identified by our algorithm that cannot actually happen in parallel.},
  booktitle = {Proceedings of the 6th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages = {24–34},
  numpages = {11},
  location = {Lake Buena Vista, Florida, USA},
  keywords = {MHP},
  series = {SIGSOFT '98/FSE-6}
}

@inproceedings{Albert:fmoods:2012,
  author = {Albert, Elvira and Flores-Montoya, Antonio E. and Genaim, Samir},
  editor = {Giese, Holger and Rosu, Grigore},
  title = {{Analysis of May-Happen-in-Parallel in Concurrent Objects}},
  booktitle = {Formal Techniques for Distributed Systems},
  year = {2012},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {35--51},
  abstract = {This paper presents a may-happen-in-parallel (MHP) analysis for OO languages based on concurrent objects. In this concurrency model, objects are the concurrency units such that, when a method is invoked on an object o2 from a task executing on object o1, statements of the current task in o1 may run in parallel with those of the (asynchronous) call on o2, and with those of transitively invoked methods. The goal of the MHP analysis is to identify pairs of statements in the program that may run in parallel in any execution. Our MHP analysis is formalized as a method-level (local) analysis whose information can be modularly composed to obtain application-level (global) information.},
  isbn = {978-3-642-30793-5},
  keywords = {MHP},
}

@inproceedings{Rinard:sas:2001,
  author = {Rinard, Martin C.},
  editor = {Cousot, Patrick},
  title = {{Analysis of Multithreaded Programs}},
  booktitle = {Static Analysis},
  year = {2001},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {1--19},
  abstract = {The field of program analysis has focused primarily on sequential programming languages. But multithreading is becoming increasingly important, both as a program structuring mechanism and to support efficient parallel computations. This paper surveys research in analysis for multithreaded programs, focusing on ways to improve the efficiency of analyzing interactions between threads, to detect data races, and to ameliorate the impact of weak memory consistency models. We identify two distinct classes of multithreaded programs, activity management programs and parallel computing programs, and discuss how the structure of these kinds of programs leads to different solutions to these problems. Specifically, we conclude that augmented type systems are the most promising approach for activity management programs, while targeted program analyses are the most promising approach for parallel computing programs.},
  isbn = {978-3-540-47764-8},
  keywords = {MHP},
}

@inproceedings{Naumovich:fse:1999,
  author = {Naumovich, Gleb and Avrunin, George S. and Clarke, Lori A.},
  title = {{An Efficient Algorithm for Computing \textit{MHP} Information for Concurrent Java Programs}},
  year = {1999},
  isbn = {3540665382},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  abstract = {Information about which statements in a concurrent program may happen in parallel (MHP) has a number of important applications. It can be used in program optimization, debugging, program understanding tools, improving the accuracy of data flow approaches, and detecting synchronization anomalies, such as data races. In this paper we propose a data flow algorithm for computing a conservative estimate of the MHP information for Java programs that has a worst-case time bound that is cubic in the size of the program. We present a preliminary experimental comparison between our algorithm and a reachability analysis algorithm that determines the “ideal” static MHP information for concurrent Java programs. This initial experiment indicates that our data flow algorithm precisely computed the ideal MHP information in the vast majority of cases we examined. In the two out of 29 cases where the MHP algorithm turned out to be less than ideally precise, the number of spurious pairs was small compared to the total number of ideal MHP pairs.},
  booktitle = {Proceedings of the 7th European Software Engineering Conference Held Jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages = {338–354},
  numpages = {17},
  location = {Toulouse, France},
  keywords = {MHP},
  series = {ESEC/FSE-7}
}

@inproceedings{Joshi:ipdpsw:2012,
  author = {Joshi, Saurabh and Shyamasundar, Rudrapatna K. and Aggarwal, Sanjeev K.},
  booktitle = {2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops \& PhD Forum},
  title = {{A New Method of MHP Analysis for Languages with Dynamic Barriers}},
  year = {2012},
  pages = {519--528},
  keywords = {MHP},
  doi = {10.1109/IPDPSW.2012.70}
}

@inproceedings{Li:lcpc:2005,
  author = {Li, Lin and Verbrugge, Clark},
  editor = {Eigenmann, Rudolf and Li, Zhiyuan and Midkiff, Samuel P.},
  title = {{A Practical MHP Information Analysis for Concurrent Java Programs}},
  booktitle = {Languages and Compilers for High Performance Computing},
  year = {2005},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {194--208},
  abstract = {In this paper we present an implementation of May Happen in Parallel analysis for Java that attempts to address some of the practical implementation concerns of the original work. We describe a design that incorporates techniques for aiding a feasible implementation and expanding the range of acceptable inputs. We provide experimental results showing the utility and impact of our approach and optimizations using a variety of concurrent benchmarks.},
  keywords = {MHP},
  isbn = {978-3-540-31813-2},
}

@article{Taylor:acta:1983,
  author    = {Richard N. Taylor},
  title     = {{Complexity of Analyzing the Synchronization Structure of Concurrent Programs}},
  journal   = {Acta Informatica},
  volume    = {19},
  pages     = {57--84},
  year      = {1983},
  url       = {https://doi.org/10.1007/BF00263928},
  doi       = {10.1007/BF00263928},
  keywords  = {MHP},
}

@techreport{Lee:unpublished:2010,
  title = {{Complexity results for may-happen-in-parallel analysis}},
  author = {Lee, Jonathan K. and Palsberg, Jens and Majumdar, Rupak},
  year = {2010},
  keywords  = {MHP},
  publisher = {Citeseer}
}

@inproceedings{Duesterwald:tav:1991,
  author    = {Evelyn Duesterwald and Mary Lou Soffa},
  editor    = {William E. Howden},
  title     = {{Concurrency Analysis in the Presence of Procedures Using a Data-Flow Framework}},
  booktitle = {Proceedings of the Symposium on Testing, Analysis, and Verification,
    {TAV} 1991, Victoria, British Columbia, Canada, October 8-10, 1991},
  pages     = {36--48},
  publisher = {{ACM}},
  year      = {1991},
  url       = {https://doi.org/10.1145/120807.120811},
  doi       = {10.1145/120807.120811},
  keywords  = {MHP},
}

@article{Ramalingam:toplas:2000,
  author    = {G. Ramalingam},
  title     = {{Context-sensitive synchronization-sensitive analysis is undecidable}},
  journal   = {{ACM} Trans. Program. Lang. Syst.},
  volume    = {22},
  number    = {2},
  pages     = {416--430},
  year      = {2000},
  url       = {https://doi.org/10.1145/349214.349241},
  doi       = {10.1145/349214.349241},
  keywords  = {MHP},
}

@inproceedings{Naumovich:icse:1999,
  author    = {Gleb Naumovich and George S. Avrunin and Lori A. Clarke},
  editor    = {Barry W. Boehm and David Garlan and Jeff Kramer},
  title     = {{Data Flow Analysis for Checking Properties of Concurrent Java Programs}},
  booktitle = {Proceedings of the 1999 International Conference on Software Engineering,
    ICSE' 99, Los Angeles, CA, USA, May 16-22, 1999},
  pages     = {399--410},
  publisher = {{ACM}},
  year      = {1999},
  url       = {https://doi.org/10.1145/302405.302663},
  doi       = {10.1145/302405.302663},
  keywords  = {MHP},
}

@inproceedings{Chen:sigada:2001,
  author    = {Zhengqiang Chen and Baowen Xu and Huiming Yu},
  title     = {{Detecting concurrently executed pairs of statements using an adapted {MHP} algorithm}},
  booktitle = {Proceedings {ACM} SIGAda Annual International Conference, SIGAda 2001,
    September 30 - October 4, 2001, Twin Cities, Best Western The Thunderbird
      Hotel {\&} Convention Center, Bloomington, MN, {USA}},
  pages     = {107--114},
  publisher = {{ACM}},
  year      = {2001},
  url       = {https://doi.org/10.1145/507574.507601},
  doi       = {10.1145/507574.507601},
  keywords  = {MHP},
}

@inproceedings{Barik:lcpc:2005,
  author    = {Rajkishore Barik},
  editor    = {Eduard Ayguad{\'{e}} and Gerald Baumgartner and J. Ramanujam and P. Sadayappan},
  title     = {{Efficient Computation of May-Happen-in-Parallel Information for Concurrent Java Programs}},
  booktitle = {Languages and Compilers for Parallel Computing, 18th International
    Workshop, {LCPC} 2005, Hawthorne, NY, USA, October 20-22, 2005, Revised
      Selected Papers},
  series    = {Lecture Notes in Computer Science},
  volume    = {4339},
  pages     = {152--169},
  publisher = {Springer},
  year      = {2005},
  url       = {https://doi.org/10.1007/978-3-540-69330-7\_11},
  doi       = {10.1007/978-3-540-69330-7\_11},
  keywords  = {MHP},
}

@inproceedings{Lee:sas:2012,
  author = {Lee, Jonathan K.  and Palsberg, Jens and Majumdar, Rupak and Hong, Hong},
  editor = {Min{\'e}, Antoine and Schmidt, David},
  title = {{Efficient May Happen in Parallel Analysis for Async-Finish Parallelism}},
  booktitle = {Static Analysis},
  year = {2012},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {5--23},
  abstract = {For concurrent and parallel languages, the may-happen-in-parallel (MHP) decision problem asks, given two actions in the program, if there is an execution in which they can execute in parallel. Closely related, the MHP computation problem asks, given a program, which pairs of statements may happen in parallel. MHP analysis is the basis for many program analysis problems, such as data race detection and determinism checking, and researchers have devised MHP analyses for a variety of programming models.},
  keywords  = {MHP},
  isbn = {978-3-642-33125-1},
}

@inproceedings{Sankar:cc:2016,
  author = {Sankar, Aravind and Chakraborty, Soham and Nandivada, V. Krishna},
  title = {{Improved MHP Analysis}},
  year = {2016},
  isbn = {9781450342414},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2892208.2897144},
  doi = {10.1145/2892208.2897144},
  abstract = { May-Happen-in-Parallel (MHP) analysis is becoming the backbone of many of the parallel analyses and optimizations. In this paper, we present new approaches to do MHP analysis for X10-like languages that support async-finish-atomic parallelism. We present a fast incremental MHP algorithm to derive all the statements that may run in parallel with a given statement. We also extend the MHP algorithm of Agarwal et al. (answers if two given X10 statements may run in parallel, and under what condition) to improve the computational complexity, without compromising on the precision. },
  booktitle = {Proceedings of the 25th International Conference on Compiler Construction},
  pages = {207–217},
  numpages = {11},
  keywords = {MHP Analysis, Incremental Analysis, MHP},
  location = {Barcelona, Spain},
  series = {CC 2016}
}

@inproceedings{Chen:pact:2012,
  author    = {Congming Chen and Wei Huo and Xiaobing Feng},
  editor    = {Pen{-}Chung Yew and Sangyeun Cho and Luiz DeRose and David J. Lilja},
  title     = {{Making it practical and effective: fast and precise may-happen-in-parallel analysis}},
  booktitle = {International Conference on Parallel Architectures and Compilation
    Techniques, {PACT} '12, Minneapolis, MN, {USA} - September 19 - 23,
    2012},
  pages     = {469--470},
  publisher = {{ACM}},
  year      = {2012},
  url       = {https://doi.org/10.1145/2370816.2370900},
  doi       = {10.1145/2370816.2370900},
  keywords  = {MHP},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/IEEEpact/ChenH012.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Albert:tocl:2015,
  author = {Albert, Elvira and Flores-Montoya, Antonio E. and Genaim, Samir and Martin-Martin, Enrique},
  title = {{May-Happen-in-Parallel Analysis for Actor-Based Concurrency}},
  year = {2015},
  issue_date = {March 2016},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {17},
  number = {2},
  issn = {1529-3785},
  url = {https://doi.org/10.1145/2824255},
  doi = {10.1145/2824255},
  abstract = {This article presents a may-happen-in-parallel (MHP) analysis for languages with actor-based concurrency. In this concurrency model, actors are the concurrency units such that, when a method is invoked on an actor a2 from a task executing on actor a1, statements of the current task in a1 may run in parallel with those of the (asynchronous) call on a2, and with those of transitively invoked methods. The goal of the MHP analysis is to identify pairs of statements in the program that may run in parallel in any execution. Our MHP analysis is formalized as a method-level (local) analysis whose information can be modularly composed to obtain application-level (global) information. The information yielded by the MHP analysis is essential to infer more complex properties of actor-based concurrent programs, for example, data race detection, deadlock freeness, termination, and resource consumption analyses can greatly benefit from the MHP relations to increase their accuracy. We report on MayPar, a prototypical implementation of an MHP static analyzer for a distributed asynchronous language.},
  journal = {ACM Trans. Comput. Logic},
  month = dec,
  articleno = {11},
  numpages = {39},
  keywords = {analysis, concurrency, Actors, may-happen-in-parallel, MHP}
}

@inproceedings{Agarwal:ppopp:2007,
  author = {Agarwal, Shivali and Barik, Rajkishore and Sarkar, Vivek and Shyamasundar, Rudrapatna K.},
  title = {{May-Happen-in-Parallel Analysis of X10 Programs}},
  year = {2007},
  isbn = {9781595936028},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1229428.1229471},
  doi = {10.1145/1229428.1229471},
  abstract = {X10 is a modern object-oriented programming language designed for high performance, high productivity programming of parallel and multi-core computer systems. Compared to the lower-level thread-based concurrency model in the JavaTM language, X10 has higher-level concurrency constructs such as async, atomic and finish built into the language to simplify creation, analysis and optimization of parallel programs. In this paper, we introduce a new algorithm for May-Happen-in-Parallel (MHP) analysis of X10 programs. The analysis algorithm is based on simple path traversals in the Program Structure Tree, and does not rely on pointer alias analysis of thread objects as in MHP analysis for Java programs. We introduce a more precise definition of the MHP relation than in past work by adding condition vectors that identify execution instances for which the MHP relation holds, instead of just returning a single true/false value for all pairs of executing instances. Further, MHP analysis is refined in our approach by using the observation that two statement instances which occur in atomic sections that execute at the same X10 place must have MHP = false. We expect that our MHP analysis algorithm will be applicable to any language that adopts the core concepts of places, async, finish, and atomic sections from the X10 programming model. We also believe that this approach offers the best of two worlds to programmers and parallel programming tools ---higher-level abstractions of concurrency coupled with simple and efficient analysis algorithms.},
  booktitle = {Proceedings of the 12th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  pages = {183–193},
  numpages = {11},
  keywords = {place, may-happen-in-parallel, parallel program analysis, activity, atomic, concurrent, X10, MHP},
  location = {San Jose, California, USA},
  series = {PPoPP '07}
}

@inproceedings{Zhou:cgo:2018,
  author = {Zhou, Qing and Li, Lian and Wang, Lei and Xue, Jingling and Feng, Xiaobing},
  title = {{May-Happen-in-Parallel Analysis with Static Vector Clocks}},
  year = {2018},
  isbn = {9781450356176},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3168813},
  doi = {10.1145/3168813},
  abstract = {May-Happen-in-Parallel (MHP) analysis computes whether two statements in a multi-threaded program may execute concurrently or not. It works as a basis for many analyses and optimization techniques of concurrent programs. This paper proposes a novel approach for MHP analysis, by statically computing vector clocks. Static vector clocks extend the classic vector clocks algorithm to handle the complex control flow structures in static analysis, and we have developed an efficient context-sensitive algorithm to compute them. To the best of our knowledge, this is the first attempt to compute vector clocks statically. Using static vector clocks, we can drastically improve the efficiency of existing MHP analyses, without loss of precision: the performance speedup can be up to 1828X, with a much smaller memory footprint (reduced by up to 150X). We have implemented our analysis in a static data race detector, and experimental results show that our MHP analysis can help remove up to 88% of spurious data race pairs.},
  booktitle = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
  pages = {228–240},
  numpages = {13},
  keywords = {context-sensitivity, static race detection, Pthreads, MHP, data race},
  location = {Vienna, Austria},
  series = {CGO 2018}
}

@inproceedings{Albert:fse:2012,
  author = {Albert, Elvira and Flores-Montoya, Antonio E. and Genaim, Samir},
  title = {{MayPar: A May-Happen-in-Parallel Analyzer for Concurrent Objects}},
  year = {2012},
  isbn = {9781450316149},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2393596.2393611},
  doi = {10.1145/2393596.2393611},
  abstract = {We present the concepts, usage and prototypical implementation of MayPar, a may-happen-in-parallel (MHP) static analyzer for a distributed asynchronous language based on concurrent objects. Our tool allows analyzing an application and finding out the pairs of statements that can execute in parallel. The information can be displayed by means of a graphical representation of the MHP analysis graph or, in a textual way, as a set of pairs which identify the program points that may run in parallel. The information yield by MayPar can be relevant (1) to spot bugs in the program related to fragments of code which should not run in parallel and also (2) to improve the precision of other analyses which infer more complex properties (e.g., termination and cost).},
  booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
  articleno = {14},
  numpages = {2},
  keywords = {static analysis, resource guarantees, parallelism, concurrent objects, MHP, data race},
  location = {Cary, North Carolina},
  series = {FSE '12}
}

@inproceedings{Masticola:ppopp:1993,
  author = {Masticola, Stephen P. and Ryder, Barbara G.},
  title = {{Non-Concurrency Analysis}},
  year = {1993},
  isbn = {0897915895},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/155332.155346},
  doi = {10.1145/155332.155346},
  abstract = {Non-concurrency analysis is a set of techniques for statically identifying pairs (or sets) of statements in a concurrent program which can never happen together. This information aids programmers in debugging and manually optimizing programs, improves the precision of data flow analysis, enables optimized translation of rendezvous, facilitates dead code elimination and other automatic optimizations, and allows anomaly detection in explicitly parallel programs. We present a framework for non-concurrency analysis, capable of incorporating previous analysis algorithms [CS88, DS92] and improving upon them. We show general theoretical results which are useful in estimating non-concurrency, and examples of non-concurrency analysis frameworks for two synchronization primitives: the Ada rendezvous and binary semaphores. Both of these frameworks have a low-order polynomial bound on worst-case solution time. We provide experimental evidence that static non-concurrency analysis of Ada programs can be accomplished in a reasonable time, and is generally quite accurate. Our framework, and the set of refinement components we develop, also exhibits dramatic accuracy improvements over [DS91], when the latter is used as a stand-alone algorithm, as demonstrated by our experiments.},
  booktitle = {Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  pages = {129–138},
  numpages = {10},
  keywords  = {MHP, data race},
  location = {San Diego, California, USA},
  series = {PPOPP '93}
}

@inproceedings{Saha:ppopp:2020,
  author = {Saha, Sonali and Nandivada, V. Krishna},
  title = {{On the Fly MHP Analysis}},
  year = {2020},
  isbn = {9781450368186},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3332466.3374541},
  doi = {10.1145/3332466.3374541},
  abstract = {May-Happen-in-Parallel (MHP) analysis forms the basis for many problems of program analysis and program understanding. MHP analysis can also be used by IDEs (integrated-development-environments) to help programmers to refactor parallel-programs, identify racy programs, understand which parts of the program run in parallel, and so on. Since the code keeps changing in the IDE, re-computing the MHP information after every change can be an expensive affair. In this manuscript, we propose a novel scheme to perform incremental MHP analysis (on the fly) of programs written in task parallel languages like X10 to keep the MHP information up to date, in an IDE environment.The key insight of our proposed approach to maintain the MHP information up to date is that we need not rebuild (from scratch) every data structure related to MHP information, after each modification (addition or deletion of statements) in the source code. The idea is to reuse the old MHP information as much as possible and incrementally recompute the MHP information (of a small set of statements) which depends on the statement added/removed. We introduce two new algorithms that deal with addition and removal of parallel constructs like finish, async, atomic, and sequential constructs like loop, if, if-else and other sequential statements, on the fly. Our evaluation shows that our algorithms run much faster than the repeated invocations of the fastest known MHP analysis for X10 programs [Sankar et al. 2016].},
  booktitle = {Proceedings of the 25th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  pages = {173–186},
  numpages = {14},
  keywords = {concurrent programs, incremental analysis, may happen in parallel analysis, MHP},
  location = {San Diego, California},
  series = {PPoPP '20}
}

@inproceedings{Callahan:padd:1998,
  author = {Callahan, David and Sublok, Jaspal},
  title = {{Static Analysis of Low-Level Synchronization}},
  year = {1988},
  isbn = {0897912969},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/68210.69225},
  doi = {10.1145/68210.69225},
  booktitle = {Proceedings of the 1988 ACM SIGPLAN and SIGOPS Workshop on Parallel and Distributed Debugging},
  pages = {100–111},
  numpages = {12},
  location = {Madison, Wisconsin, USA},
  keywords  = {MHP},
  series = {PADD '88}
}

@inproceedings{Lin:iwomp:2005,
  author = {Lin, Yuan},
  title = {{Static Nonconcurrency Analysis of OpenMP Programs}},
  year = {2005},
  isbn = {3540685545},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 2005 and 2006 International Conference on OpenMP Shared Memory Parallel Programming},
  pages = {36–50},
  numpages = {15},
  location = {Eugene, OR, USA},
  keywords  = {MHP},
  series = {IWOMP'05/IWOMP'06}
}

@inproceedings{Bora-llvm-hpc-2021,
  author = {Bora, Utpal and Vaishay, Shraiysh and Joshi, Saurabh and Upadrasta, Ramakrishna},
  title = {{OpenMP aware MHP Analysis for Improved Static Data-Race Detection}},
  year = {2021},
  abstract = {Data races, a major source of bugs in concurrent
  programs, can result in loss of manpower and time as well as data
  loss due to system failures. OpenMP, the de facto shared memory
  parallelism framework used in the HPC community, also suffers
  from data races. To detect race conditions in OpenMP programs
  and improve turnaround time and/or developer productivity, we
  present a data flow analysis based, fast, static data race checker
  in the LLVM compiler framework. Our tool can detect races in
  the presence or absence of explicit barriers, with implicit or
  explicit synchronization. In addition, our tool effectively works
  for the OpenMP target offloading constructs and also supports
  the frequently used OpenMP constructs.
  We formalize and provide a data flow analysis framework to
  perform Phase Interval Analysis (PIA) of OpenMP programs.
  Phase intervals are then used to compute the MHP (and its
  complement NHP) sets for the programs, which, in turn, are
  used to detect data races statically.
  We evaluate our work using multiple OpenMP race detection
  benchmarks and real world applications. Our experiments show
  that the checker is comparable to the state-of-the-art in various
  performance metrics with around 90\% accuracy, almost perfect
  recall, and significantly lower runtime and memory footprint.
  },
  booktitle = {Proceedings of the Seventh Annual Workshop on the LLVM Compiler Infrastructure in HPC},
  numpages = {11},
  location = {St. Louis, Missouri, USA},
  series = {LLVM-HPC '21}
}

@inproceedings{Kildall:popl:1973,
author = {Kildall, Gary A.},
title = {{A Unified Approach to Global Program Optimization}},
year = {1973},
isbn = {9781450373494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/512927.512945},
doi = {10.1145/512927.512945},
abstract = {A technique is presented for global analysis of program structure in order to perform
compile time optimization of object code generated for expressions. The global expression
optimization presented includes constant propagation, common subexpression elimination,
elimination of redundant register load operations, and live expression analysis. A
general purpose program flow analysis algorithm is developed which depends upon the
existence of an "optimizing function." The algorithm is defined formally using a directed
graph model of program flow structure, and is shown to be correct. Several optimizing
functions are defined which, when used in conjunction with the flow analysis algorithm,
provide the various forms of code optimization. The flow analysis algorithm is sufficiently
general that additional functions can easily be defined for other forms of global
code optimization.},
booktitle = {Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {194–206},
numpages = {13},
location = {Boston, Massachusetts},
series = {POPL '73}
}

@inproceedings{Cousot:popl:1977,
   author = {Cousot, Patrick and Cousot, Radhia},
   title = {{Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints}},
   year = {1977},
   isbn = {9781450373500},
   publisher = {Association for Computing Machinery},
   address = {New York, NY, USA},
   url = {https://doi.org/10.1145/512950.512973},
   doi = {10.1145/512950.512973},
   abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), (±)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 → -(+) * (+) → (-) * (+) → (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 → -(+) + (+) → (-) + (+) → (±)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, …).},
   booktitle = {Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
   pages = {238–252},
   numpages = {15},
   location = {Los Angeles, California},
   series = {POPL '77}
}

@article{Kam:acta:1977,
   author = {Kam, John B. and Ullman, Jeffrey D.},
   title = {{Monotone Data Flow Analysis Frameworks}},
   year = {1977},
   issue_date = {September 1977},
   publisher = {Springer-Verlag},
   address = {Berlin, Heidelberg},
   volume = {7},
   number = {3},
   issn = {0001-5903},
   url = {https://doi.org/10.1007/BF00290339},
   doi = {10.1007/BF00290339},
   abstract = {We consider a generalization of Kildall's lattice theoretic approach to data flow analysis, which we call monotone data flow analysis frameworks. Many flow analysis problems which appear in practice meet the monotonicity condition but not Kildall's condition called distributivity. We show that the maximal fixed point solution exists for every instance of every monotone framework, and that it can be obtained by Kildall's algorithm. However, whenever the framework is monotone but not distributive, there are instances in which the desired solution--the "meet over all paths solution" -- differs from the maximal fixed point. Finally, we show the nonexistence of an algorithm to compute the meet over all paths solution for monotone frameworks.},
   journal = {Acta Inf.},
   month = {sep},
   pages = {305–317},
   numpages = {13}
}

@book{Khedker:book:2009,
   author = {Khedker, Uday and Sanyal, Amitabha and Karkare, Bageshri},
   title = {{Data Flow Analysis: Theory and Practice}},
   year = {2009},
   isbn = {0849328802},
   publisher = {CRC Press, Inc.},
   address = {USA},
   edition = {1st},
   abstract = {This work provides an in-depth treatment of data flow analysis technique. Apart from including interprocedural data flow analysis, this book is the first to extend detailed coverage of analysis beyond bit vectors. Supplemented by numerous examples, it equips readers with a combination of mutually supportive theory and practice, presenting mathematical foundations and including study of data flow analysis implementation through use of the GNU Compiler Collection (GCC). Readers can experiment with the analyses described in the book by accessing the authors web page, where they will find the source code of gdfa (generic data flow analyzer).}
}

@book{Birkhoff:book:1940,
   title={{Lattice Theory}},
   author={Birkhoff, Garrett},
   volume={25},
   year={1940},
   publisher={American Mathematical Soc.}
}

@article{Feautrier:ijpp:1992a,
 author = {Feautrier, Paul},
 title = {{Some efficient solutions to the affine scheduling problem: Part I. One-dimensional time}},
 journal = {International Journal of Parallel Programming},
 issue_date = {Oct. 1992},
 volume = {21},
 number = {5},
 month = {October},
 year = {1992},
 issn = {0885-7458},
 pages = {313--348},
 numpages = {36},
 url = {http://dx.doi.org/10.1007/BF01407835},
 doi = {10.1007/BF01407835},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {automatic parallelization, automatic systolic array design,
             scheduling, polyhedral},
 abstract = {
  Programs and systems of recurrence equations may be represented as
  sets of actions which are to be executed subject to precedence constraints. In
  many cases, actions may be labelled by integral vectors in some iteration
  domain, and precedence constraints may be described by affine relations. A
  schedule for such a program is a function which allows one to estimate the
  intrinsic degree of parallelism of the program and to compile a parallel
  version for multiprocessor architectures or systolic arrays. This paper deals
  with the problem of finding closed form schedules as affine or piecewise
  affine functions of the iteration vector. An efficient algorithm which
  reduces the scheduling problem to a parametric linear program of small size,
  which can be readily solved by an efficient algorithm.
 }
}

@article{Feautrier:ijpp:1992b,
 author = {Feautrier, Paul},
 affiliation = {Laboratoire MASI Université de Versailles St-Quentin 45 Avenue
                des Etats-Unis 78035 Versailles Cedex France},
 title = {{Some efficient solutions to the affine scheduling problem. Part II. Multidimensional time}},
 journal = {International Journal of Parallel Programming},
 publisher = {Springer Netherlands},
 issn = {0885-7458},
 keywords = {Informatique},
 pages = {389-420},
 volume = {21},
 issue = {6},
 url = {http://dx.doi.org/10.1007/BF01379404},
 note = {10.1007/BF01379404},
 year = {1992},
 keywords = {polyhedral},
 abstract = {
  This paper extends the algorithms which were given in Part I to cases in which
  there is no affine schedule, i.e. to problems whose parallel complexity is
  polynomial but not linear. The natural generalization is to multidimensional
  schedules with lexicographic ordering as temporal succession. Multidimensional
  affine schedules, are, in a sense, equivalent to polynomial schedules, and are
  much easier to handle automatically. Furthermore, there is a strong connexion
  between multidimensional schedules and loop nests, which allows one to prove
  that a static control program always has a multidimensional schedule. Roughly,
  a larger dimension indicates less parallelism. In the algorithm which is
  presented here, this dimension is computed dynamically, and is just sufficient
  for scheduling the source program. The algorithm lends itself to a "divide and
  conquer" strategy. The paper gives some experimental evidence for the
  applicability, performances and limitations of the algorithm.
 }
}
